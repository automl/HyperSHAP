{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to HyperSHAP's documentation!","text":"<p><code>HyperSHAP</code> is a framework to explain the outcomes of hyperparameter optimization (HPO) by leveraging cooperative game theory concepts such as Shapley values and interaction indices. It is designed to provide actionable insights into the role and interplay of hyperparameters, thereby reducing the manual effort typically required to interpret HPO results. While its primary audience is researchers and practitioners in machine learning and artificial intelligence, its use is not restricted to these target groups.</p> <p>The analysis of HPO results often involves comparing tuned configurations, assessing hyperparameter importance, and identifying optimizer biases. These tasks are typically performed in an ad-hoc and dataset-specific manner, requiring extensive manual inspection of results. Moreover, existing approaches often lack the ability to systematically capture interactions among hyperparameters or to generalize explanations across datasets and optimizers.</p> <p><code>HyperSHAP</code> addresses these challenges by formulating HPO explanations as cooperative games, where hyperparameters form coalitions whose contributions to performance are quantified. This unified framework enables fine-grained analyses, such as ablation studies, sensitivity attribution, tunability assessment, and optimizer behavior characterization. All computations are naturally parallelizable, making <code>HyperSHAP</code> scalable to modern HPO scenarios. By automating and standardizing the generation of interpretable explanations, <code>HyperSHAP</code> alleviates much of the overhead in analyzing HPO results and provides practitioners with clear guidance on which hyperparameters to focus on and how optimizers behave across tasks.</p> <ul> <li>Github repository: https://github.com/automl/hypershap/</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>Additive Shapley decomposition of any performance metric across hyper\u2011parameters.</li> <li>Interaction analysis via the Faithful Shapley Interaction Index (FSII).</li> <li>Ready\u2011made explanation tasks for Ablation, Tunability, and Optimizer Bias studies.</li> <li>Integrated visualisation (SI\u2011graph) for interaction effects.</li> <li>Works with any surrogate model that follows the <code>ExplanationTask</code> interface.</li> </ul>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>This work was partially supported by the European Union (ERC, \u201cixAutoML\u201d, grant no.101041029).</p> <p>Enjoy exploring your HPO pipelines with HyperSHAP! \ud83c\udf89</p>"},{"location":"authors/","title":"Authors","text":""},{"location":"authors/#core-development","title":"Core Development","text":"<ul> <li>Marcel Wever</li> </ul>"},{"location":"authors/#contributions","title":"Contributions","text":"<ul> <li>Maximilian Muschalik</li> <li>Fabian Fumagalli</li> </ul>"},{"location":"cite/","title":"Cite HyperSHAP","text":"<p>If you use HyperSHAP in your research, please cite the original paper:</p>"},{"location":"cite/#citation-string","title":"Citation String","text":"<p>Wever et al., (2025). HyperSHAP: Shapley Values and Interactions for Hyperparameter Importance. CoRR, abs/2502.01276, https://doi.org/10.48550/ARXIV.2502.01276.</p>"},{"location":"cite/#bibtex","title":"Bibtex","text":"<pre><code>@article{wever-arxiv25,\n  author       = {Marcel Wever and\n                  Maximilian Muschalik and\n                  Fabian Fumagalli and\n                  Marius Lindauer},\n  title        = {HyperSHAP: Shapley Values and Interactions for Hyperparameter Importance},\n  journal      = {CoRR},\n  volume       = {abs/2502.01276},\n  year         = {2025},\n  doi          = {10.48550/ARXIV.2502.01276},\n}\n</code></pre> <p>The paper introduces the underlying game-theoretic framework and demonstrates its usefulness for HPO explainability.</p>"},{"location":"contribute/","title":"How to Contribute","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contribute/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contribute/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/automl/HyperSHAP/issues</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contribute/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement a fix for it.</p>"},{"location":"contribute/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"contribute/#write-documentation","title":"Write Documentation","text":"<p>HyperSHAP could always use more documentation, whether as part of the official docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contribute/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/automl/HyperSHAP/issues.</p> <p>If you are proposing a new feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions   are welcome :)</li> </ul>"},{"location":"contribute/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up <code>HyperSHAP</code> for local development. Please note this documentation assumes you already have <code>uv</code> and <code>Git</code> installed and ready to go.</p> <ol> <li> <p>Fork the <code>HyperSHAP</code> repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> </li> </ol> <pre><code>cd &lt;directory_in_which_repo_should_be_created&gt;\ngit clone git@github.com:YOUR_NAME/HyperSHAP.git\n</code></pre> <ol> <li>Now we need to install the environment. Navigate into the directory</li> </ol> <pre><code>cd HyperSHAP\n</code></pre> <p>Then, install and activate the environment with:</p> <pre><code>uv sync\n</code></pre> <ol> <li>Install pre-commit to run linters/formatters at commit time:</li> </ol> <pre><code>uv run pre-commit install\n</code></pre> <ol> <li>Create a branch for local development:</li> </ol> <pre><code>git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> <ol> <li> <p>Don't forget to add test cases for your added functionality to the <code>tests</code> directory.</p> </li> <li> <p>When you're done making changes, check that your changes pass the formatting tests.</p> </li> </ol> <pre><code>make check\n</code></pre> <p>Now, validate that all unit tests are passing:</p> <pre><code>make test\n</code></pre> <ol> <li>Before raising a pull request you should also run tox.    This will run the tests across different versions of Python:</li> </ol> <pre><code>tox\n</code></pre> <p>This requires you to have multiple versions of python installed. This step is also triggered in the CI/CD pipeline, so you could also choose to skip this step locally.</p> <ol> <li>Commit your changes and push your branch to GitHub:</li> </ol> <pre><code>git add .\ngit commit -m \"Your detailed description of your changes.\"\ngit push origin name-of-your-bugfix-or-feature\n</code></pre> <ol> <li>Submit a pull request through the GitHub website.</li> </ol>"},{"location":"contribute/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li> <p>The pull request should include tests.</p> </li> <li> <p>If the pull request adds functionality, the docs should be updated.    Put your new functionality into a function with a docstring, and add the feature to the list in <code>README.md</code>.</p> </li> </ol>"},{"location":"getting_started/","title":"Getting Started","text":""},{"location":"getting_started/#installation","title":"Installation","text":"<p>The <code>HyperSHAP</code> package can be easily installed via PyPI:</p> <pre><code>pip install hypershap\n</code></pre> <p>Alternatively, one can clone the GitHub repository and install hypershap via the following command:</p> <pre><code>make install\n</code></pre>"},{"location":"getting_started/#general-usage","title":"General Usage","text":"<p>Given an existing setup with a ConfigurationSpace from the ConfigSpace package and black-box function as follows:</p> <pre><code>from ConfigSpace import ConfigurationSpace, Configuration\n\n# ConfigurationSpace describing the hyperparameter space\ncs = ConfigurationSpace()\n  ...\n\n# A black-box function, evaluating ConfigSpace.Configuration objects\ndef blackbox_function(cfg: Configuration) -&gt; float:\n  ...\n</code></pre> <p>You can use HyperSHAP as follows:</p> <pre><code>from hypershap import ExplanationTask, HyperSHAP\n\n# Instantiate HyperSHAP\nhypershap = HyperSHAP(ExplanationTask.from_function(config_space=cs,function=blackbox_function))\n# Conduct tunability analysis\nhypershap.tunability(baseline_config=cs.get_default_configuration())\n# Plot results as a Shapley Interaction graph\nhypershap.plot_si_graph()\n</code></pre> <p>The example demonstrates how to:</p> <ol> <li>Wrap a black-box function in an explanation task.</li> <li>Use <code>HyperSHAP</code> to obtain interaction values for the tunability game.</li> <li>Plot the corresponding SI-graph.</li> </ol>"},{"location":"help/","title":"Need help?","text":"<p>Do you have further questions or a problem with <code>HyperSHAP</code> and do not know how to continue?</p> <ol> <li>Check the examples, maybe you can find a suitable solution.</li> <li>Check the GitHub issues, maybe someone else has been in a similar situation already.</li> <li>If you could not find anything related, please create a help issue.</li> </ol>"},{"location":"license/","title":"License","text":"<p>This program is free software: you can redistribute it and/or modify it under the terms of the 3-clause BSD license (please see the LICENSE file). This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. You should have received a copy of the 3-clause BSD license along with this program (see LICENSE file). If not, see BSD-3-Clause license.</p>"},{"location":"api/games/","title":"Games","text":"<p>The games module contains all the game-theoretic explanation games of HyperSHAP.</p>"},{"location":"api/games/#hypershap.games.AblationGame","title":"<code>AblationGame</code>","text":"<p>               Bases: <code>AbstractHPIGame</code></p> <p>The ablation game generates local explanations for hyperparameter configurations.</p> <p>It does so by evaluating all potential ablation paths, switching from a baseline configuration to an optimized configuration value by value. It leverages a surrogate model to estimate performance based on blended configurations.</p> Source code in <code>src/hypershap/games/ablation.py</code> <pre><code>class AblationGame(AbstractHPIGame):\n    \"\"\"The ablation game generates local explanations for hyperparameter configurations.\n\n    It does so by evaluating all potential ablation paths, switching from a baseline configuration\n    to an optimized configuration value by value. It leverages a surrogate model to estimate\n    performance based on blended configurations.\n    \"\"\"\n\n    def __init__(\n        self,\n        explanation_task: AblationExplanationTask,\n        n_workers: int | None = None,\n        verbose: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize an AblationGame.\n\n        Args:\n        explanation_task (AblationExplanationTask): An instance of `AblationExplanationTask`\n            providing access to the baseline configuration, configuration of interest,\n            and the surrogate model for evaluation.\n        n_workers (int | None): The number of worker threads to use for parallel\n            evaluation of coalitions. Defaults to None, which disables parallelization.\n            Using more workers can significantly speed up the computation of Shapley values.\n            The maximum number of workers is capped by the number of coalitions.\n        verbose (bool | None): A boolean indicating whether to print verbose messages\n            during computation. Defaults to None. When set to True, the method prints\n            debugging information and progress updates.\n\n        \"\"\"\n        super().__init__(explanation_task, n_workers=n_workers, verbose=verbose)\n\n    def evaluate_single_coalition(self, coalition: np.ndarray) -&gt; float:\n        \"\"\"Evaluate a single coalition (combination of baseline and optimized hyperparameters).\n\n        This method blends the baseline and optimized configurations based on the provided coalition,\n        then uses the surrogate model to estimate the performance of the blended configuration.\n\n        Args:\n            coalition (np.ndarray): A Boolean array indicating which hyperparameters should be taken from the\n                baseline configuration (False) and which from the configuration of interest (True).\n\n        Returns:\n            float: The performance score of the blended configuration as estimated by the surrogate model.\n\n        \"\"\"\n        baseline_cfg = self._get_explanation_task().baseline_config.get_array()\n        cfg_of_interest = self._get_explanation_task().config_of_interest.get_array()\n        blend = np.where(coalition == 0, baseline_cfg, cfg_of_interest)\n\n        res = self._get_explanation_task().get_single_surrogate_model().evaluate(blend)\n\n        # validate that we do not get a list of floats by accident\n        if isinstance(res, list):  # pragma: no cover\n            raise TypeError  # pragma: no cover\n\n        return res\n\n    def _get_explanation_task(self) -&gt; AblationExplanationTask:\n        \"\"\"Retrieve the explanation task associated with this ablation game.\n\n        This method simply returns the `explanation_task` attribute, which provides\n        access to the baseline configuration, configuration of interest, and surrogate model.\n\n        Returns:\n            AblationExplanationTask: The explanation task associated with this ablation game.\n\n        \"\"\"\n        if isinstance(self.explanation_task, AblationExplanationTask):\n            return self.explanation_task\n\n        raise ValueError  # pragma: no cover\n</code></pre>"},{"location":"api/games/#hypershap.games.AblationGame.__init__","title":"<code>__init__(explanation_task, n_workers=None, verbose=None)</code>","text":"<p>Initialize an AblationGame.</p> <p>explanation_task (AblationExplanationTask): An instance of <code>AblationExplanationTask</code>     providing access to the baseline configuration, configuration of interest,     and the surrogate model for evaluation. n_workers (int | None): The number of worker threads to use for parallel     evaluation of coalitions. Defaults to None, which disables parallelization.     Using more workers can significantly speed up the computation of Shapley values.     The maximum number of workers is capped by the number of coalitions. verbose (bool | None): A boolean indicating whether to print verbose messages     during computation. Defaults to None. When set to True, the method prints     debugging information and progress updates.</p> Source code in <code>src/hypershap/games/ablation.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: AblationExplanationTask,\n    n_workers: int | None = None,\n    verbose: bool | None = None,\n) -&gt; None:\n    \"\"\"Initialize an AblationGame.\n\n    Args:\n    explanation_task (AblationExplanationTask): An instance of `AblationExplanationTask`\n        providing access to the baseline configuration, configuration of interest,\n        and the surrogate model for evaluation.\n    n_workers (int | None): The number of worker threads to use for parallel\n        evaluation of coalitions. Defaults to None, which disables parallelization.\n        Using more workers can significantly speed up the computation of Shapley values.\n        The maximum number of workers is capped by the number of coalitions.\n    verbose (bool | None): A boolean indicating whether to print verbose messages\n        during computation. Defaults to None. When set to True, the method prints\n        debugging information and progress updates.\n\n    \"\"\"\n    super().__init__(explanation_task, n_workers=n_workers, verbose=verbose)\n</code></pre>"},{"location":"api/games/#hypershap.games.AblationGame.evaluate_single_coalition","title":"<code>evaluate_single_coalition(coalition)</code>","text":"<p>Evaluate a single coalition (combination of baseline and optimized hyperparameters).</p> <p>This method blends the baseline and optimized configurations based on the provided coalition, then uses the surrogate model to estimate the performance of the blended configuration.</p> <p>Parameters:</p> Name Type Description Default <code>coalition</code> <code>ndarray</code> <p>A Boolean array indicating which hyperparameters should be taken from the baseline configuration (False) and which from the configuration of interest (True).</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The performance score of the blended configuration as estimated by the surrogate model.</p> Source code in <code>src/hypershap/games/ablation.py</code> <pre><code>def evaluate_single_coalition(self, coalition: np.ndarray) -&gt; float:\n    \"\"\"Evaluate a single coalition (combination of baseline and optimized hyperparameters).\n\n    This method blends the baseline and optimized configurations based on the provided coalition,\n    then uses the surrogate model to estimate the performance of the blended configuration.\n\n    Args:\n        coalition (np.ndarray): A Boolean array indicating which hyperparameters should be taken from the\n            baseline configuration (False) and which from the configuration of interest (True).\n\n    Returns:\n        float: The performance score of the blended configuration as estimated by the surrogate model.\n\n    \"\"\"\n    baseline_cfg = self._get_explanation_task().baseline_config.get_array()\n    cfg_of_interest = self._get_explanation_task().config_of_interest.get_array()\n    blend = np.where(coalition == 0, baseline_cfg, cfg_of_interest)\n\n    res = self._get_explanation_task().get_single_surrogate_model().evaluate(blend)\n\n    # validate that we do not get a list of floats by accident\n    if isinstance(res, list):  # pragma: no cover\n        raise TypeError  # pragma: no cover\n\n    return res\n</code></pre>"},{"location":"api/games/#hypershap.games.AbstractHPIGame","title":"<code>AbstractHPIGame</code>","text":"<p>               Bases: <code>Game</code></p> <p>Abstract base class for Hyperparameter Importance Games (HPIGames).</p> <p>Represents a game-theoretic framework for analyzing the importance of hyperparameters for HPO. It leverages the <code>shapiq</code> library to compute Shapley values and analyze coalition behavior.</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>ExplanationTask</code> <p>The <code>ExplanationTask</code> containing information about the configuration space and surrogate model.</p> required <code>n_workers</code> <code>int | None</code> <p>The number of worker threads to use for parallel evaluation of coalitions. Defaults to 1.  Using more workers can significantly speed up the computation of Shapley values.</p> <code>None</code> <code>verbose</code> <code>bool | None</code> <p>A boolean indicating whether to print verbose messages during computation. Defaults to False.</p> <code>None</code> Source code in <code>src/hypershap/games/abstract.py</code> <pre><code>class AbstractHPIGame(Game):\n    \"\"\"Abstract base class for Hyperparameter Importance Games (HPIGames).\n\n    Represents a game-theoretic framework for analyzing the importance of\n    hyperparameters for HPO. It leverages the `shapiq` library to compute\n    Shapley values and analyze coalition behavior.\n\n    Args:\n        explanation_task: The `ExplanationTask` containing information about\n            the configuration space and surrogate model.\n        n_workers: The number of worker threads to use for parallel evaluation\n            of coalitions. Defaults to 1.  Using more workers can significantly\n            speed up the computation of Shapley values.\n        verbose:  A boolean indicating whether to print verbose messages during\n            computation. Defaults to False.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        explanation_task: ExplanationTask,\n        n_workers: int | None = None,\n        verbose: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize the Hyperparameter Interaction Game (HPIGame).\n\n        Args:\n            explanation_task: The `ExplanationTask` containing information about\n                the configuration space and surrogate model. This task defines the\n                hyperparameter search space and the model used to estimate performance.\n            n_workers: The number of worker threads to use for parallel evaluation\n                of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n                speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n            verbose:  A boolean indicating whether to print verbose messages during\n                computation. Defaults to None.  When set to True, the method prints\n                debugging information and progress updates.\n\n        \"\"\"\n        self.explanation_task = explanation_task\n        self.n_workers = n_workers if n_workers is not None else 1\n        self.verbose = verbose if verbose is not None else False\n\n        # determine the value of the empty coalition so that we can normalize wrt to that performance\n        normalization_value = self.evaluate_single_coalition(\n            np.array([False] * explanation_task.get_num_hyperparameters()),\n        )\n\n        super().__init__(\n            n_players=explanation_task.get_num_hyperparameters(),\n            normalize=True,\n            normalization_value=normalization_value,\n        )\n\n    def _process_chunk(self, chunk: np.ndarray) -&gt; list:\n        \"\"\"Process a chunk of coalitions, evaluating each coalition using the `evaluate_single_coalition` method.\n\n        Args:\n            chunk: A NumPy array representing a subset of coalitions.\n\n        Returns:\n            A list of floats, where each float is the value of a coalition\n            in the input chunk.\n\n        \"\"\"\n        return [self.evaluate_single_coalition(c) for c in chunk]\n\n    def value_function(self, coalitions: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Calculate the value of a list of coalitions.\n\n        This method handles both single-worker and multi-worker scenarios for efficient computation.\n\n        Args:\n            coalitions: A NumPy array representing a list of coalitions.  Each\n                coalition is a Boolean array indicating which hyperparameters\n                are included in that coalition.\n\n        Returns:\n            A NumPy array containing the values of the input coalitions.\n\n        \"\"\"\n        if self.n_workers == 1:\n            value_list = []\n            for coalition in coalitions:\n                value_list += [self.evaluate_single_coalition(coalition)]\n        else:\n            m = len(coalitions)\n            num_workers = min(self.n_workers, m)\n            base_size = m // num_workers\n            remainder = m % num_workers\n\n            chunk_indices: Iterable[tuple[int, int]] = []\n            start = 0\n            for i in range(num_workers):\n                size = base_size + (1 if i &lt; remainder else 0)\n                chunk_indices.append((start, start + size))\n                start += size\n\n            chunks = [coalitions[start:end] for start, end in chunk_indices]\n\n            with ThreadPoolExecutor(max_workers=self.n_workers) as executor:\n                partial_results = list(executor.map(self._process_chunk, chunks))\n\n            value_list = [val for sublist in partial_results for val in sublist]\n        return np.array(value_list)\n\n    @abstractmethod\n    def evaluate_single_coalition(self, coalition: np.ndarray) -&gt; float:\n        \"\"\"Evaluate the value of a single coalition.\n\n        This method *must* be implemented by subclasses.\n\n        Args:\n            coalition: A boolean array representing a coalition of hyperparameters.\n\n        Returns:\n            The value of the coalition (a float).\n\n        \"\"\"\n\n    def get_num_hyperparameters(self) -&gt; int:\n        \"\"\"Return the number of hyperparameters being considered.\n\n        Returns:\n            The number of hyperparameters (an integer).\n\n        \"\"\"\n        return self.explanation_task.get_num_hyperparameters()\n\n    def get_hyperparameter_names(self) -&gt; list[str]:\n        \"\"\"Return a list of the names of the hyperparameters.\n\n        Returns:\n            A list of strings, where each string is the name of a hyperparameter.\n\n        \"\"\"\n        return self.explanation_task.get_hyperparameter_names()\n</code></pre>"},{"location":"api/games/#hypershap.games.AbstractHPIGame.__init__","title":"<code>__init__(explanation_task, n_workers=None, verbose=None)</code>","text":"<p>Initialize the Hyperparameter Interaction Game (HPIGame).</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>ExplanationTask</code> <p>The <code>ExplanationTask</code> containing information about the configuration space and surrogate model. This task defines the hyperparameter search space and the model used to estimate performance.</p> required <code>n_workers</code> <code>int | None</code> <p>The number of worker threads to use for parallel evaluation of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.</p> <code>None</code> <code>verbose</code> <code>bool | None</code> <p>A boolean indicating whether to print verbose messages during computation. Defaults to None.  When set to True, the method prints debugging information and progress updates.</p> <code>None</code> Source code in <code>src/hypershap/games/abstract.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: ExplanationTask,\n    n_workers: int | None = None,\n    verbose: bool | None = None,\n) -&gt; None:\n    \"\"\"Initialize the Hyperparameter Interaction Game (HPIGame).\n\n    Args:\n        explanation_task: The `ExplanationTask` containing information about\n            the configuration space and surrogate model. This task defines the\n            hyperparameter search space and the model used to estimate performance.\n        n_workers: The number of worker threads to use for parallel evaluation\n            of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n            speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n        verbose:  A boolean indicating whether to print verbose messages during\n            computation. Defaults to None.  When set to True, the method prints\n            debugging information and progress updates.\n\n    \"\"\"\n    self.explanation_task = explanation_task\n    self.n_workers = n_workers if n_workers is not None else 1\n    self.verbose = verbose if verbose is not None else False\n\n    # determine the value of the empty coalition so that we can normalize wrt to that performance\n    normalization_value = self.evaluate_single_coalition(\n        np.array([False] * explanation_task.get_num_hyperparameters()),\n    )\n\n    super().__init__(\n        n_players=explanation_task.get_num_hyperparameters(),\n        normalize=True,\n        normalization_value=normalization_value,\n    )\n</code></pre>"},{"location":"api/games/#hypershap.games.AbstractHPIGame.evaluate_single_coalition","title":"<code>evaluate_single_coalition(coalition)</code>  <code>abstractmethod</code>","text":"<p>Evaluate the value of a single coalition.</p> <p>This method must be implemented by subclasses.</p> <p>Parameters:</p> Name Type Description Default <code>coalition</code> <code>ndarray</code> <p>A boolean array representing a coalition of hyperparameters.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The value of the coalition (a float).</p> Source code in <code>src/hypershap/games/abstract.py</code> <pre><code>@abstractmethod\ndef evaluate_single_coalition(self, coalition: np.ndarray) -&gt; float:\n    \"\"\"Evaluate the value of a single coalition.\n\n    This method *must* be implemented by subclasses.\n\n    Args:\n        coalition: A boolean array representing a coalition of hyperparameters.\n\n    Returns:\n        The value of the coalition (a float).\n\n    \"\"\"\n</code></pre>"},{"location":"api/games/#hypershap.games.AbstractHPIGame.get_hyperparameter_names","title":"<code>get_hyperparameter_names()</code>","text":"<p>Return a list of the names of the hyperparameters.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of strings, where each string is the name of a hyperparameter.</p> Source code in <code>src/hypershap/games/abstract.py</code> <pre><code>def get_hyperparameter_names(self) -&gt; list[str]:\n    \"\"\"Return a list of the names of the hyperparameters.\n\n    Returns:\n        A list of strings, where each string is the name of a hyperparameter.\n\n    \"\"\"\n    return self.explanation_task.get_hyperparameter_names()\n</code></pre>"},{"location":"api/games/#hypershap.games.AbstractHPIGame.get_num_hyperparameters","title":"<code>get_num_hyperparameters()</code>","text":"<p>Return the number of hyperparameters being considered.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of hyperparameters (an integer).</p> Source code in <code>src/hypershap/games/abstract.py</code> <pre><code>def get_num_hyperparameters(self) -&gt; int:\n    \"\"\"Return the number of hyperparameters being considered.\n\n    Returns:\n        The number of hyperparameters (an integer).\n\n    \"\"\"\n    return self.explanation_task.get_num_hyperparameters()\n</code></pre>"},{"location":"api/games/#hypershap.games.AbstractHPIGame.value_function","title":"<code>value_function(coalitions)</code>","text":"<p>Calculate the value of a list of coalitions.</p> <p>This method handles both single-worker and multi-worker scenarios for efficient computation.</p> <p>Parameters:</p> Name Type Description Default <code>coalitions</code> <code>ndarray</code> <p>A NumPy array representing a list of coalitions.  Each coalition is a Boolean array indicating which hyperparameters are included in that coalition.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A NumPy array containing the values of the input coalitions.</p> Source code in <code>src/hypershap/games/abstract.py</code> <pre><code>def value_function(self, coalitions: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Calculate the value of a list of coalitions.\n\n    This method handles both single-worker and multi-worker scenarios for efficient computation.\n\n    Args:\n        coalitions: A NumPy array representing a list of coalitions.  Each\n            coalition is a Boolean array indicating which hyperparameters\n            are included in that coalition.\n\n    Returns:\n        A NumPy array containing the values of the input coalitions.\n\n    \"\"\"\n    if self.n_workers == 1:\n        value_list = []\n        for coalition in coalitions:\n            value_list += [self.evaluate_single_coalition(coalition)]\n    else:\n        m = len(coalitions)\n        num_workers = min(self.n_workers, m)\n        base_size = m // num_workers\n        remainder = m % num_workers\n\n        chunk_indices: Iterable[tuple[int, int]] = []\n        start = 0\n        for i in range(num_workers):\n            size = base_size + (1 if i &lt; remainder else 0)\n            chunk_indices.append((start, start + size))\n            start += size\n\n        chunks = [coalitions[start:end] for start, end in chunk_indices]\n\n        with ThreadPoolExecutor(max_workers=self.n_workers) as executor:\n            partial_results = list(executor.map(self._process_chunk, chunks))\n\n        value_list = [val for sublist in partial_results for val in sublist]\n    return np.array(value_list)\n</code></pre>"},{"location":"api/games/#hypershap.games.MistunabilityGame","title":"<code>MistunabilityGame</code>","text":"<p>               Bases: <code>SearchBasedGame</code></p> <p>Game representing the mistunability of hyperparameters.</p> Source code in <code>src/hypershap/games/tunability.py</code> <pre><code>class MistunabilityGame(SearchBasedGame):\n    \"\"\"Game representing the mistunability of hyperparameters.\"\"\"\n\n    def __init__(\n        self,\n        explanation_task: MistunabilityExplanationTask,\n        cs_searcher: ConfigSpaceSearcher | None = None,\n        n_workers: int | None = None,\n        verbose: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize the mistunability game.\n\n        Args:\n            explanation_task: The explanation task containing the configuration\n                space and surrogate model.\n            cs_searcher: The configuration space searcher. If None, a\n                RandomConfigSpaceSearcher is used by default.\n            n_workers: The number of worker threads to use for parallel evaluation\n                of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n                speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n            verbose:  A boolean indicating whether to print verbose messages during\n                computation. Defaults to None.  When set to True, the method prints\n                debugging information and progress updates.\n\n        \"\"\"\n        # set cs searcher if not given by default to a random config space searcher.\n        if cs_searcher is None:\n            cs_searcher = RandomConfigSpaceSearcher(explanation_task, mode=Aggregation.MIN)\n        elif cs_searcher.mode != Aggregation.MIN:  # ensure that cs_searcher is maximizing\n            logger.warning(\"WARN: Mistunability game set mode of given ConfigSpaceSearcher to minimize.\")\n            cs_searcher.mode = Aggregation.MIN\n\n        super().__init__(explanation_task, cs_searcher, n_workers=n_workers, verbose=verbose)\n</code></pre>"},{"location":"api/games/#hypershap.games.MistunabilityGame.__init__","title":"<code>__init__(explanation_task, cs_searcher=None, n_workers=None, verbose=None)</code>","text":"<p>Initialize the mistunability game.</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>MistunabilityExplanationTask</code> <p>The explanation task containing the configuration space and surrogate model.</p> required <code>cs_searcher</code> <code>ConfigSpaceSearcher | None</code> <p>The configuration space searcher. If None, a RandomConfigSpaceSearcher is used by default.</p> <code>None</code> <code>n_workers</code> <code>int | None</code> <p>The number of worker threads to use for parallel evaluation of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.</p> <code>None</code> <code>verbose</code> <code>bool | None</code> <p>A boolean indicating whether to print verbose messages during computation. Defaults to None.  When set to True, the method prints debugging information and progress updates.</p> <code>None</code> Source code in <code>src/hypershap/games/tunability.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: MistunabilityExplanationTask,\n    cs_searcher: ConfigSpaceSearcher | None = None,\n    n_workers: int | None = None,\n    verbose: bool | None = None,\n) -&gt; None:\n    \"\"\"Initialize the mistunability game.\n\n    Args:\n        explanation_task: The explanation task containing the configuration\n            space and surrogate model.\n        cs_searcher: The configuration space searcher. If None, a\n            RandomConfigSpaceSearcher is used by default.\n        n_workers: The number of worker threads to use for parallel evaluation\n            of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n            speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n        verbose:  A boolean indicating whether to print verbose messages during\n            computation. Defaults to None.  When set to True, the method prints\n            debugging information and progress updates.\n\n    \"\"\"\n    # set cs searcher if not given by default to a random config space searcher.\n    if cs_searcher is None:\n        cs_searcher = RandomConfigSpaceSearcher(explanation_task, mode=Aggregation.MIN)\n    elif cs_searcher.mode != Aggregation.MIN:  # ensure that cs_searcher is maximizing\n        logger.warning(\"WARN: Mistunability game set mode of given ConfigSpaceSearcher to minimize.\")\n        cs_searcher.mode = Aggregation.MIN\n\n    super().__init__(explanation_task, cs_searcher, n_workers=n_workers, verbose=verbose)\n</code></pre>"},{"location":"api/games/#hypershap.games.MultiBaselineAblationGame","title":"<code>MultiBaselineAblationGame</code>","text":"<p>               Bases: <code>AbstractHPIGame</code></p> <p>The multi-baseline ablation game generates local explanations for hyperparameter configurations.</p> <p>It does so by considering multiple baseline configurations as starting points.</p> Source code in <code>src/hypershap/games/ablation.py</code> <pre><code>class MultiBaselineAblationGame(AbstractHPIGame):\n    \"\"\"The multi-baseline ablation game generates local explanations for hyperparameter configurations.\n\n    It does so by considering multiple baseline configurations as starting points.\n    \"\"\"\n\n    def __init__(\n        self,\n        explanation_task: MultiBaselineAblationExplanationTask,\n        aggregation: Aggregation = Aggregation.AVG,\n        n_workers: int | None = None,\n        verbose: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize a MultiBaselineAblationGame.\n\n        n_workers (int | None): The number of worker threads to use for parallel\n            evaluation of coalitions. Defaults to None, which disables parallelization.\n            Using more workers can significantly speed up the computation of Shapley values.\n            The maximum number of workers is capped by the number of coalitions.\n        verbose (bool | None): A boolean indicating whether to print verbose messages\n            during computation. Defaults to None. When set to True, the method prints\n            debugging information and progress updates.\n        \"\"\"\n        self.aggregation = aggregation\n        self.ablation_games = [\n            AblationGame(\n                AblationExplanationTask(\n                    config_space=explanation_task.config_space,\n                    surrogate_model=explanation_task.surrogate_model,\n                    baseline_config=baseline_config,\n                    config_of_interest=explanation_task.config_of_interest,\n                ),\n                n_workers=n_workers,\n                verbose=verbose,\n            )\n            for baseline_config in explanation_task.baseline_configs\n        ]\n        super().__init__(explanation_task, n_workers, verbose)\n\n    def evaluate_single_coalition(self, coalition: np.ndarray) -&gt; float:\n        \"\"\"Evaluate a single coalition (combination of baseline and optimized hyperparameters).\"\"\"\n        vals = np.array([ag.evaluate_single_coalition(coalition) for ag in self.ablation_games])\n        return evaluate_aggregation(self.aggregation, vals)\n</code></pre>"},{"location":"api/games/#hypershap.games.MultiBaselineAblationGame.__init__","title":"<code>__init__(explanation_task, aggregation=Aggregation.AVG, n_workers=None, verbose=None)</code>","text":"<p>Initialize a MultiBaselineAblationGame.</p> <p>n_workers (int | None): The number of worker threads to use for parallel     evaluation of coalitions. Defaults to None, which disables parallelization.     Using more workers can significantly speed up the computation of Shapley values.     The maximum number of workers is capped by the number of coalitions. verbose (bool | None): A boolean indicating whether to print verbose messages     during computation. Defaults to None. When set to True, the method prints     debugging information and progress updates.</p> Source code in <code>src/hypershap/games/ablation.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: MultiBaselineAblationExplanationTask,\n    aggregation: Aggregation = Aggregation.AVG,\n    n_workers: int | None = None,\n    verbose: bool | None = None,\n) -&gt; None:\n    \"\"\"Initialize a MultiBaselineAblationGame.\n\n    n_workers (int | None): The number of worker threads to use for parallel\n        evaluation of coalitions. Defaults to None, which disables parallelization.\n        Using more workers can significantly speed up the computation of Shapley values.\n        The maximum number of workers is capped by the number of coalitions.\n    verbose (bool | None): A boolean indicating whether to print verbose messages\n        during computation. Defaults to None. When set to True, the method prints\n        debugging information and progress updates.\n    \"\"\"\n    self.aggregation = aggregation\n    self.ablation_games = [\n        AblationGame(\n            AblationExplanationTask(\n                config_space=explanation_task.config_space,\n                surrogate_model=explanation_task.surrogate_model,\n                baseline_config=baseline_config,\n                config_of_interest=explanation_task.config_of_interest,\n            ),\n            n_workers=n_workers,\n            verbose=verbose,\n        )\n        for baseline_config in explanation_task.baseline_configs\n    ]\n    super().__init__(explanation_task, n_workers, verbose)\n</code></pre>"},{"location":"api/games/#hypershap.games.MultiBaselineAblationGame.evaluate_single_coalition","title":"<code>evaluate_single_coalition(coalition)</code>","text":"<p>Evaluate a single coalition (combination of baseline and optimized hyperparameters).</p> Source code in <code>src/hypershap/games/ablation.py</code> <pre><code>def evaluate_single_coalition(self, coalition: np.ndarray) -&gt; float:\n    \"\"\"Evaluate a single coalition (combination of baseline and optimized hyperparameters).\"\"\"\n    vals = np.array([ag.evaluate_single_coalition(coalition) for ag in self.ablation_games])\n    return evaluate_aggregation(self.aggregation, vals)\n</code></pre>"},{"location":"api/games/#hypershap.games.MultiDataHPIGame","title":"<code>MultiDataHPIGame</code>","text":"<p>               Bases: <code>AbstractHPIGame</code></p> <p>The multi-data game generalizes an explanation game to multiple datasets.</p> Source code in <code>src/hypershap/games/multi_data.py</code> <pre><code>class MultiDataHPIGame(AbstractHPIGame):\n    \"\"\"The multi-data game generalizes an explanation game to multiple datasets.\"\"\"\n\n    def __init__(\n        self,\n        explanation_task: ExplanationTask,\n        base_game: AbstractHPIGame,\n        aggregation: Aggregation,\n    ) -&gt; None:\n        \"\"\"Initialize the multi-data game wrapper.\n\n        Args:\n            explanation_task: The explanation task containing the configuration space and surrogate model.\n            base_game: The base game instance.\n            aggregation: The aggregation method to use.\n\n        \"\"\"\n        self.aggregation = aggregation\n        self.base_game = base_game\n\n        self.sub_games = []\n        for surrogate_model in explanation_task.get_surrogate_model_list():\n            game_copy = copy.deepcopy(base_game)\n            game_copy.explanation_task.surrogate_model = surrogate_model\n            if isinstance(game_copy, SearchBasedGame):\n                game_copy.cs_searcher.explanation_task.surrogate_model = surrogate_model\n            if isinstance(game_copy, MultiBaselineAblationGame):\n                for ag in game_copy.ablation_games:\n                    ag.explanation_task.surrogate_model = surrogate_model\n            self.sub_games.append(game_copy)\n\n        super().__init__(explanation_task)\n\n    def evaluate_single_coalition(self, coalition: np.ndarray) -&gt; float:\n        \"\"\"Evaluate the multi-data game on the coalition.\n\n        Args:\n            coalition: The coalition to evaluate.\n\n        Returns: The value of the multi-data game on the coalition.\n\n        \"\"\"\n        vals = np.array([game.evaluate_single_coalition(coalition) for game in self.sub_games])\n        return evaluate_aggregation(self.aggregation, vals)\n</code></pre>"},{"location":"api/games/#hypershap.games.MultiDataHPIGame.__init__","title":"<code>__init__(explanation_task, base_game, aggregation)</code>","text":"<p>Initialize the multi-data game wrapper.</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>ExplanationTask</code> <p>The explanation task containing the configuration space and surrogate model.</p> required <code>base_game</code> <code>AbstractHPIGame</code> <p>The base game instance.</p> required <code>aggregation</code> <code>Aggregation</code> <p>The aggregation method to use.</p> required Source code in <code>src/hypershap/games/multi_data.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: ExplanationTask,\n    base_game: AbstractHPIGame,\n    aggregation: Aggregation,\n) -&gt; None:\n    \"\"\"Initialize the multi-data game wrapper.\n\n    Args:\n        explanation_task: The explanation task containing the configuration space and surrogate model.\n        base_game: The base game instance.\n        aggregation: The aggregation method to use.\n\n    \"\"\"\n    self.aggregation = aggregation\n    self.base_game = base_game\n\n    self.sub_games = []\n    for surrogate_model in explanation_task.get_surrogate_model_list():\n        game_copy = copy.deepcopy(base_game)\n        game_copy.explanation_task.surrogate_model = surrogate_model\n        if isinstance(game_copy, SearchBasedGame):\n            game_copy.cs_searcher.explanation_task.surrogate_model = surrogate_model\n        if isinstance(game_copy, MultiBaselineAblationGame):\n            for ag in game_copy.ablation_games:\n                ag.explanation_task.surrogate_model = surrogate_model\n        self.sub_games.append(game_copy)\n\n    super().__init__(explanation_task)\n</code></pre>"},{"location":"api/games/#hypershap.games.MultiDataHPIGame.evaluate_single_coalition","title":"<code>evaluate_single_coalition(coalition)</code>","text":"<p>Evaluate the multi-data game on the coalition.</p> <p>Parameters:</p> Name Type Description Default <code>coalition</code> <code>ndarray</code> <p>The coalition to evaluate.</p> required <p>Returns: The value of the multi-data game on the coalition.</p> Source code in <code>src/hypershap/games/multi_data.py</code> <pre><code>def evaluate_single_coalition(self, coalition: np.ndarray) -&gt; float:\n    \"\"\"Evaluate the multi-data game on the coalition.\n\n    Args:\n        coalition: The coalition to evaluate.\n\n    Returns: The value of the multi-data game on the coalition.\n\n    \"\"\"\n    vals = np.array([game.evaluate_single_coalition(coalition) for game in self.sub_games])\n    return evaluate_aggregation(self.aggregation, vals)\n</code></pre>"},{"location":"api/games/#hypershap.games.OptimizerBiasGame","title":"<code>OptimizerBiasGame</code>","text":"<p>               Bases: <code>AbstractHPIGame</code></p> <p>An explanation game to measure bias in hyperparameter optimizers.</p> <p>This class extends the <code>AbstractHPIGame</code> base class and is specifically designed to quantify how much an optimizer is biased toward tuning certain hyperparameters. To this end a set of diverse optimizers is used as a reference.</p> <p>Attributes:</p> Name Type Description <code>explanation_task</code> <code>OptimizerBiasExplanationTask</code> <p>The task that defines the game. This includes the configuration sapce, the surrogate model and a baseline configuration, as well as the optimizer of interest and the ensemble of diverse optimizers.</p> <p>Methods:</p> Name Description <code>evaluate_single_coalition</code> <p>Computes the marginal contribution of a coalition (subset of features) by comparing the optimizer of interest against an optimizer ensemble. This method is called internally during the game's main evaluation process.</p> Note <p>The game evaluates coalitions based on the difference between the outcome using the primary optimizer and the maximum outcome achieved by any optimizer in the provided ensemble.</p> Source code in <code>src/hypershap/games/optimizerbias.py</code> <pre><code>class OptimizerBiasGame(AbstractHPIGame):\n    \"\"\"An explanation game to measure bias in hyperparameter optimizers.\n\n    This class extends the `AbstractHPIGame` base class and is specifically designed\n    to quantify how much an optimizer is biased toward tuning certain hyperparameters.\n    To this end a set of diverse optimizers is used as a reference.\n\n    Attributes:\n        explanation_task (OptimizerBiasExplanationTask): The task that defines the game.\n            This includes the configuration sapce, the surrogate model and a baseline configuration, as well as the\n            optimizer of interest and the ensemble of diverse optimizers.\n\n\n    Methods:\n        evaluate_single_coalition: Computes the marginal contribution of a coalition (subset of features)\n            by comparing the optimizer of interest against an optimizer ensemble. This method is called internally\n            during the game's main evaluation process.\n\n    Note:\n        The game evaluates coalitions based on the difference between the outcome using the primary optimizer\n        and the maximum outcome achieved by any optimizer in the provided ensemble.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        explanation_task: OptimizerBiasExplanationTask,\n        n_workers: int | None = None,\n        verbose: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize an instance of `OptimizerBiasGame`.\n\n        Args:\n            explanation_task (OptimizerBiasExplanationTask): The task that contains all necessary\n                information for defining the game. This includes the configuration space, the surrogate model, the\n                optimizer of interest, and the ensemble of diverse optimizers.\n            n_workers: The number of worker threads to use for parallel evaluation\n                of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n                speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n            verbose:  A boolean indicating whether to print verbose messages during\n                computation. Defaults to None.  When set to True, the method prints\n                debugging information and progress updates.\n\n        Example:\n            &gt;&gt;&gt; from hypershap.task import OptimizerBiasExplanationTask\n            &gt;&gt;&gt; # Create an explanation task instance with specific parameters\n            &gt;&gt;&gt; expl_task = OptimizerBiasExplanationTask(...)\n            &gt;&gt;&gt; game = OptimizerBiasGame(expl_task)\n\n        \"\"\"\n        super().__init__(explanation_task, n_workers=n_workers, verbose=verbose)\n\n    def _get_explanation_task(self) -&gt; OptimizerBiasExplanationTask:\n        if isinstance(self.explanation_task, OptimizerBiasExplanationTask):\n            return self.explanation_task\n        raise ValueError  # pragma: no cover\n\n    def evaluate_single_coalition(self, coalition: np.ndarray) -&gt; float:\n        \"\"\"Evaluate a single coalition by comparing against an optimizer ensemble.\n\n        Args:\n            coalition (np.ndarray): A binary array indicating which hyperparameters are included in the coalition.\n                The array has shape (n_hyperparameters,) where True means hyperparameters is included and False\n                 otherwise.\n\n        Returns:\n            float: The marginal contribution of the coalition. It is computed as the difference between\n                the outcome when using the optimizer of interest with the given coalition, versus the best outcome\n                achievable by any optimizer in the ensemble (including the one of interest).\n\n        Note:\n            This method overrides a base class abstract method and must be implemented to provide specific game logic.\n            The value returned here is used for computing Shapley values or other cooperative game theory measures.\n\n        Example:\n            &gt;&gt;&gt; coalition = np.array([1, 0, 1])  # Hyperparameters 0 and 2 are included\n            &gt;&gt;&gt; marginal_contribution = game.evaluate_single_coalition(coalition)\n            &gt;&gt;&gt; print(marginal_contribution)  # Outputs the difference in outcomes for this coalition.\n\n        \"\"\"\n        optimizer_res = self._get_explanation_task().optimizer_of_interest.search(coalition)\n        optimizer_ensemble_res = [\n            optimizer.search(coalition) for optimizer in self._get_explanation_task().optimizer_ensemble\n        ]\n        return optimizer_res - max([*optimizer_ensemble_res, optimizer_res])\n</code></pre>"},{"location":"api/games/#hypershap.games.OptimizerBiasGame.__init__","title":"<code>__init__(explanation_task, n_workers=None, verbose=None)</code>","text":"<p>Initialize an instance of <code>OptimizerBiasGame</code>.</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>OptimizerBiasExplanationTask</code> <p>The task that contains all necessary information for defining the game. This includes the configuration space, the surrogate model, the optimizer of interest, and the ensemble of diverse optimizers.</p> required <code>n_workers</code> <code>int | None</code> <p>The number of worker threads to use for parallel evaluation of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.</p> <code>None</code> <code>verbose</code> <code>bool | None</code> <p>A boolean indicating whether to print verbose messages during computation. Defaults to None.  When set to True, the method prints debugging information and progress updates.</p> <code>None</code> Example <p>from hypershap.task import OptimizerBiasExplanationTask</p> Source code in <code>src/hypershap/games/optimizerbias.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: OptimizerBiasExplanationTask,\n    n_workers: int | None = None,\n    verbose: bool | None = None,\n) -&gt; None:\n    \"\"\"Initialize an instance of `OptimizerBiasGame`.\n\n    Args:\n        explanation_task (OptimizerBiasExplanationTask): The task that contains all necessary\n            information for defining the game. This includes the configuration space, the surrogate model, the\n            optimizer of interest, and the ensemble of diverse optimizers.\n        n_workers: The number of worker threads to use for parallel evaluation\n            of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n            speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n        verbose:  A boolean indicating whether to print verbose messages during\n            computation. Defaults to None.  When set to True, the method prints\n            debugging information and progress updates.\n\n    Example:\n        &gt;&gt;&gt; from hypershap.task import OptimizerBiasExplanationTask\n        &gt;&gt;&gt; # Create an explanation task instance with specific parameters\n        &gt;&gt;&gt; expl_task = OptimizerBiasExplanationTask(...)\n        &gt;&gt;&gt; game = OptimizerBiasGame(expl_task)\n\n    \"\"\"\n    super().__init__(explanation_task, n_workers=n_workers, verbose=verbose)\n</code></pre>"},{"location":"api/games/#hypershap.games.OptimizerBiasGame.__init__--create-an-explanation-task-instance-with-specific-parameters","title":"Create an explanation task instance with specific parameters","text":"<p>expl_task = OptimizerBiasExplanationTask(...) game = OptimizerBiasGame(expl_task)</p>"},{"location":"api/games/#hypershap.games.OptimizerBiasGame.evaluate_single_coalition","title":"<code>evaluate_single_coalition(coalition)</code>","text":"<p>Evaluate a single coalition by comparing against an optimizer ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>coalition</code> <code>ndarray</code> <p>A binary array indicating which hyperparameters are included in the coalition. The array has shape (n_hyperparameters,) where True means hyperparameters is included and False  otherwise.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The marginal contribution of the coalition. It is computed as the difference between the outcome when using the optimizer of interest with the given coalition, versus the best outcome achievable by any optimizer in the ensemble (including the one of interest).</p> Note <p>This method overrides a base class abstract method and must be implemented to provide specific game logic. The value returned here is used for computing Shapley values or other cooperative game theory measures.</p> Example <p>coalition = np.array([1, 0, 1])  # Hyperparameters 0 and 2 are included marginal_contribution = game.evaluate_single_coalition(coalition) print(marginal_contribution)  # Outputs the difference in outcomes for this coalition.</p> Source code in <code>src/hypershap/games/optimizerbias.py</code> <pre><code>def evaluate_single_coalition(self, coalition: np.ndarray) -&gt; float:\n    \"\"\"Evaluate a single coalition by comparing against an optimizer ensemble.\n\n    Args:\n        coalition (np.ndarray): A binary array indicating which hyperparameters are included in the coalition.\n            The array has shape (n_hyperparameters,) where True means hyperparameters is included and False\n             otherwise.\n\n    Returns:\n        float: The marginal contribution of the coalition. It is computed as the difference between\n            the outcome when using the optimizer of interest with the given coalition, versus the best outcome\n            achievable by any optimizer in the ensemble (including the one of interest).\n\n    Note:\n        This method overrides a base class abstract method and must be implemented to provide specific game logic.\n        The value returned here is used for computing Shapley values or other cooperative game theory measures.\n\n    Example:\n        &gt;&gt;&gt; coalition = np.array([1, 0, 1])  # Hyperparameters 0 and 2 are included\n        &gt;&gt;&gt; marginal_contribution = game.evaluate_single_coalition(coalition)\n        &gt;&gt;&gt; print(marginal_contribution)  # Outputs the difference in outcomes for this coalition.\n\n    \"\"\"\n    optimizer_res = self._get_explanation_task().optimizer_of_interest.search(coalition)\n    optimizer_ensemble_res = [\n        optimizer.search(coalition) for optimizer in self._get_explanation_task().optimizer_ensemble\n    ]\n    return optimizer_res - max([*optimizer_ensemble_res, optimizer_res])\n</code></pre>"},{"location":"api/games/#hypershap.games.SearchBasedGame","title":"<code>SearchBasedGame</code>","text":"<p>               Bases: <code>AbstractHPIGame</code></p> <p>Base class for games that rely on searching the configuration space.</p> Source code in <code>src/hypershap/games/tunability.py</code> <pre><code>class SearchBasedGame(AbstractHPIGame):\n    \"\"\"Base class for games that rely on searching the configuration space.\"\"\"\n\n    def __init__(\n        self,\n        explanation_task: BaselineExplanationTask,\n        cs_searcher: ConfigSpaceSearcher,\n        n_workers: int | None = None,\n        verbose: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize the search-based game.\n\n        Args:\n            explanation_task: The explanation task containing the configuration\n                space and surrogate model.\n            cs_searcher: The configuration space searcher. If None, a\n                RandomConfigSpaceSearcher is used by default.\n            n_workers: The number of worker threads to use for parallel evaluation\n                of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n                speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n            verbose:  A boolean indicating whether to print verbose messages during\n                computation. Defaults to None.  When set to True, the method prints\n                debugging information and progress updates.\n\n        \"\"\"\n        self.cs_searcher = cs_searcher\n        super().__init__(explanation_task, n_workers=n_workers, verbose=verbose)\n\n    def evaluate_single_coalition(self, coalition: np.ndarray) -&gt; float:\n        \"\"\"Evaluate the value of a single coalition using the configuration space searcher.\n\n        Args:\n            coalition: A boolean array indicating which hyperparameters are\n                constrained by the coalition.\n\n        Returns:\n            The value of the coalition based on the search results.\n\n        \"\"\"\n        return self.cs_searcher.search(coalition)\n</code></pre>"},{"location":"api/games/#hypershap.games.SearchBasedGame.__init__","title":"<code>__init__(explanation_task, cs_searcher, n_workers=None, verbose=None)</code>","text":"<p>Initialize the search-based game.</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>BaselineExplanationTask</code> <p>The explanation task containing the configuration space and surrogate model.</p> required <code>cs_searcher</code> <code>ConfigSpaceSearcher</code> <p>The configuration space searcher. If None, a RandomConfigSpaceSearcher is used by default.</p> required <code>n_workers</code> <code>int | None</code> <p>The number of worker threads to use for parallel evaluation of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.</p> <code>None</code> <code>verbose</code> <code>bool | None</code> <p>A boolean indicating whether to print verbose messages during computation. Defaults to None.  When set to True, the method prints debugging information and progress updates.</p> <code>None</code> Source code in <code>src/hypershap/games/tunability.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: BaselineExplanationTask,\n    cs_searcher: ConfigSpaceSearcher,\n    n_workers: int | None = None,\n    verbose: bool | None = None,\n) -&gt; None:\n    \"\"\"Initialize the search-based game.\n\n    Args:\n        explanation_task: The explanation task containing the configuration\n            space and surrogate model.\n        cs_searcher: The configuration space searcher. If None, a\n            RandomConfigSpaceSearcher is used by default.\n        n_workers: The number of worker threads to use for parallel evaluation\n            of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n            speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n        verbose:  A boolean indicating whether to print verbose messages during\n            computation. Defaults to None.  When set to True, the method prints\n            debugging information and progress updates.\n\n    \"\"\"\n    self.cs_searcher = cs_searcher\n    super().__init__(explanation_task, n_workers=n_workers, verbose=verbose)\n</code></pre>"},{"location":"api/games/#hypershap.games.SearchBasedGame.evaluate_single_coalition","title":"<code>evaluate_single_coalition(coalition)</code>","text":"<p>Evaluate the value of a single coalition using the configuration space searcher.</p> <p>Parameters:</p> Name Type Description Default <code>coalition</code> <code>ndarray</code> <p>A boolean array indicating which hyperparameters are constrained by the coalition.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The value of the coalition based on the search results.</p> Source code in <code>src/hypershap/games/tunability.py</code> <pre><code>def evaluate_single_coalition(self, coalition: np.ndarray) -&gt; float:\n    \"\"\"Evaluate the value of a single coalition using the configuration space searcher.\n\n    Args:\n        coalition: A boolean array indicating which hyperparameters are\n            constrained by the coalition.\n\n    Returns:\n        The value of the coalition based on the search results.\n\n    \"\"\"\n    return self.cs_searcher.search(coalition)\n</code></pre>"},{"location":"api/games/#hypershap.games.SensitivityGame","title":"<code>SensitivityGame</code>","text":"<p>               Bases: <code>SearchBasedGame</code></p> <p>Game representing the sensitivity of hyperparameters.</p> Source code in <code>src/hypershap/games/tunability.py</code> <pre><code>class SensitivityGame(SearchBasedGame):\n    \"\"\"Game representing the sensitivity of hyperparameters.\"\"\"\n\n    def __init__(\n        self,\n        explanation_task: SensitivityExplanationTask,\n        cs_searcher: ConfigSpaceSearcher | None = None,\n        n_workers: int | None = None,\n        verbose: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize the sensitivity game.\n\n        Args:\n            explanation_task: The explanation task containing the configuration\n                space and surrogate model.\n            cs_searcher: The configuration space searcher. If None, a\n                RandomConfigSpaceSearcher is used by default.\n            n_workers: The number of worker threads to use for parallel evaluation\n                of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n                speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n            verbose:  A boolean indicating whether to print verbose messages during\n                computation. Defaults to None.  When set to True, the method prints\n                debugging information and progress updates.\n\n        \"\"\"\n        # set cs searcher if not given by default to a random config space searcher.\n        if cs_searcher is None:\n            cs_searcher = RandomConfigSpaceSearcher(explanation_task, mode=Aggregation.VAR)\n        elif cs_searcher.mode != Aggregation.VAR:  # ensure that cs_searcher is maximizing\n            logger.warning(\"WARN: Sensitivity game set mode of given ConfigSpaceSearcher to variance.\")\n            cs_searcher.mode = Aggregation.VAR\n\n        super().__init__(explanation_task, cs_searcher, n_workers=n_workers, verbose=verbose)\n</code></pre>"},{"location":"api/games/#hypershap.games.SensitivityGame.__init__","title":"<code>__init__(explanation_task, cs_searcher=None, n_workers=None, verbose=None)</code>","text":"<p>Initialize the sensitivity game.</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>SensitivityExplanationTask</code> <p>The explanation task containing the configuration space and surrogate model.</p> required <code>cs_searcher</code> <code>ConfigSpaceSearcher | None</code> <p>The configuration space searcher. If None, a RandomConfigSpaceSearcher is used by default.</p> <code>None</code> <code>n_workers</code> <code>int | None</code> <p>The number of worker threads to use for parallel evaluation of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.</p> <code>None</code> <code>verbose</code> <code>bool | None</code> <p>A boolean indicating whether to print verbose messages during computation. Defaults to None.  When set to True, the method prints debugging information and progress updates.</p> <code>None</code> Source code in <code>src/hypershap/games/tunability.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: SensitivityExplanationTask,\n    cs_searcher: ConfigSpaceSearcher | None = None,\n    n_workers: int | None = None,\n    verbose: bool | None = None,\n) -&gt; None:\n    \"\"\"Initialize the sensitivity game.\n\n    Args:\n        explanation_task: The explanation task containing the configuration\n            space and surrogate model.\n        cs_searcher: The configuration space searcher. If None, a\n            RandomConfigSpaceSearcher is used by default.\n        n_workers: The number of worker threads to use for parallel evaluation\n            of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n            speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n        verbose:  A boolean indicating whether to print verbose messages during\n            computation. Defaults to None.  When set to True, the method prints\n            debugging information and progress updates.\n\n    \"\"\"\n    # set cs searcher if not given by default to a random config space searcher.\n    if cs_searcher is None:\n        cs_searcher = RandomConfigSpaceSearcher(explanation_task, mode=Aggregation.VAR)\n    elif cs_searcher.mode != Aggregation.VAR:  # ensure that cs_searcher is maximizing\n        logger.warning(\"WARN: Sensitivity game set mode of given ConfigSpaceSearcher to variance.\")\n        cs_searcher.mode = Aggregation.VAR\n\n    super().__init__(explanation_task, cs_searcher, n_workers=n_workers, verbose=verbose)\n</code></pre>"},{"location":"api/games/#hypershap.games.TunabilityGame","title":"<code>TunabilityGame</code>","text":"<p>               Bases: <code>SearchBasedGame</code></p> <p>Game representing the tunability of hyperparameters.</p> Source code in <code>src/hypershap/games/tunability.py</code> <pre><code>class TunabilityGame(SearchBasedGame):\n    \"\"\"Game representing the tunability of hyperparameters.\"\"\"\n\n    def __init__(\n        self,\n        explanation_task: TunabilityExplanationTask,\n        cs_searcher: ConfigSpaceSearcher | None = None,\n        n_workers: int | None = None,\n        verbose: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize the tunability game.\n\n        Args:\n            explanation_task: The explanation task containing the configuration\n                space and surrogate model.\n            cs_searcher: The configuration space searcher. If None, a\n                RandomConfigSpaceSearcher is used by default.\n            n_workers: The number of worker threads to use for parallel evaluation\n                of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n                speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n            verbose:  A boolean indicating whether to print verbose messages during\n                computation. Defaults to None.  When set to True, the method prints\n                debugging information and progress updates.\n\n        \"\"\"\n        # set cs searcher if not given by default to a random config space searcher.\n        if cs_searcher is None:\n            cs_searcher = RandomConfigSpaceSearcher(explanation_task, mode=Aggregation.MAX)\n        elif cs_searcher.mode != Aggregation.MAX:  # ensure that cs_searcher is maximizing\n            logger.warning(\"WARN: Tunability game set mode of given ConfigSpaceSearcher to maximize.\")\n            cs_searcher.mode = Aggregation.MAX\n        super().__init__(explanation_task, cs_searcher, n_workers=n_workers, verbose=verbose)\n</code></pre>"},{"location":"api/games/#hypershap.games.TunabilityGame.__init__","title":"<code>__init__(explanation_task, cs_searcher=None, n_workers=None, verbose=None)</code>","text":"<p>Initialize the tunability game.</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>TunabilityExplanationTask</code> <p>The explanation task containing the configuration space and surrogate model.</p> required <code>cs_searcher</code> <code>ConfigSpaceSearcher | None</code> <p>The configuration space searcher. If None, a RandomConfigSpaceSearcher is used by default.</p> <code>None</code> <code>n_workers</code> <code>int | None</code> <p>The number of worker threads to use for parallel evaluation of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.</p> <code>None</code> <code>verbose</code> <code>bool | None</code> <p>A boolean indicating whether to print verbose messages during computation. Defaults to None.  When set to True, the method prints debugging information and progress updates.</p> <code>None</code> Source code in <code>src/hypershap/games/tunability.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: TunabilityExplanationTask,\n    cs_searcher: ConfigSpaceSearcher | None = None,\n    n_workers: int | None = None,\n    verbose: bool | None = None,\n) -&gt; None:\n    \"\"\"Initialize the tunability game.\n\n    Args:\n        explanation_task: The explanation task containing the configuration\n            space and surrogate model.\n        cs_searcher: The configuration space searcher. If None, a\n            RandomConfigSpaceSearcher is used by default.\n        n_workers: The number of worker threads to use for parallel evaluation\n            of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n            speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n        verbose:  A boolean indicating whether to print verbose messages during\n            computation. Defaults to None.  When set to True, the method prints\n            debugging information and progress updates.\n\n    \"\"\"\n    # set cs searcher if not given by default to a random config space searcher.\n    if cs_searcher is None:\n        cs_searcher = RandomConfigSpaceSearcher(explanation_task, mode=Aggregation.MAX)\n    elif cs_searcher.mode != Aggregation.MAX:  # ensure that cs_searcher is maximizing\n        logger.warning(\"WARN: Tunability game set mode of given ConfigSpaceSearcher to maximize.\")\n        cs_searcher.mode = Aggregation.MAX\n    super().__init__(explanation_task, cs_searcher, n_workers=n_workers, verbose=verbose)\n</code></pre>"},{"location":"api/hypershap/","title":"HyperSHAP","text":"<p>HyperSHAP main interface to work on explanation for a given task.</p> <p>This module provides the main interface for working with HyperSHAP to access explanations regarding ablation, tunability, sensitivity, and optimizer bias.</p>"},{"location":"api/hypershap/#hypershap.hypershap.HyperSHAP","title":"<code>HyperSHAP</code>","text":"<p>A class for computing and visualizing HyperSHAP Shapley values and interactions.</p> <p>Attributes:</p> Name Type Description <code>explanation_task</code> <code>ExplanationTask</code> <p>The task responsible for generating explanations.</p> <code>last_interaction_values</code> <code>InteractionValues | None</code> <p>The cached interaction values for plotting shortcuts.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>ExplanationTask): Initializes the HyperSHAP instance with an explanation task.</p> <code>ablation</code> <p>Configuration, baseline_config: Configuration, index: ValidApproximationIndices = \"FSII\", order: int = 2) -&gt; InteractionValues: Computes and returns the interaction values for ablation analysis.</p> <code>tunability</code> <p>Configuration | None, index: ValidApproximationIndices = \"FSII\", order: int = 2) -&gt; InteractionValues: Computes and returns the interaction values for tunability analysis.</p> <code>optimizer_bias</code> <p>ConfigSpaceSearcher, optimizer_ensemble: list[ConfigSpaceSearcher], index: ValidApproximationIndices = \"FSII\", order: int = 2) -&gt; InteractionValues: Computes and returns the interaction values for optimizer bias analysis.</p> <code>plot_si_graph</code> <p>InteractionValues | None = None, save_path: str | None = None): Plots the SHAP interaction values as a graph.</p> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>class HyperSHAP:\n    \"\"\"A class for computing and visualizing HyperSHAP Shapley values and interactions.\n\n    Attributes:\n        explanation_task (ExplanationTask): The task responsible for generating explanations.\n        last_interaction_values (InteractionValues | None): The cached interaction values for plotting shortcuts.\n\n    Methods:\n        __init__(explanation_task: ExplanationTask):\n            Initializes the HyperSHAP instance with an explanation task.\n\n        ablation(config_of_interest: Configuration, baseline_config: Configuration, index: ValidApproximationIndices = \"FSII\", order: int = 2) -&gt; InteractionValues:\n            Computes and returns the interaction values for ablation analysis.\n\n        tunability(baseline_config: Configuration | None, index: ValidApproximationIndices = \"FSII\", order: int = 2) -&gt; InteractionValues:\n            Computes and returns the interaction values for tunability analysis.\n\n        optimizer_bias(optimizer_of_interest: ConfigSpaceSearcher, optimizer_ensemble: list[ConfigSpaceSearcher], index: ValidApproximationIndices = \"FSII\", order: int = 2) -&gt; InteractionValues:\n            Computes and returns the interaction values for optimizer bias analysis.\n\n        plot_si_graph(interaction_values: InteractionValues | None = None, save_path: str | None = None):\n            Plots the SHAP interaction values as a graph.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        explanation_task: ExplanationTask,\n        n_workers: int | None = None,\n        max_hyperparameters_exact: int | None = None,\n        approximation_budget: int | None = None,\n        verbose: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize the HyperSHAP instance with an explanation task.\n\n        Args:\n            explanation_task (ExplanationTask): The task responsible for generating explanations.\n            n_workers: The number of worker threads to use for parallel evaluation\n                of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n                speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n            max_hyperparameters_exact: The maximum number of hyperparameters to compute exactly. Defaults to 14. If this number of\n                hyperparameters is exceeded, the Shapley values and interactions will be approximated by a sampling method with a\n                budget set via `approximation_budget`.\n            approximation_budget: The budget to be used for approximating Shapley values when the number of hyperparameters exceeds\n                the maximum number of hyperparameters for computing exact values. Defaults to 2**14.\n            verbose:  A boolean indicating whether to print verbose messages during\n                computation. Defaults to None.  When set to True, the method prints\n                debugging information and progress updates.\n\n        \"\"\"\n        self.explanation_task = explanation_task\n        self.last_interaction_values = None\n        self.n_workers = n_workers\n        self.max_hyperparameters_exact = (\n            max_hyperparameters_exact if max_hyperparameters_exact is not None else EXACT_MAX_HYPERPARAMETERS\n        )\n        self.approximation_budget = (\n            approximation_budget if approximation_budget is not None else 2**EXACT_MAX_HYPERPARAMETERS\n        )\n        self.verbose = verbose\n\n    def __get_interaction_values(\n        self,\n        game: AbstractHPIGame,\n        index: ValidApproximationIndices = \"FSII\",\n        order: int = 2,\n        seed: int | None = 0,\n    ) -&gt; InteractionValues:\n        if game.n_players &lt;= EXACT_MAX_HYPERPARAMETERS:\n            # instantiate exact computer if number of hyperparameters is small enough\n            ec = ExactComputer(n_players=game.get_num_hyperparameters(), game=game)  # pyright: ignore\n\n            # compute interaction values with the given index and order\n            interaction_values = ec(index=index, order=order)\n        else:\n            # instantiate approximator\n            approx = setup_approximator_automatically(index, order, game.n_players, seed)\n\n            # approximate interaction values with the given index and order\n            interaction_values = approx(budget=self.approximation_budget, game=game)\n\n        # cache current interaction values for plotting shortcuts\n        self.last_interaction_values = interaction_values\n\n        return interaction_values\n\n    def ablation(\n        self,\n        config_of_interest: Configuration,\n        baseline_config: Configuration,\n        index: ValidApproximationIndices = \"FSII\",\n        order: int = 2,\n    ) -&gt; InteractionValues:\n        \"\"\"Compute and return the interaction values for ablation analysis.\n\n        Args:\n            config_of_interest (Configuration): The configuration of interest.\n            baseline_config (Configuration): The baseline configuration.\n            index (ValidApproximationIndices, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n            order (int, optional): The order of the interaction values. Defaults to 2.\n\n        Returns:\n            InteractionValues: The computed interaction values.\n\n        \"\"\"\n        # setup explanation task\n        if isinstance(self.explanation_task.surrogate_model, list):\n            surrogate_model = self.explanation_task.surrogate_model[0]\n        else:\n            surrogate_model = self.explanation_task.surrogate_model\n\n        ablation_task: AblationExplanationTask = AblationExplanationTask(\n            config_space=self.explanation_task.config_space,\n            surrogate_model=surrogate_model,\n            baseline_config=baseline_config,\n            config_of_interest=config_of_interest,\n        )\n\n        # setup ablation game and get interaction values\n        ag = AblationGame(\n            explanation_task=ablation_task,\n            n_workers=self.n_workers,\n            verbose=self.verbose,\n        )\n\n        if self.explanation_task.is_multi_data():\n            ag = MultiDataHPIGame(\n                explanation_task=self.explanation_task,\n                base_game=ag,\n                aggregation=Aggregation.AVG,\n            )\n\n        return self.__get_interaction_values(game=ag, index=index, order=order)\n\n    def ablation_multibaseline(\n        self,\n        config_of_interest: Configuration,\n        baseline_configs: list[Configuration],\n        aggregation: Aggregation = Aggregation.AVG,\n        index: ValidApproximationIndices = \"FSII\",\n        order: int = 2,\n    ) -&gt; InteractionValues:\n        \"\"\"Compute and return the interaction values for multi-baseline ablation analysis.\n\n        Args:\n            config_of_interest (Configuration): The configuration of interest.\n            baseline_configs (list[Configuration]): The list of baseline configurations.\n            aggregation (Aggregation): The aggregation method to use for computing interaction values.\n            index (ValidApproximationIndices, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n            order (int, optional): The order of the interaction values. Defaults to 2.\n\n        Returns:\n            InteractionValues: The computed interaction values.\n\n        \"\"\"\n        if isinstance(self.explanation_task.surrogate_model, list):\n            surrogate_model = self.explanation_task.surrogate_model[0]\n        else:\n            surrogate_model = self.explanation_task.surrogate_model\n\n        # setup explanation task\n        multibaseline_ablation_task = MultiBaselineAblationExplanationTask(\n            config_space=self.explanation_task.config_space,\n            surrogate_model=surrogate_model,\n            baseline_configs=baseline_configs,\n            config_of_interest=config_of_interest,\n        )\n\n        # setup ablation game and get interaction values\n        ag = MultiBaselineAblationGame(\n            explanation_task=multibaseline_ablation_task,\n            aggregation=aggregation,\n            n_workers=self.n_workers,\n            verbose=self.verbose,\n        )\n\n        if self.explanation_task.is_multi_data():\n            ag = MultiDataHPIGame(\n                explanation_task=self.explanation_task,\n                base_game=ag,\n                aggregation=Aggregation.AVG,\n            )\n\n        return self.__get_interaction_values(game=ag, index=index, order=order)\n\n    def tunability(\n        self,\n        baseline_config: Configuration | None = None,\n        index: ValidApproximationIndices = \"FSII\",\n        order: int = 2,\n        n_samples: int = 10_000,\n        seed: int | None = 0,\n    ) -&gt; InteractionValues:\n        \"\"\"Compute and return the interaction values for tunability analysis.\n\n        Args:\n            baseline_config (Configuration | None, optional): The baseline configuration. Defaults to None.\n            index (str, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n            order (int, optional): The order of the interaction values. Defaults to 2.\n            n_samples (int, optional): The number of samples to use for simulating HPO. Defaults to 10_000.\n            seed (int, optiona): The random seed for simulating HPO. Defaults to 0.\n\n        Returns:\n            InteractionValues: The computed interaction values.\n\n        \"\"\"\n        if baseline_config is None:\n            baseline_config = self.explanation_task.config_space.get_default_configuration()\n\n        if isinstance(self.explanation_task.surrogate_model, list):\n            surrogate_model = self.explanation_task.surrogate_model[0]\n        else:\n            surrogate_model = self.explanation_task.surrogate_model\n\n        # setup explanation task\n        tunability_task: TunabilityExplanationTask = TunabilityExplanationTask(\n            config_space=self.explanation_task.config_space,\n            surrogate_model=surrogate_model,\n            baseline_config=baseline_config,\n        )\n\n        # setup tunability game and get interaction values\n        tg = TunabilityGame(\n            explanation_task=tunability_task,\n            cs_searcher=RandomConfigSpaceSearcher(\n                explanation_task=tunability_task,\n                n_samples=n_samples,\n                mode=Aggregation.MAX,\n                seed=seed,\n            ),\n            n_workers=self.n_workers,\n            verbose=self.verbose,\n        )\n\n        if self.explanation_task.is_multi_data():\n            tg = MultiDataHPIGame(\n                explanation_task=self.explanation_task,\n                base_game=tg,\n                aggregation=Aggregation.AVG,\n            )\n\n        return self.__get_interaction_values(game=tg, index=index, order=order)\n\n    def sensitivity(\n        self,\n        baseline_config: Configuration | None = None,\n        index: ValidApproximationIndices = \"FSII\",\n        order: int = 2,\n        n_samples: int = 10_000,\n        seed: int | None = 0,\n    ) -&gt; InteractionValues:\n        \"\"\"Compute and return the interaction values for sensitivity analysis.\n\n        Args:\n            baseline_config (Configuration | None, optional): The baseline configuration. Defaults to None.\n            index (str, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n            order (int, optional): The order of the interaction values. Defaults to 2.\n            n_samples (int, optional): The number of samples to use for simulating HPO. Defaults to 10_000.\n            seed (int, optiona): The random seed for simulating HPO. Defaults to 0.\n\n        Returns:\n            InteractionValues: The computed interaction values.\n\n        \"\"\"\n        if baseline_config is None:\n            baseline_config = self.explanation_task.config_space.get_default_configuration()\n\n        if isinstance(self.explanation_task.surrogate_model, list):\n            surrogate_model = self.explanation_task.surrogate_model[0]\n        else:\n            surrogate_model = self.explanation_task.surrogate_model\n\n        # setup explanation task\n        sensitivity_task: SensitivityExplanationTask = SensitivityExplanationTask(\n            config_space=self.explanation_task.config_space,\n            surrogate_model=surrogate_model,\n            baseline_config=baseline_config,\n        )\n\n        # setup tunability game and get interaction values\n        tg = SensitivityGame(\n            explanation_task=sensitivity_task,\n            cs_searcher=RandomConfigSpaceSearcher(\n                explanation_task=sensitivity_task,\n                n_samples=n_samples,\n                mode=Aggregation.VAR,\n                seed=seed,\n            ),\n            n_workers=self.n_workers,\n            verbose=self.verbose,\n        )\n\n        if self.explanation_task.is_multi_data():\n            tg = MultiDataHPIGame(\n                explanation_task=self.explanation_task,\n                base_game=tg,\n                aggregation=Aggregation.AVG,\n            )\n\n        return self.__get_interaction_values(game=tg, index=index, order=order)\n\n    def mistunability(\n        self,\n        baseline_config: Configuration | None = None,\n        index: ValidApproximationIndices = \"FSII\",\n        order: int = 2,\n        n_samples: int = 10_000,\n        seed: int | None = 0,\n    ) -&gt; InteractionValues:\n        \"\"\"Compute and return the interaction values for mistunability analysis.\n\n        Args:\n            baseline_config (Configuration | None, optional): The baseline configuration. Defaults to None.\n            index (ValidApproximationIndices, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n            order (int, optional): The order of the interaction values. Defaults to 2.\n            n_samples (int, optional): The number of samples to use for simulating HPO. Defaults to 10_000.\n            seed (int, optiona): The random seed for simulating HPO. Defaults to 0.\n\n        Returns:\n            InteractionValues: The computed interaction values.\n\n        \"\"\"\n        if baseline_config is None:\n            baseline_config = self.explanation_task.config_space.get_default_configuration()\n\n        if isinstance(self.explanation_task.surrogate_model, list):\n            surrogate_model = self.explanation_task.surrogate_model[0]\n        else:\n            surrogate_model = self.explanation_task.surrogate_model\n\n        # setup explanation task\n        mistunability_task: MistunabilityExplanationTask = MistunabilityExplanationTask(\n            config_space=self.explanation_task.config_space,\n            surrogate_model=surrogate_model,\n            baseline_config=baseline_config,\n        )\n\n        # setup tunability game and get interaction values\n        tg = MistunabilityGame(\n            explanation_task=mistunability_task,\n            cs_searcher=RandomConfigSpaceSearcher(\n                explanation_task=mistunability_task,\n                n_samples=n_samples,\n                mode=Aggregation.MIN,\n                seed=seed,\n            ),\n            n_workers=self.n_workers,\n            verbose=self.verbose,\n        )\n\n        if self.explanation_task.is_multi_data():\n            tg = MultiDataHPIGame(\n                explanation_task=self.explanation_task,\n                base_game=tg,\n                aggregation=Aggregation.AVG,\n            )\n        return self.__get_interaction_values(game=tg, index=index, order=order)\n\n    def optimizer_bias(\n        self,\n        optimizer_of_interest: ConfigSpaceSearcher,\n        optimizer_ensemble: list[ConfigSpaceSearcher],\n        index: ValidApproximationIndices = \"FSII\",\n        order: int = 2,\n    ) -&gt; InteractionValues:\n        \"\"\"Compute and return the interaction values for optimizer bias analysis.\n\n        Args:\n            optimizer_of_interest (ConfigSpaceSearcher): The optimizer of interest.\n            optimizer_ensemble (list[ConfigSpaceSearcher]): The ensemble of optimizers.\n            index (ValidApproximationIndices, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n            order (int, optional): The order of the interaction values. Defaults to 2.\n\n        Returns:\n            InteractionValues: The computed interaction values.\n\n        \"\"\"\n        # setup explanation task\n        optimizer_bias_task: OptimizerBiasExplanationTask = OptimizerBiasExplanationTask(\n            config_space=self.explanation_task.config_space,\n            surrogate_model=self.explanation_task.surrogate_model,\n            optimizer_of_interest=optimizer_of_interest,\n            optimizer_ensemble=optimizer_ensemble,\n        )\n\n        # setup optimizer bias game and get interaction values\n        og = OptimizerBiasGame(explanation_task=optimizer_bias_task, n_workers=self.n_workers, verbose=self.verbose)\n        return self.__get_interaction_values(game=og, index=index, order=order)\n\n    def get_interaction_values_with_names(self, iv: InteractionValues | None = None) -&gt; dict[tuple, float]:\n        \"\"\"Get the interaction values provided as argument or the last interaction values as a dict of hyperparameter names and their interaction values.\n\n        Args:\n            iv (InteractionValues | None): The interaction values to compute with.\n\n        Returns:\n            dict[Tuple, float]: A dictionary with a tuples of hyperparameter names as keys mapping to their interaction values.\n\n        \"\"\"\n        # prioritize given iv's over last interaction values stored in the object\n        iv = iv if iv is not None else self.last_interaction_values\n\n        # check whether we now have actually interaction values if not: nothing to get here\n        if not isinstance(iv, InteractionValues):  # pragma: no cover\n            raise TypeError  # pragma: no cover\n\n        iv_mapped = {}\n        for key, value in iv.dict_values.items():\n            names = []\n            if len(key) == 0:\n                iv_mapped[()] = value\n                continue\n            names = [self.explanation_task.get_hyperparameter_names()[k] for k in key]\n            iv_mapped[tuple(names)] = value\n        return iv_mapped\n\n    def plot_si_graph(\n        self,\n        interaction_values: InteractionValues | None = None,\n        save_path: str | None = None,\n        no_show: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Plot the SHAP interaction values as a graph.\n\n        Args:\n            interaction_values (InteractionValues | None, optional): The interaction values to plot. Defaults to None.\n            save_path (str | None, optional): The path to save the plot. Defaults to None.\n            no_show (bool | None, optional): Do not show the plot if set to true. Defaults to None.\n\n        \"\"\"\n        if interaction_values is None and self.last_interaction_values is None:\n            raise NoInteractionValuesError\n\n        # if given interaction values use those, else use cached interaction values\n        iv = interaction_values if interaction_values is not None else self.last_interaction_values\n\n        if not isinstance(iv, InteractionValues):  # pragma: no cover\n            raise TypeError  # pragma: no cover\n\n        hyperparameter_names = self.explanation_task.get_hyperparameter_names()\n\n        def get_circular_layout(n_players: int) -&gt; dict:\n            original_graph, graph_nodes = nx.Graph(), []\n            for i in range(n_players):\n                original_graph.add_node(i, label=i)\n                graph_nodes.append(i)\n            return nx.circular_layout(original_graph)\n\n        pos = get_circular_layout(n_players=self.explanation_task.get_num_hyperparameters())\n        iv.plot_si_graph(\n            show=False,\n            size_factor=3.0,\n            feature_names=hyperparameter_names,\n            pos=pos,\n            n_interactions=1_000,\n            compactness=1e50,\n        )\n        plt.tight_layout()\n\n        if save_path is not None:\n            plt.savefig(save_path)\n            logger.info(\"Saved SI graph to %s\", save_path)\n\n        if no_show is None or not no_show:  # pragma: no cover\n            plt.show()  # pragma: no cover\n\n    def plot_upset(\n        self,\n        interaction_values: InteractionValues | None = None,\n        save_path: str | None = None,\n        no_show: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Plot the SHAP interaction values as an upset plot graph.\n\n        Args:\n            interaction_values (InteractionValues | None, optional): The interaction values to plot. Defaults to None.\n            save_path (str | None, optional): The path to save the plot. Defaults to None.\n            no_show (bool | None, optional): Do not show the plot if set to true. Defaults to None.\n\n        \"\"\"\n        if interaction_values is None and self.last_interaction_values is None:\n            raise NoInteractionValuesError\n\n        # if given interaction values use those, else use cached interaction values\n        iv = interaction_values if interaction_values is not None else self.last_interaction_values\n\n        if not isinstance(iv, InteractionValues):  # pragma: no cover\n            raise TypeError  # pragma: no cover\n\n        hyperparameter_names = self.explanation_task.get_hyperparameter_names()\n\n        fig = iv.plot_upset(feature_names=hyperparameter_names, show=False)\n\n        if fig is None:  # pragma: no cover\n            raise TypeError  # pragma: no cover\n\n        ax = fig.get_axes()[0]\n        ax.set_ylabel(\"Performance Gain\")\n        # also add \"parameter\" to the y-axis label\n        ax = fig.get_axes()[1]\n        ax.set_ylabel(\"Hyperparameter\")\n\n        plt.tight_layout()\n\n        if save_path is not None:\n            plt.savefig(save_path)\n\n        if no_show is None or not no_show:  # pragma: no cover\n            plt.show()  # pragma: no cover\n\n    def plot_force(\n        self,\n        interaction_values: InteractionValues | None = None,\n        save_path: str | None = None,\n        no_show: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Plot the SHAP interaction values as a forceplot graph.\n\n        Args:\n            interaction_values: Interaction values to plot. Defaults to None.\n            save_path: The path to save the plot. Defaults to None.\n            no_show (bool | None, optional): Do not show the plot if set to true. Defaults to None.\n\n        \"\"\"\n        if interaction_values is None and self.last_interaction_values is None:\n            raise NoInteractionValuesError\n\n        # if given interaction values use those, else use cached interaction values\n        iv = interaction_values if interaction_values is not None else self.last_interaction_values\n\n        if not isinstance(iv, InteractionValues):  # pragma: no cover\n            raise TypeError  # pragma: no cover\n\n        hyperparameter_names = self.explanation_task.get_hyperparameter_names()\n\n        iv.plot_force(feature_names=np.array(hyperparameter_names), show=False)\n        plt.tight_layout()\n\n        if save_path is not None:\n            plt.savefig(save_path)\n\n        if no_show is None or not no_show:  # pragma: no cover\n            plt.show()  # pragma: no cover\n\n    def plot_waterfall(\n        self,\n        interaction_values: InteractionValues | None = None,\n        save_path: str | None = None,\n        no_show: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Plot the SHAP interaction values as a waterfall graph.\n\n        Args:\n            interaction_values: Interaction values to plot. Defaults to None.\n            save_path: The path to save the plot. Defaults to None.\n            no_show (bool | None, optional): Do not show the plot if set to true. Defaults to None.\n\n        \"\"\"\n        if interaction_values is None and self.last_interaction_values is None:\n            raise NoInteractionValuesError\n\n        # if given interaction values use those, else use cached interaction values\n        iv = interaction_values if interaction_values is not None else self.last_interaction_values\n\n        if not isinstance(iv, InteractionValues):  # pragma: no cover\n            raise TypeError  # pragma: no cover\n\n        hyperparameter_names = self.explanation_task.get_hyperparameter_names()\n\n        iv.plot_waterfall(feature_names=np.array(hyperparameter_names), show=False)\n        plt.tight_layout()\n\n        if save_path is not None:\n            plt.savefig(save_path)\n\n        if no_show is None or not no_show:  # pragma: no cover\n            plt.show()  # pragma: no cover\n\n    def plot_stacked_bar(\n        self,\n        interaction_values: InteractionValues | None = None,\n        save_path: str | None = None,\n        no_show: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Plot the SHAP interaction values as a stacked bar chart.\n\n        Args:\n            interaction_values: Interaction values to plot. Defaults to None.\n            save_path: The path to save the plot. Defaults to None.\n            no_show (bool | None, optional): Do not show the plot if set to true. Defaults to None.\n\n        \"\"\"\n        if interaction_values is None and self.last_interaction_values is None:\n            raise NoInteractionValuesError\n\n        # if given interaction values use those, else use cached interaction values\n        iv = interaction_values if interaction_values is not None else self.last_interaction_values\n\n        if not isinstance(iv, InteractionValues):  # pragma: no cover\n            raise TypeError  # pragma: no cover\n\n        hyperparameter_names = self.explanation_task.get_hyperparameter_names()\n\n        iv.plot_stacked_bar(feature_names=np.array(hyperparameter_names), show=False)\n        plt.tight_layout()\n\n        if save_path is not None:\n            plt.savefig(save_path)\n\n        if no_show is None or not no_show:  # pragma: no cover\n            plt.show()  # pragma: no cover\n</code></pre>"},{"location":"api/hypershap/#hypershap.hypershap.HyperSHAP.__init__","title":"<code>__init__(explanation_task, n_workers=None, max_hyperparameters_exact=None, approximation_budget=None, verbose=None)</code>","text":"<p>Initialize the HyperSHAP instance with an explanation task.</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>ExplanationTask</code> <p>The task responsible for generating explanations.</p> required <code>n_workers</code> <code>int | None</code> <p>The number of worker threads to use for parallel evaluation of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.</p> <code>None</code> <code>max_hyperparameters_exact</code> <code>int | None</code> <p>The maximum number of hyperparameters to compute exactly. Defaults to 14. If this number of hyperparameters is exceeded, the Shapley values and interactions will be approximated by a sampling method with a budget set via <code>approximation_budget</code>.</p> <code>None</code> <code>approximation_budget</code> <code>int | None</code> <p>The budget to be used for approximating Shapley values when the number of hyperparameters exceeds the maximum number of hyperparameters for computing exact values. Defaults to 2**14.</p> <code>None</code> <code>verbose</code> <code>bool | None</code> <p>A boolean indicating whether to print verbose messages during computation. Defaults to None.  When set to True, the method prints debugging information and progress updates.</p> <code>None</code> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: ExplanationTask,\n    n_workers: int | None = None,\n    max_hyperparameters_exact: int | None = None,\n    approximation_budget: int | None = None,\n    verbose: bool | None = None,\n) -&gt; None:\n    \"\"\"Initialize the HyperSHAP instance with an explanation task.\n\n    Args:\n        explanation_task (ExplanationTask): The task responsible for generating explanations.\n        n_workers: The number of worker threads to use for parallel evaluation\n            of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n            speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n        max_hyperparameters_exact: The maximum number of hyperparameters to compute exactly. Defaults to 14. If this number of\n            hyperparameters is exceeded, the Shapley values and interactions will be approximated by a sampling method with a\n            budget set via `approximation_budget`.\n        approximation_budget: The budget to be used for approximating Shapley values when the number of hyperparameters exceeds\n            the maximum number of hyperparameters for computing exact values. Defaults to 2**14.\n        verbose:  A boolean indicating whether to print verbose messages during\n            computation. Defaults to None.  When set to True, the method prints\n            debugging information and progress updates.\n\n    \"\"\"\n    self.explanation_task = explanation_task\n    self.last_interaction_values = None\n    self.n_workers = n_workers\n    self.max_hyperparameters_exact = (\n        max_hyperparameters_exact if max_hyperparameters_exact is not None else EXACT_MAX_HYPERPARAMETERS\n    )\n    self.approximation_budget = (\n        approximation_budget if approximation_budget is not None else 2**EXACT_MAX_HYPERPARAMETERS\n    )\n    self.verbose = verbose\n</code></pre>"},{"location":"api/hypershap/#hypershap.hypershap.HyperSHAP.ablation","title":"<code>ablation(config_of_interest, baseline_config, index='FSII', order=2)</code>","text":"<p>Compute and return the interaction values for ablation analysis.</p> <p>Parameters:</p> Name Type Description Default <code>config_of_interest</code> <code>Configuration</code> <p>The configuration of interest.</p> required <code>baseline_config</code> <code>Configuration</code> <p>The baseline configuration.</p> required <code>index</code> <code>ValidApproximationIndices</code> <p>The index to use for computing interaction values. Defaults to \"FSII\".</p> <code>'FSII'</code> <code>order</code> <code>int</code> <p>The order of the interaction values. Defaults to 2.</p> <code>2</code> <p>Returns:</p> Name Type Description <code>InteractionValues</code> <code>InteractionValues</code> <p>The computed interaction values.</p> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def ablation(\n    self,\n    config_of_interest: Configuration,\n    baseline_config: Configuration,\n    index: ValidApproximationIndices = \"FSII\",\n    order: int = 2,\n) -&gt; InteractionValues:\n    \"\"\"Compute and return the interaction values for ablation analysis.\n\n    Args:\n        config_of_interest (Configuration): The configuration of interest.\n        baseline_config (Configuration): The baseline configuration.\n        index (ValidApproximationIndices, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n        order (int, optional): The order of the interaction values. Defaults to 2.\n\n    Returns:\n        InteractionValues: The computed interaction values.\n\n    \"\"\"\n    # setup explanation task\n    if isinstance(self.explanation_task.surrogate_model, list):\n        surrogate_model = self.explanation_task.surrogate_model[0]\n    else:\n        surrogate_model = self.explanation_task.surrogate_model\n\n    ablation_task: AblationExplanationTask = AblationExplanationTask(\n        config_space=self.explanation_task.config_space,\n        surrogate_model=surrogate_model,\n        baseline_config=baseline_config,\n        config_of_interest=config_of_interest,\n    )\n\n    # setup ablation game and get interaction values\n    ag = AblationGame(\n        explanation_task=ablation_task,\n        n_workers=self.n_workers,\n        verbose=self.verbose,\n    )\n\n    if self.explanation_task.is_multi_data():\n        ag = MultiDataHPIGame(\n            explanation_task=self.explanation_task,\n            base_game=ag,\n            aggregation=Aggregation.AVG,\n        )\n\n    return self.__get_interaction_values(game=ag, index=index, order=order)\n</code></pre>"},{"location":"api/hypershap/#hypershap.hypershap.HyperSHAP.ablation_multibaseline","title":"<code>ablation_multibaseline(config_of_interest, baseline_configs, aggregation=Aggregation.AVG, index='FSII', order=2)</code>","text":"<p>Compute and return the interaction values for multi-baseline ablation analysis.</p> <p>Parameters:</p> Name Type Description Default <code>config_of_interest</code> <code>Configuration</code> <p>The configuration of interest.</p> required <code>baseline_configs</code> <code>list[Configuration]</code> <p>The list of baseline configurations.</p> required <code>aggregation</code> <code>Aggregation</code> <p>The aggregation method to use for computing interaction values.</p> <code>AVG</code> <code>index</code> <code>ValidApproximationIndices</code> <p>The index to use for computing interaction values. Defaults to \"FSII\".</p> <code>'FSII'</code> <code>order</code> <code>int</code> <p>The order of the interaction values. Defaults to 2.</p> <code>2</code> <p>Returns:</p> Name Type Description <code>InteractionValues</code> <code>InteractionValues</code> <p>The computed interaction values.</p> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def ablation_multibaseline(\n    self,\n    config_of_interest: Configuration,\n    baseline_configs: list[Configuration],\n    aggregation: Aggregation = Aggregation.AVG,\n    index: ValidApproximationIndices = \"FSII\",\n    order: int = 2,\n) -&gt; InteractionValues:\n    \"\"\"Compute and return the interaction values for multi-baseline ablation analysis.\n\n    Args:\n        config_of_interest (Configuration): The configuration of interest.\n        baseline_configs (list[Configuration]): The list of baseline configurations.\n        aggregation (Aggregation): The aggregation method to use for computing interaction values.\n        index (ValidApproximationIndices, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n        order (int, optional): The order of the interaction values. Defaults to 2.\n\n    Returns:\n        InteractionValues: The computed interaction values.\n\n    \"\"\"\n    if isinstance(self.explanation_task.surrogate_model, list):\n        surrogate_model = self.explanation_task.surrogate_model[0]\n    else:\n        surrogate_model = self.explanation_task.surrogate_model\n\n    # setup explanation task\n    multibaseline_ablation_task = MultiBaselineAblationExplanationTask(\n        config_space=self.explanation_task.config_space,\n        surrogate_model=surrogate_model,\n        baseline_configs=baseline_configs,\n        config_of_interest=config_of_interest,\n    )\n\n    # setup ablation game and get interaction values\n    ag = MultiBaselineAblationGame(\n        explanation_task=multibaseline_ablation_task,\n        aggregation=aggregation,\n        n_workers=self.n_workers,\n        verbose=self.verbose,\n    )\n\n    if self.explanation_task.is_multi_data():\n        ag = MultiDataHPIGame(\n            explanation_task=self.explanation_task,\n            base_game=ag,\n            aggregation=Aggregation.AVG,\n        )\n\n    return self.__get_interaction_values(game=ag, index=index, order=order)\n</code></pre>"},{"location":"api/hypershap/#hypershap.hypershap.HyperSHAP.get_interaction_values_with_names","title":"<code>get_interaction_values_with_names(iv=None)</code>","text":"<p>Get the interaction values provided as argument or the last interaction values as a dict of hyperparameter names and their interaction values.</p> <p>Parameters:</p> Name Type Description Default <code>iv</code> <code>InteractionValues | None</code> <p>The interaction values to compute with.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[tuple, float]</code> <p>dict[Tuple, float]: A dictionary with a tuples of hyperparameter names as keys mapping to their interaction values.</p> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def get_interaction_values_with_names(self, iv: InteractionValues | None = None) -&gt; dict[tuple, float]:\n    \"\"\"Get the interaction values provided as argument or the last interaction values as a dict of hyperparameter names and their interaction values.\n\n    Args:\n        iv (InteractionValues | None): The interaction values to compute with.\n\n    Returns:\n        dict[Tuple, float]: A dictionary with a tuples of hyperparameter names as keys mapping to their interaction values.\n\n    \"\"\"\n    # prioritize given iv's over last interaction values stored in the object\n    iv = iv if iv is not None else self.last_interaction_values\n\n    # check whether we now have actually interaction values if not: nothing to get here\n    if not isinstance(iv, InteractionValues):  # pragma: no cover\n        raise TypeError  # pragma: no cover\n\n    iv_mapped = {}\n    for key, value in iv.dict_values.items():\n        names = []\n        if len(key) == 0:\n            iv_mapped[()] = value\n            continue\n        names = [self.explanation_task.get_hyperparameter_names()[k] for k in key]\n        iv_mapped[tuple(names)] = value\n    return iv_mapped\n</code></pre>"},{"location":"api/hypershap/#hypershap.hypershap.HyperSHAP.mistunability","title":"<code>mistunability(baseline_config=None, index='FSII', order=2, n_samples=10000, seed=0)</code>","text":"<p>Compute and return the interaction values for mistunability analysis.</p> <p>Parameters:</p> Name Type Description Default <code>baseline_config</code> <code>Configuration | None</code> <p>The baseline configuration. Defaults to None.</p> <code>None</code> <code>index</code> <code>ValidApproximationIndices</code> <p>The index to use for computing interaction values. Defaults to \"FSII\".</p> <code>'FSII'</code> <code>order</code> <code>int</code> <p>The order of the interaction values. Defaults to 2.</p> <code>2</code> <code>n_samples</code> <code>int</code> <p>The number of samples to use for simulating HPO. Defaults to 10_000.</p> <code>10000</code> <code>seed</code> <code>(int, optiona)</code> <p>The random seed for simulating HPO. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Name Type Description <code>InteractionValues</code> <code>InteractionValues</code> <p>The computed interaction values.</p> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def mistunability(\n    self,\n    baseline_config: Configuration | None = None,\n    index: ValidApproximationIndices = \"FSII\",\n    order: int = 2,\n    n_samples: int = 10_000,\n    seed: int | None = 0,\n) -&gt; InteractionValues:\n    \"\"\"Compute and return the interaction values for mistunability analysis.\n\n    Args:\n        baseline_config (Configuration | None, optional): The baseline configuration. Defaults to None.\n        index (ValidApproximationIndices, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n        order (int, optional): The order of the interaction values. Defaults to 2.\n        n_samples (int, optional): The number of samples to use for simulating HPO. Defaults to 10_000.\n        seed (int, optiona): The random seed for simulating HPO. Defaults to 0.\n\n    Returns:\n        InteractionValues: The computed interaction values.\n\n    \"\"\"\n    if baseline_config is None:\n        baseline_config = self.explanation_task.config_space.get_default_configuration()\n\n    if isinstance(self.explanation_task.surrogate_model, list):\n        surrogate_model = self.explanation_task.surrogate_model[0]\n    else:\n        surrogate_model = self.explanation_task.surrogate_model\n\n    # setup explanation task\n    mistunability_task: MistunabilityExplanationTask = MistunabilityExplanationTask(\n        config_space=self.explanation_task.config_space,\n        surrogate_model=surrogate_model,\n        baseline_config=baseline_config,\n    )\n\n    # setup tunability game and get interaction values\n    tg = MistunabilityGame(\n        explanation_task=mistunability_task,\n        cs_searcher=RandomConfigSpaceSearcher(\n            explanation_task=mistunability_task,\n            n_samples=n_samples,\n            mode=Aggregation.MIN,\n            seed=seed,\n        ),\n        n_workers=self.n_workers,\n        verbose=self.verbose,\n    )\n\n    if self.explanation_task.is_multi_data():\n        tg = MultiDataHPIGame(\n            explanation_task=self.explanation_task,\n            base_game=tg,\n            aggregation=Aggregation.AVG,\n        )\n    return self.__get_interaction_values(game=tg, index=index, order=order)\n</code></pre>"},{"location":"api/hypershap/#hypershap.hypershap.HyperSHAP.optimizer_bias","title":"<code>optimizer_bias(optimizer_of_interest, optimizer_ensemble, index='FSII', order=2)</code>","text":"<p>Compute and return the interaction values for optimizer bias analysis.</p> <p>Parameters:</p> Name Type Description Default <code>optimizer_of_interest</code> <code>ConfigSpaceSearcher</code> <p>The optimizer of interest.</p> required <code>optimizer_ensemble</code> <code>list[ConfigSpaceSearcher]</code> <p>The ensemble of optimizers.</p> required <code>index</code> <code>ValidApproximationIndices</code> <p>The index to use for computing interaction values. Defaults to \"FSII\".</p> <code>'FSII'</code> <code>order</code> <code>int</code> <p>The order of the interaction values. Defaults to 2.</p> <code>2</code> <p>Returns:</p> Name Type Description <code>InteractionValues</code> <code>InteractionValues</code> <p>The computed interaction values.</p> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def optimizer_bias(\n    self,\n    optimizer_of_interest: ConfigSpaceSearcher,\n    optimizer_ensemble: list[ConfigSpaceSearcher],\n    index: ValidApproximationIndices = \"FSII\",\n    order: int = 2,\n) -&gt; InteractionValues:\n    \"\"\"Compute and return the interaction values for optimizer bias analysis.\n\n    Args:\n        optimizer_of_interest (ConfigSpaceSearcher): The optimizer of interest.\n        optimizer_ensemble (list[ConfigSpaceSearcher]): The ensemble of optimizers.\n        index (ValidApproximationIndices, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n        order (int, optional): The order of the interaction values. Defaults to 2.\n\n    Returns:\n        InteractionValues: The computed interaction values.\n\n    \"\"\"\n    # setup explanation task\n    optimizer_bias_task: OptimizerBiasExplanationTask = OptimizerBiasExplanationTask(\n        config_space=self.explanation_task.config_space,\n        surrogate_model=self.explanation_task.surrogate_model,\n        optimizer_of_interest=optimizer_of_interest,\n        optimizer_ensemble=optimizer_ensemble,\n    )\n\n    # setup optimizer bias game and get interaction values\n    og = OptimizerBiasGame(explanation_task=optimizer_bias_task, n_workers=self.n_workers, verbose=self.verbose)\n    return self.__get_interaction_values(game=og, index=index, order=order)\n</code></pre>"},{"location":"api/hypershap/#hypershap.hypershap.HyperSHAP.plot_force","title":"<code>plot_force(interaction_values=None, save_path=None, no_show=None)</code>","text":"<p>Plot the SHAP interaction values as a forceplot graph.</p> <p>Parameters:</p> Name Type Description Default <code>interaction_values</code> <code>InteractionValues | None</code> <p>Interaction values to plot. Defaults to None.</p> <code>None</code> <code>save_path</code> <code>str | None</code> <p>The path to save the plot. Defaults to None.</p> <code>None</code> <code>no_show</code> <code>bool | None</code> <p>Do not show the plot if set to true. Defaults to None.</p> <code>None</code> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def plot_force(\n    self,\n    interaction_values: InteractionValues | None = None,\n    save_path: str | None = None,\n    no_show: bool | None = None,\n) -&gt; None:\n    \"\"\"Plot the SHAP interaction values as a forceplot graph.\n\n    Args:\n        interaction_values: Interaction values to plot. Defaults to None.\n        save_path: The path to save the plot. Defaults to None.\n        no_show (bool | None, optional): Do not show the plot if set to true. Defaults to None.\n\n    \"\"\"\n    if interaction_values is None and self.last_interaction_values is None:\n        raise NoInteractionValuesError\n\n    # if given interaction values use those, else use cached interaction values\n    iv = interaction_values if interaction_values is not None else self.last_interaction_values\n\n    if not isinstance(iv, InteractionValues):  # pragma: no cover\n        raise TypeError  # pragma: no cover\n\n    hyperparameter_names = self.explanation_task.get_hyperparameter_names()\n\n    iv.plot_force(feature_names=np.array(hyperparameter_names), show=False)\n    plt.tight_layout()\n\n    if save_path is not None:\n        plt.savefig(save_path)\n\n    if no_show is None or not no_show:  # pragma: no cover\n        plt.show()  # pragma: no cover\n</code></pre>"},{"location":"api/hypershap/#hypershap.hypershap.HyperSHAP.plot_si_graph","title":"<code>plot_si_graph(interaction_values=None, save_path=None, no_show=None)</code>","text":"<p>Plot the SHAP interaction values as a graph.</p> <p>Parameters:</p> Name Type Description Default <code>interaction_values</code> <code>InteractionValues | None</code> <p>The interaction values to plot. Defaults to None.</p> <code>None</code> <code>save_path</code> <code>str | None</code> <p>The path to save the plot. Defaults to None.</p> <code>None</code> <code>no_show</code> <code>bool | None</code> <p>Do not show the plot if set to true. Defaults to None.</p> <code>None</code> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def plot_si_graph(\n    self,\n    interaction_values: InteractionValues | None = None,\n    save_path: str | None = None,\n    no_show: bool | None = None,\n) -&gt; None:\n    \"\"\"Plot the SHAP interaction values as a graph.\n\n    Args:\n        interaction_values (InteractionValues | None, optional): The interaction values to plot. Defaults to None.\n        save_path (str | None, optional): The path to save the plot. Defaults to None.\n        no_show (bool | None, optional): Do not show the plot if set to true. Defaults to None.\n\n    \"\"\"\n    if interaction_values is None and self.last_interaction_values is None:\n        raise NoInteractionValuesError\n\n    # if given interaction values use those, else use cached interaction values\n    iv = interaction_values if interaction_values is not None else self.last_interaction_values\n\n    if not isinstance(iv, InteractionValues):  # pragma: no cover\n        raise TypeError  # pragma: no cover\n\n    hyperparameter_names = self.explanation_task.get_hyperparameter_names()\n\n    def get_circular_layout(n_players: int) -&gt; dict:\n        original_graph, graph_nodes = nx.Graph(), []\n        for i in range(n_players):\n            original_graph.add_node(i, label=i)\n            graph_nodes.append(i)\n        return nx.circular_layout(original_graph)\n\n    pos = get_circular_layout(n_players=self.explanation_task.get_num_hyperparameters())\n    iv.plot_si_graph(\n        show=False,\n        size_factor=3.0,\n        feature_names=hyperparameter_names,\n        pos=pos,\n        n_interactions=1_000,\n        compactness=1e50,\n    )\n    plt.tight_layout()\n\n    if save_path is not None:\n        plt.savefig(save_path)\n        logger.info(\"Saved SI graph to %s\", save_path)\n\n    if no_show is None or not no_show:  # pragma: no cover\n        plt.show()  # pragma: no cover\n</code></pre>"},{"location":"api/hypershap/#hypershap.hypershap.HyperSHAP.plot_stacked_bar","title":"<code>plot_stacked_bar(interaction_values=None, save_path=None, no_show=None)</code>","text":"<p>Plot the SHAP interaction values as a stacked bar chart.</p> <p>Parameters:</p> Name Type Description Default <code>interaction_values</code> <code>InteractionValues | None</code> <p>Interaction values to plot. Defaults to None.</p> <code>None</code> <code>save_path</code> <code>str | None</code> <p>The path to save the plot. Defaults to None.</p> <code>None</code> <code>no_show</code> <code>bool | None</code> <p>Do not show the plot if set to true. Defaults to None.</p> <code>None</code> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def plot_stacked_bar(\n    self,\n    interaction_values: InteractionValues | None = None,\n    save_path: str | None = None,\n    no_show: bool | None = None,\n) -&gt; None:\n    \"\"\"Plot the SHAP interaction values as a stacked bar chart.\n\n    Args:\n        interaction_values: Interaction values to plot. Defaults to None.\n        save_path: The path to save the plot. Defaults to None.\n        no_show (bool | None, optional): Do not show the plot if set to true. Defaults to None.\n\n    \"\"\"\n    if interaction_values is None and self.last_interaction_values is None:\n        raise NoInteractionValuesError\n\n    # if given interaction values use those, else use cached interaction values\n    iv = interaction_values if interaction_values is not None else self.last_interaction_values\n\n    if not isinstance(iv, InteractionValues):  # pragma: no cover\n        raise TypeError  # pragma: no cover\n\n    hyperparameter_names = self.explanation_task.get_hyperparameter_names()\n\n    iv.plot_stacked_bar(feature_names=np.array(hyperparameter_names), show=False)\n    plt.tight_layout()\n\n    if save_path is not None:\n        plt.savefig(save_path)\n\n    if no_show is None or not no_show:  # pragma: no cover\n        plt.show()  # pragma: no cover\n</code></pre>"},{"location":"api/hypershap/#hypershap.hypershap.HyperSHAP.plot_upset","title":"<code>plot_upset(interaction_values=None, save_path=None, no_show=None)</code>","text":"<p>Plot the SHAP interaction values as an upset plot graph.</p> <p>Parameters:</p> Name Type Description Default <code>interaction_values</code> <code>InteractionValues | None</code> <p>The interaction values to plot. Defaults to None.</p> <code>None</code> <code>save_path</code> <code>str | None</code> <p>The path to save the plot. Defaults to None.</p> <code>None</code> <code>no_show</code> <code>bool | None</code> <p>Do not show the plot if set to true. Defaults to None.</p> <code>None</code> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def plot_upset(\n    self,\n    interaction_values: InteractionValues | None = None,\n    save_path: str | None = None,\n    no_show: bool | None = None,\n) -&gt; None:\n    \"\"\"Plot the SHAP interaction values as an upset plot graph.\n\n    Args:\n        interaction_values (InteractionValues | None, optional): The interaction values to plot. Defaults to None.\n        save_path (str | None, optional): The path to save the plot. Defaults to None.\n        no_show (bool | None, optional): Do not show the plot if set to true. Defaults to None.\n\n    \"\"\"\n    if interaction_values is None and self.last_interaction_values is None:\n        raise NoInteractionValuesError\n\n    # if given interaction values use those, else use cached interaction values\n    iv = interaction_values if interaction_values is not None else self.last_interaction_values\n\n    if not isinstance(iv, InteractionValues):  # pragma: no cover\n        raise TypeError  # pragma: no cover\n\n    hyperparameter_names = self.explanation_task.get_hyperparameter_names()\n\n    fig = iv.plot_upset(feature_names=hyperparameter_names, show=False)\n\n    if fig is None:  # pragma: no cover\n        raise TypeError  # pragma: no cover\n\n    ax = fig.get_axes()[0]\n    ax.set_ylabel(\"Performance Gain\")\n    # also add \"parameter\" to the y-axis label\n    ax = fig.get_axes()[1]\n    ax.set_ylabel(\"Hyperparameter\")\n\n    plt.tight_layout()\n\n    if save_path is not None:\n        plt.savefig(save_path)\n\n    if no_show is None or not no_show:  # pragma: no cover\n        plt.show()  # pragma: no cover\n</code></pre>"},{"location":"api/hypershap/#hypershap.hypershap.HyperSHAP.plot_waterfall","title":"<code>plot_waterfall(interaction_values=None, save_path=None, no_show=None)</code>","text":"<p>Plot the SHAP interaction values as a waterfall graph.</p> <p>Parameters:</p> Name Type Description Default <code>interaction_values</code> <code>InteractionValues | None</code> <p>Interaction values to plot. Defaults to None.</p> <code>None</code> <code>save_path</code> <code>str | None</code> <p>The path to save the plot. Defaults to None.</p> <code>None</code> <code>no_show</code> <code>bool | None</code> <p>Do not show the plot if set to true. Defaults to None.</p> <code>None</code> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def plot_waterfall(\n    self,\n    interaction_values: InteractionValues | None = None,\n    save_path: str | None = None,\n    no_show: bool | None = None,\n) -&gt; None:\n    \"\"\"Plot the SHAP interaction values as a waterfall graph.\n\n    Args:\n        interaction_values: Interaction values to plot. Defaults to None.\n        save_path: The path to save the plot. Defaults to None.\n        no_show (bool | None, optional): Do not show the plot if set to true. Defaults to None.\n\n    \"\"\"\n    if interaction_values is None and self.last_interaction_values is None:\n        raise NoInteractionValuesError\n\n    # if given interaction values use those, else use cached interaction values\n    iv = interaction_values if interaction_values is not None else self.last_interaction_values\n\n    if not isinstance(iv, InteractionValues):  # pragma: no cover\n        raise TypeError  # pragma: no cover\n\n    hyperparameter_names = self.explanation_task.get_hyperparameter_names()\n\n    iv.plot_waterfall(feature_names=np.array(hyperparameter_names), show=False)\n    plt.tight_layout()\n\n    if save_path is not None:\n        plt.savefig(save_path)\n\n    if no_show is None or not no_show:  # pragma: no cover\n        plt.show()  # pragma: no cover\n</code></pre>"},{"location":"api/hypershap/#hypershap.hypershap.HyperSHAP.sensitivity","title":"<code>sensitivity(baseline_config=None, index='FSII', order=2, n_samples=10000, seed=0)</code>","text":"<p>Compute and return the interaction values for sensitivity analysis.</p> <p>Parameters:</p> Name Type Description Default <code>baseline_config</code> <code>Configuration | None</code> <p>The baseline configuration. Defaults to None.</p> <code>None</code> <code>index</code> <code>str</code> <p>The index to use for computing interaction values. Defaults to \"FSII\".</p> <code>'FSII'</code> <code>order</code> <code>int</code> <p>The order of the interaction values. Defaults to 2.</p> <code>2</code> <code>n_samples</code> <code>int</code> <p>The number of samples to use for simulating HPO. Defaults to 10_000.</p> <code>10000</code> <code>seed</code> <code>(int, optiona)</code> <p>The random seed for simulating HPO. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Name Type Description <code>InteractionValues</code> <code>InteractionValues</code> <p>The computed interaction values.</p> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def sensitivity(\n    self,\n    baseline_config: Configuration | None = None,\n    index: ValidApproximationIndices = \"FSII\",\n    order: int = 2,\n    n_samples: int = 10_000,\n    seed: int | None = 0,\n) -&gt; InteractionValues:\n    \"\"\"Compute and return the interaction values for sensitivity analysis.\n\n    Args:\n        baseline_config (Configuration | None, optional): The baseline configuration. Defaults to None.\n        index (str, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n        order (int, optional): The order of the interaction values. Defaults to 2.\n        n_samples (int, optional): The number of samples to use for simulating HPO. Defaults to 10_000.\n        seed (int, optiona): The random seed for simulating HPO. Defaults to 0.\n\n    Returns:\n        InteractionValues: The computed interaction values.\n\n    \"\"\"\n    if baseline_config is None:\n        baseline_config = self.explanation_task.config_space.get_default_configuration()\n\n    if isinstance(self.explanation_task.surrogate_model, list):\n        surrogate_model = self.explanation_task.surrogate_model[0]\n    else:\n        surrogate_model = self.explanation_task.surrogate_model\n\n    # setup explanation task\n    sensitivity_task: SensitivityExplanationTask = SensitivityExplanationTask(\n        config_space=self.explanation_task.config_space,\n        surrogate_model=surrogate_model,\n        baseline_config=baseline_config,\n    )\n\n    # setup tunability game and get interaction values\n    tg = SensitivityGame(\n        explanation_task=sensitivity_task,\n        cs_searcher=RandomConfigSpaceSearcher(\n            explanation_task=sensitivity_task,\n            n_samples=n_samples,\n            mode=Aggregation.VAR,\n            seed=seed,\n        ),\n        n_workers=self.n_workers,\n        verbose=self.verbose,\n    )\n\n    if self.explanation_task.is_multi_data():\n        tg = MultiDataHPIGame(\n            explanation_task=self.explanation_task,\n            base_game=tg,\n            aggregation=Aggregation.AVG,\n        )\n\n    return self.__get_interaction_values(game=tg, index=index, order=order)\n</code></pre>"},{"location":"api/hypershap/#hypershap.hypershap.HyperSHAP.tunability","title":"<code>tunability(baseline_config=None, index='FSII', order=2, n_samples=10000, seed=0)</code>","text":"<p>Compute and return the interaction values for tunability analysis.</p> <p>Parameters:</p> Name Type Description Default <code>baseline_config</code> <code>Configuration | None</code> <p>The baseline configuration. Defaults to None.</p> <code>None</code> <code>index</code> <code>str</code> <p>The index to use for computing interaction values. Defaults to \"FSII\".</p> <code>'FSII'</code> <code>order</code> <code>int</code> <p>The order of the interaction values. Defaults to 2.</p> <code>2</code> <code>n_samples</code> <code>int</code> <p>The number of samples to use for simulating HPO. Defaults to 10_000.</p> <code>10000</code> <code>seed</code> <code>(int, optiona)</code> <p>The random seed for simulating HPO. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Name Type Description <code>InteractionValues</code> <code>InteractionValues</code> <p>The computed interaction values.</p> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def tunability(\n    self,\n    baseline_config: Configuration | None = None,\n    index: ValidApproximationIndices = \"FSII\",\n    order: int = 2,\n    n_samples: int = 10_000,\n    seed: int | None = 0,\n) -&gt; InteractionValues:\n    \"\"\"Compute and return the interaction values for tunability analysis.\n\n    Args:\n        baseline_config (Configuration | None, optional): The baseline configuration. Defaults to None.\n        index (str, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n        order (int, optional): The order of the interaction values. Defaults to 2.\n        n_samples (int, optional): The number of samples to use for simulating HPO. Defaults to 10_000.\n        seed (int, optiona): The random seed for simulating HPO. Defaults to 0.\n\n    Returns:\n        InteractionValues: The computed interaction values.\n\n    \"\"\"\n    if baseline_config is None:\n        baseline_config = self.explanation_task.config_space.get_default_configuration()\n\n    if isinstance(self.explanation_task.surrogate_model, list):\n        surrogate_model = self.explanation_task.surrogate_model[0]\n    else:\n        surrogate_model = self.explanation_task.surrogate_model\n\n    # setup explanation task\n    tunability_task: TunabilityExplanationTask = TunabilityExplanationTask(\n        config_space=self.explanation_task.config_space,\n        surrogate_model=surrogate_model,\n        baseline_config=baseline_config,\n    )\n\n    # setup tunability game and get interaction values\n    tg = TunabilityGame(\n        explanation_task=tunability_task,\n        cs_searcher=RandomConfigSpaceSearcher(\n            explanation_task=tunability_task,\n            n_samples=n_samples,\n            mode=Aggregation.MAX,\n            seed=seed,\n        ),\n        n_workers=self.n_workers,\n        verbose=self.verbose,\n    )\n\n    if self.explanation_task.is_multi_data():\n        tg = MultiDataHPIGame(\n            explanation_task=self.explanation_task,\n            base_game=tg,\n            aggregation=Aggregation.AVG,\n        )\n\n    return self.__get_interaction_values(game=tg, index=index, order=order)\n</code></pre>"},{"location":"api/hypershap/#hypershap.hypershap.NoInteractionValuesError","title":"<code>NoInteractionValuesError</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>Exception raised when no interaction values are present for plotting.</p> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>class NoInteractionValuesError(ValueError):\n    \"\"\"Exception raised when no interaction values are present for plotting.\"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize the no interaction values error.\"\"\"\n        super().__init__(\"No interaction values present for plotting.\")\n</code></pre>"},{"location":"api/hypershap/#hypershap.hypershap.NoInteractionValuesError.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the no interaction values error.</p> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize the no interaction values error.\"\"\"\n    super().__init__(\"No interaction values present for plotting.\")\n</code></pre>"},{"location":"api/surrogate_model/","title":"Surrogate Model","text":"<p>The surrogate module defines the basic classes for surrogate models.</p> <p>It provides methods for training and evaluating a model that approximates the relationship between input hyperparameters and performance.</p>"},{"location":"api/surrogate_model/#hypershap.surrogate_model.DataBasedSurrogateModel","title":"<code>DataBasedSurrogateModel</code>","text":"<p>               Bases: <code>ModelBasedSurrogateModel</code></p> <p>A surrogate model trained on a dataset of configurations and their performance.</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>class DataBasedSurrogateModel(ModelBasedSurrogateModel):\n    \"\"\"A surrogate model trained on a dataset of configurations and their performance.\"\"\"\n\n    def __init__(\n        self,\n        config_space: ConfigurationSpace,\n        data: list[tuple[Configuration, float]],\n        base_model: BaseEstimator | None = None,\n        seed: int | None = 0,\n    ) -&gt; None:\n        \"\"\"Initialize the DataBasedSurrogateModel with data and an optional base model.\n\n        Args:\n            config_space: The configuration space.\n            data: The data to be used for fitting the surrogate model.  Each element\n                  is a tuple of (Configuration, float).\n            base_model: The base model to be used for fitting the surrogate model.\n                        If None, a RandomForestRegressor is used.\n            seed: The random seed for pseudo-randomization of the surrogate model. Defaults to 0.\n\n        \"\"\"\n        train_x = np.array([obs[0].get_array() for obs in data])\n        train_y = np.array([obs[1] for obs in data])\n\n        if base_model is None:\n            base_model = RandomForestRegressor(random_state=seed)\n\n        pipeline = cast(\"SklearnRegressorProtocol\", base_model)\n        pipeline.fit(train_x, train_y)\n\n        super().__init__(config_space, base_model)\n</code></pre>"},{"location":"api/surrogate_model/#hypershap.surrogate_model.DataBasedSurrogateModel.__init__","title":"<code>__init__(config_space, data, base_model=None, seed=0)</code>","text":"<p>Initialize the DataBasedSurrogateModel with data and an optional base model.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>data</code> <code>list[tuple[Configuration, float]]</code> <p>The data to be used for fitting the surrogate model.  Each element   is a tuple of (Configuration, float).</p> required <code>base_model</code> <code>BaseEstimator | None</code> <p>The base model to be used for fitting the surrogate model.         If None, a RandomForestRegressor is used.</p> <code>None</code> <code>seed</code> <code>int | None</code> <p>The random seed for pseudo-randomization of the surrogate model. Defaults to 0.</p> <code>0</code> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>def __init__(\n    self,\n    config_space: ConfigurationSpace,\n    data: list[tuple[Configuration, float]],\n    base_model: BaseEstimator | None = None,\n    seed: int | None = 0,\n) -&gt; None:\n    \"\"\"Initialize the DataBasedSurrogateModel with data and an optional base model.\n\n    Args:\n        config_space: The configuration space.\n        data: The data to be used for fitting the surrogate model.  Each element\n              is a tuple of (Configuration, float).\n        base_model: The base model to be used for fitting the surrogate model.\n                    If None, a RandomForestRegressor is used.\n        seed: The random seed for pseudo-randomization of the surrogate model. Defaults to 0.\n\n    \"\"\"\n    train_x = np.array([obs[0].get_array() for obs in data])\n    train_y = np.array([obs[1] for obs in data])\n\n    if base_model is None:\n        base_model = RandomForestRegressor(random_state=seed)\n\n    pipeline = cast(\"SklearnRegressorProtocol\", base_model)\n    pipeline.fit(train_x, train_y)\n\n    super().__init__(config_space, base_model)\n</code></pre>"},{"location":"api/surrogate_model/#hypershap.surrogate_model.ModelBasedSurrogateModel","title":"<code>ModelBasedSurrogateModel</code>","text":"<p>               Bases: <code>SurrogateModel</code></p> <p>A surrogate model based on a pre-trained machine learning model.</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>class ModelBasedSurrogateModel(SurrogateModel):\n    \"\"\"A surrogate model based on a pre-trained machine learning model.\"\"\"\n\n    def __init__(self, config_space: ConfigurationSpace, base_model: BaseEstimator) -&gt; None:\n        \"\"\"Initialize the ModelBasedSurrogateModel with a configuration space and a base model.\n\n        Args:\n            config_space: The configuration space.\n            base_model: The base machine learning model.\n\n        \"\"\"\n        super().__init__(config_space)\n        self.base_model = base_model\n\n    def evaluate(self, config_array: np.ndarray) -&gt; float | list[float]:\n        \"\"\"Evaluate a configuration (or batch of configurations).\n\n        Args:\n            config_array: A numpy array representing the configuration(s).\n\n        Returns:\n            The predicted performance(s).\n\n        \"\"\"\n        if config_array.ndim == 1:\n            config_array = config_array.reshape(1, -1)\n\n        base_model = cast(\"SklearnRegressorProtocol\", self.base_model)\n        predictions = base_model.predict(config_array)\n\n        if predictions.shape == (1,):  # Check for a 1-element array (scalar)\n            return float(predictions[0])  # Convert to a Python float\n\n        return predictions.tolist()  # Convert to a Python list\n</code></pre>"},{"location":"api/surrogate_model/#hypershap.surrogate_model.ModelBasedSurrogateModel.__init__","title":"<code>__init__(config_space, base_model)</code>","text":"<p>Initialize the ModelBasedSurrogateModel with a configuration space and a base model.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>base_model</code> <code>BaseEstimator</code> <p>The base machine learning model.</p> required Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>def __init__(self, config_space: ConfigurationSpace, base_model: BaseEstimator) -&gt; None:\n    \"\"\"Initialize the ModelBasedSurrogateModel with a configuration space and a base model.\n\n    Args:\n        config_space: The configuration space.\n        base_model: The base machine learning model.\n\n    \"\"\"\n    super().__init__(config_space)\n    self.base_model = base_model\n</code></pre>"},{"location":"api/surrogate_model/#hypershap.surrogate_model.ModelBasedSurrogateModel.evaluate","title":"<code>evaluate(config_array)</code>","text":"<p>Evaluate a configuration (or batch of configurations).</p> <p>Parameters:</p> Name Type Description Default <code>config_array</code> <code>ndarray</code> <p>A numpy array representing the configuration(s).</p> required <p>Returns:</p> Type Description <code>float | list[float]</code> <p>The predicted performance(s).</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>def evaluate(self, config_array: np.ndarray) -&gt; float | list[float]:\n    \"\"\"Evaluate a configuration (or batch of configurations).\n\n    Args:\n        config_array: A numpy array representing the configuration(s).\n\n    Returns:\n        The predicted performance(s).\n\n    \"\"\"\n    if config_array.ndim == 1:\n        config_array = config_array.reshape(1, -1)\n\n    base_model = cast(\"SklearnRegressorProtocol\", self.base_model)\n    predictions = base_model.predict(config_array)\n\n    if predictions.shape == (1,):  # Check for a 1-element array (scalar)\n        return float(predictions[0])  # Convert to a Python float\n\n    return predictions.tolist()  # Convert to a Python list\n</code></pre>"},{"location":"api/surrogate_model/#hypershap.surrogate_model.SklearnRegressorProtocol","title":"<code>SklearnRegressorProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Defines the interface for scikit-learn-like regression models.</p> <p>This protocol specifies the required methods for a class to be considered a compatible scikit-learn regression model.  It mandates the presence of <code>fit</code>, <code>predict</code>, and <code>score</code> methods, mirroring the structure of many scikit-learn estimators.</p> <p>Attributes:</p> Name Type Description <code>fit</code> <code>callable</code> <p>A method that fits the model to the provided data.              It should accept training data (X) and target variables (y)              as arguments, and any optional fit parameters. It should return              the fitted model instance itself (allowing for chaining).</p> <code>predict</code> <code>callable</code> <p>A method that generates predictions for a given input dataset.                It accepts input data (X) and returns predictions as a NumPy array.</p> <code>score</code> <code>callable</code> <p>A method that evaluates the model's performance on a given dataset.               It accepts input data (X) and corresponding target variables (y)               and returns a scalar performance score (e.g., R-squared, MSE).</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>class SklearnRegressorProtocol(Protocol):\n    \"\"\"Defines the interface for scikit-learn-like regression models.\n\n    This protocol specifies the required methods for a class to be considered\n    a compatible scikit-learn regression model.  It mandates the presence of `fit`,\n    `predict`, and `score` methods, mirroring the structure of many\n    scikit-learn estimators.\n\n    Attributes:\n        fit (callable): A method that fits the model to the provided data.\n                         It should accept training data (X) and target variables (y)\n                         as arguments, and any optional fit parameters. It should return\n                         the fitted model instance itself (allowing for chaining).\n        predict (callable): A method that generates predictions for a given input dataset.\n                           It accepts input data (X) and returns predictions as a NumPy array.\n        score (callable): A method that evaluates the model's performance on a given dataset.\n                          It accepts input data (X) and corresponding target variables (y)\n                          and returns a scalar performance score (e.g., R-squared, MSE).\n\n    \"\"\"\n\n    def fit(self, X: Any, y: Any, **fit_params: Any) -&gt; None:\n        \"\"\"Fit the regression model to the provided training data.\n\n        Args:\n            X (np.ndarray): The training data features.\n            y (np.ndarray): The training data target variables.\n            **fit_params (Any): Optional keyword arguments passed to the fit method.\n\n        Returns:\n            'SklearnRegressorProtocol': The fitted regression model instance itself, allowing for method chaining.\n\n        \"\"\"\n        ...\n\n    def predict(self, X: Any) -&gt; np.ndarray:\n        \"\"\"Generate predictions for a given input dataset.\n\n        Args:\n            X (np.ndarray): The input data features for prediction.\n\n        Returns:\n            np.ndarray: The predicted target values as a NumPy array.\n\n        \"\"\"\n        ...\n\n    def score(self, X: Any, y: Any) -&gt; float:\n        \"\"\"Evaluate the model's performance on a given dataset.\n\n        Args:\n            X (np.ndarray): The input data features.\n            y (np.ndarray): The corresponding target variables.\n\n        Returns:\n            float: A scalar performance score, representing the model's accuracy on the dataset.\n\n        \"\"\"\n        ...\n</code></pre>"},{"location":"api/surrogate_model/#hypershap.surrogate_model.SklearnRegressorProtocol.fit","title":"<code>fit(X, y, **fit_params)</code>","text":"<p>Fit the regression model to the provided training data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The training data features.</p> required <code>y</code> <code>ndarray</code> <p>The training data target variables.</p> required <code>**fit_params</code> <code>Any</code> <p>Optional keyword arguments passed to the fit method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>None</code> <p>'SklearnRegressorProtocol': The fitted regression model instance itself, allowing for method chaining.</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>def fit(self, X: Any, y: Any, **fit_params: Any) -&gt; None:\n    \"\"\"Fit the regression model to the provided training data.\n\n    Args:\n        X (np.ndarray): The training data features.\n        y (np.ndarray): The training data target variables.\n        **fit_params (Any): Optional keyword arguments passed to the fit method.\n\n    Returns:\n        'SklearnRegressorProtocol': The fitted regression model instance itself, allowing for method chaining.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/surrogate_model/#hypershap.surrogate_model.SklearnRegressorProtocol.predict","title":"<code>predict(X)</code>","text":"<p>Generate predictions for a given input dataset.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The input data features for prediction.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The predicted target values as a NumPy array.</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>def predict(self, X: Any) -&gt; np.ndarray:\n    \"\"\"Generate predictions for a given input dataset.\n\n    Args:\n        X (np.ndarray): The input data features for prediction.\n\n    Returns:\n        np.ndarray: The predicted target values as a NumPy array.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/surrogate_model/#hypershap.surrogate_model.SklearnRegressorProtocol.score","title":"<code>score(X, y)</code>","text":"<p>Evaluate the model's performance on a given dataset.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The input data features.</p> required <code>y</code> <code>ndarray</code> <p>The corresponding target variables.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>A scalar performance score, representing the model's accuracy on the dataset.</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>def score(self, X: Any, y: Any) -&gt; float:\n    \"\"\"Evaluate the model's performance on a given dataset.\n\n    Args:\n        X (np.ndarray): The input data features.\n        y (np.ndarray): The corresponding target variables.\n\n    Returns:\n        float: A scalar performance score, representing the model's accuracy on the dataset.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/surrogate_model/#hypershap.surrogate_model.SurrogateModel","title":"<code>SurrogateModel</code>","text":"<p>               Bases: <code>ABC</code></p> <p>An abstract class for defining the interface of surrogate models.</p> <p>This class defines the basic methods that all surrogate models should implement, allowing for a consistent interface for evaluating different models.</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>class SurrogateModel(ABC):\n    \"\"\"An abstract class for defining the interface of surrogate models.\n\n    This class defines the basic methods that all surrogate models should implement,\n    allowing for a consistent interface for evaluating different models.\n    \"\"\"\n\n    def __init__(self, config_space: ConfigurationSpace) -&gt; None:\n        \"\"\"Initialize the SurrogateModel with a configuration space.\n\n        Args:\n            config_space: The configuration space for the surrogate model.\n\n        \"\"\"\n        self.config_space = config_space\n\n    def evaluate_config(self, config: Configuration) -&gt; float:\n        \"\"\"Evaluate a single configuration using the surrogate model.\n\n        Args:\n            config: The configuration to evaluate.\n\n        Returns:\n            The predicted performance for the given configuration.\n\n        \"\"\"\n        res = self.evaluate(np.array(config.get_array()))\n        if not isinstance(res, float):  # pragma: no cover\n            raise TypeError  # pragma: no cover\n        return res\n\n    def evaluate_config_batch(self, config_batch: list[Configuration]) -&gt; list[float]:\n        \"\"\"Evaluate a batch of configurations using the surrogate model.\n\n        Args:\n            config_batch: A list of configurations to evaluate.\n\n        Returns:\n            A list of predicted performances for the given configurations.\n\n        \"\"\"\n        res = self.evaluate(np.array([config.get_array() for config in config_batch]))\n        if not isinstance(res, list):  # pragma: no cover\n            raise TypeError  # pragma: no cover\n        return res\n\n    @abstractmethod\n    def evaluate(self, config_array: np.ndarray) -&gt; float | list[float]:\n        \"\"\"Evaluate a configuration (or batch of configurations) represented as a numpy array.\n\n        Args:\n            config_array: A numpy array representing the configuration(s).\n\n        Returns:\n            The predicted performance(s).\n\n        \"\"\"\n</code></pre>"},{"location":"api/surrogate_model/#hypershap.surrogate_model.SurrogateModel.__init__","title":"<code>__init__(config_space)</code>","text":"<p>Initialize the SurrogateModel with a configuration space.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space for the surrogate model.</p> required Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>def __init__(self, config_space: ConfigurationSpace) -&gt; None:\n    \"\"\"Initialize the SurrogateModel with a configuration space.\n\n    Args:\n        config_space: The configuration space for the surrogate model.\n\n    \"\"\"\n    self.config_space = config_space\n</code></pre>"},{"location":"api/surrogate_model/#hypershap.surrogate_model.SurrogateModel.evaluate","title":"<code>evaluate(config_array)</code>  <code>abstractmethod</code>","text":"<p>Evaluate a configuration (or batch of configurations) represented as a numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>config_array</code> <code>ndarray</code> <p>A numpy array representing the configuration(s).</p> required <p>Returns:</p> Type Description <code>float | list[float]</code> <p>The predicted performance(s).</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>@abstractmethod\ndef evaluate(self, config_array: np.ndarray) -&gt; float | list[float]:\n    \"\"\"Evaluate a configuration (or batch of configurations) represented as a numpy array.\n\n    Args:\n        config_array: A numpy array representing the configuration(s).\n\n    Returns:\n        The predicted performance(s).\n\n    \"\"\"\n</code></pre>"},{"location":"api/surrogate_model/#hypershap.surrogate_model.SurrogateModel.evaluate_config","title":"<code>evaluate_config(config)</code>","text":"<p>Evaluate a single configuration using the surrogate model.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Configuration</code> <p>The configuration to evaluate.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The predicted performance for the given configuration.</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>def evaluate_config(self, config: Configuration) -&gt; float:\n    \"\"\"Evaluate a single configuration using the surrogate model.\n\n    Args:\n        config: The configuration to evaluate.\n\n    Returns:\n        The predicted performance for the given configuration.\n\n    \"\"\"\n    res = self.evaluate(np.array(config.get_array()))\n    if not isinstance(res, float):  # pragma: no cover\n        raise TypeError  # pragma: no cover\n    return res\n</code></pre>"},{"location":"api/surrogate_model/#hypershap.surrogate_model.SurrogateModel.evaluate_config_batch","title":"<code>evaluate_config_batch(config_batch)</code>","text":"<p>Evaluate a batch of configurations using the surrogate model.</p> <p>Parameters:</p> Name Type Description Default <code>config_batch</code> <code>list[Configuration]</code> <p>A list of configurations to evaluate.</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>A list of predicted performances for the given configurations.</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>def evaluate_config_batch(self, config_batch: list[Configuration]) -&gt; list[float]:\n    \"\"\"Evaluate a batch of configurations using the surrogate model.\n\n    Args:\n        config_batch: A list of configurations to evaluate.\n\n    Returns:\n        A list of predicted performances for the given configurations.\n\n    \"\"\"\n    res = self.evaluate(np.array([config.get_array() for config in config_batch]))\n    if not isinstance(res, list):  # pragma: no cover\n        raise TypeError  # pragma: no cover\n    return res\n</code></pre>"},{"location":"api/task/","title":"Tasks","text":"<p>The task module implements a hierarchy of explanation tasks that can be used to explain HPO.</p> <p>The tasks provide a convenient API to construct surrogate models from different data sources (pretrained estimators, empirical data, or a black box function) and to add domain specific information such as a baseline configuration or an optimizer of interest.</p>"},{"location":"api/task/#hypershap.task.AblationExplanationTask","title":"<code>AblationExplanationTask</code>","text":"<p>               Bases: <code>BaselineExplanationTask</code></p> <p>Defines an ablation explanation task, comparing a configuration of interest to a baseline.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>class AblationExplanationTask(BaselineExplanationTask):\n    \"\"\"Defines an ablation explanation task, comparing a configuration of interest to a baseline.\"\"\"\n\n    def __init__(\n        self,\n        config_space: ConfigurationSpace,\n        surrogate_model: SurrogateModel | list[SurrogateModel],\n        baseline_config: Configuration,\n        config_of_interest: Configuration,\n    ) -&gt; None:\n        \"\"\"Initialize an AblationExplanationTask with a baseline and a configuration of interest.\n\n        Args:\n            config_space: The configuration space.\n            surrogate_model: The (list of) surrogate model(s) used for the explanation task.\n            baseline_config: The baseline configuration.\n            config_of_interest: The configuration of interest.\n\n        \"\"\"\n        super().__init__(config_space, surrogate_model, baseline_config)\n        self.config_of_interest = config_of_interest\n</code></pre>"},{"location":"api/task/#hypershap.task.AblationExplanationTask.__init__","title":"<code>__init__(config_space, surrogate_model, baseline_config, config_of_interest)</code>","text":"<p>Initialize an AblationExplanationTask with a baseline and a configuration of interest.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>surrogate_model</code> <code>SurrogateModel | list[SurrogateModel]</code> <p>The (list of) surrogate model(s) used for the explanation task.</p> required <code>baseline_config</code> <code>Configuration</code> <p>The baseline configuration.</p> required <code>config_of_interest</code> <code>Configuration</code> <p>The configuration of interest.</p> required Source code in <code>src/hypershap/task.py</code> <pre><code>def __init__(\n    self,\n    config_space: ConfigurationSpace,\n    surrogate_model: SurrogateModel | list[SurrogateModel],\n    baseline_config: Configuration,\n    config_of_interest: Configuration,\n) -&gt; None:\n    \"\"\"Initialize an AblationExplanationTask with a baseline and a configuration of interest.\n\n    Args:\n        config_space: The configuration space.\n        surrogate_model: The (list of) surrogate model(s) used for the explanation task.\n        baseline_config: The baseline configuration.\n        config_of_interest: The configuration of interest.\n\n    \"\"\"\n    super().__init__(config_space, surrogate_model, baseline_config)\n    self.config_of_interest = config_of_interest\n</code></pre>"},{"location":"api/task/#hypershap.task.BaselineExplanationTask","title":"<code>BaselineExplanationTask</code>","text":"<p>               Bases: <code>ExplanationTask</code></p> <p>Defines an explanation task with a baseline configuration.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>class BaselineExplanationTask(ExplanationTask):\n    \"\"\"Defines an explanation task with a baseline configuration.\"\"\"\n\n    def __init__(\n        self,\n        config_space: ConfigurationSpace,\n        surrogate_model: SurrogateModel | list[SurrogateModel],\n        baseline_config: Configuration,\n    ) -&gt; None:\n        \"\"\"Initialize a BaselineExplanationTask with a baseline configuration.\n\n        Args:\n            config_space: The configuration space.\n            surrogate_model: The (list of) surrogate model(s) used for the explanation task.\n            baseline_config: The baseline configuration.\n\n        \"\"\"\n        super().__init__(config_space, surrogate_model)\n        self.baseline_config = baseline_config\n</code></pre>"},{"location":"api/task/#hypershap.task.BaselineExplanationTask.__init__","title":"<code>__init__(config_space, surrogate_model, baseline_config)</code>","text":"<p>Initialize a BaselineExplanationTask with a baseline configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>surrogate_model</code> <code>SurrogateModel | list[SurrogateModel]</code> <p>The (list of) surrogate model(s) used for the explanation task.</p> required <code>baseline_config</code> <code>Configuration</code> <p>The baseline configuration.</p> required Source code in <code>src/hypershap/task.py</code> <pre><code>def __init__(\n    self,\n    config_space: ConfigurationSpace,\n    surrogate_model: SurrogateModel | list[SurrogateModel],\n    baseline_config: Configuration,\n) -&gt; None:\n    \"\"\"Initialize a BaselineExplanationTask with a baseline configuration.\n\n    Args:\n        config_space: The configuration space.\n        surrogate_model: The (list of) surrogate model(s) used for the explanation task.\n        baseline_config: The baseline configuration.\n\n    \"\"\"\n    super().__init__(config_space, surrogate_model)\n    self.baseline_config = baseline_config\n</code></pre>"},{"location":"api/task/#hypershap.task.ExplanationTask","title":"<code>ExplanationTask</code>","text":"<p>Defines the base class for explanation tasks, providing access to the configuration space and surrogate model.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>class ExplanationTask:\n    \"\"\"Defines the base class for explanation tasks, providing access to the configuration space and surrogate model.\"\"\"\n\n    def __init__(\n        self,\n        config_space: ConfigurationSpace,\n        surrogate_model: SurrogateModel | list[SurrogateModel],\n    ) -&gt; None:\n        \"\"\"Initialize an ExplanationTask with a configuration space and surrogate model.\n\n        Args:\n            config_space: The configuration space for the explanation task.\n            surrogate_model: The (list of) surrogate model(s) used for the explanation task.\n\n        \"\"\"\n        self.config_space = config_space\n        self.surrogate_model = surrogate_model\n\n    def is_multi_data(self) -&gt; bool:\n        \"\"\"Return if the explanation task is a multi-data task.\n\n        Returns:\n            True if the explanation task is a multi-data task.\n\n        \"\"\"\n        return isinstance(self.surrogate_model, list)\n\n    def get_single_surrogate_model(self) -&gt; SurrogateModel:\n        \"\"\"Return the surrogate model for the explanation task.\n\n        Returns:\n            The surrogate model for the explanation task.\n\n        \"\"\"\n        if isinstance(self.surrogate_model, list):\n            raise TypeError\n\n        return self.surrogate_model\n\n    def get_surrogate_model_list(self) -&gt; list[SurrogateModel]:\n        \"\"\"Return the list of surrogate models for the explanation task.\n\n        Returns:\n            The list of surrogate models for the explanation task.\n\n        \"\"\"\n        if not isinstance(self.surrogate_model, list):\n            raise TypeError\n\n        return self.surrogate_model\n\n    def get_num_hyperparameters(self) -&gt; int:\n        \"\"\"Return the number of hyperparameters in the configuration space.\n\n        Returns:\n            The number of hyperparameters.\n\n        \"\"\"\n        return len(self.config_space)\n\n    def get_hyperparameter_names(self) -&gt; list[str]:\n        \"\"\"Return the names of the hyperparameters in the configuration space.\n\n        Returns:\n            A list of hyperparameter names.\n\n        \"\"\"\n        return list(self.config_space.keys())\n\n    @staticmethod\n    def from_base_model(config_space: ConfigurationSpace, base_model: BaseEstimator) -&gt; ExplanationTask:\n        \"\"\"Create an ExplanationTask from a pre-trained base model.\n\n        Args:\n            config_space: The configuration space.\n            base_model: The pre-trained base model.\n\n        Returns:\n            An ExplanationTask instance.\n\n        \"\"\"\n        surrogate_model = ModelBasedSurrogateModel(config_space=config_space, base_model=base_model)\n        return ExplanationTask(config_space=config_space, surrogate_model=surrogate_model)\n\n    @staticmethod\n    def from_data(\n        config_space: ConfigurationSpace,\n        data: list[tuple[Configuration, float]],\n        base_model: BaseEstimator | None = None,\n    ) -&gt; ExplanationTask:\n        \"\"\"Create an ExplanationTask from a dataset of configurations and their performance.\n\n        Args:\n            config_space: The configuration space.\n            data: A list of tuples, where each tuple contains a configuration and its corresponding performance.\n            base_model: The base model to use for training the surrogate model. Defaults to RandomForestRegressor.\n\n        Returns:\n            An ExplanationTask instance.\n\n        \"\"\"\n        surrogate_model = DataBasedSurrogateModel(config_space=config_space, data=data, base_model=base_model)\n        return ExplanationTask(config_space=config_space, surrogate_model=surrogate_model)\n\n    @staticmethod\n    def from_function(\n        config_space: ConfigurationSpace,\n        function: Callable[[Configuration], float],\n        n_samples: int = 1_000,\n        base_model: BaseEstimator | None = None,\n        seed: int | None = 0,\n    ) -&gt; ExplanationTask:\n        \"\"\"Create an ExplanationTask from a function that evaluates configurations.\n\n        Args:\n            config_space: The configuration space.\n            function: A callable that takes a configuration and returns its performance.\n            n_samples: The number of configurations to sample for training the surrogate model. Defaults to 1000.\n            base_model: The base model to use for training the surrogate model. Defaults to RandomForestRegressor.\n            seed: The seed for the random number generator, it is used to seed a deep copy of the config space.\n\n        Returns:\n            An ExplanationTask instance.\n\n        \"\"\"\n        cs = deepcopy(config_space)\n        if seed is not None:\n            cs.seed(seed)\n        samples: list[Configuration] = cs.sample_configuration(n_samples)\n        values: list[float] = [function(config) for config in samples]\n        data: list[tuple[Configuration, float]] = list(zip(samples, values, strict=False))\n        base_model = base_model if base_model is not None else RandomForestRegressor(random_state=seed)\n\n        return ExplanationTask.from_data(config_space=cs, data=data, base_model=base_model)\n\n    @staticmethod\n    def from_function_multidata(\n        config_space: ConfigurationSpace,\n        functions: list[Callable[[Configuration], float]],\n        n_samples: int = 1_000,\n        base_model: BaseEstimator | None = None,\n    ) -&gt; ExplanationTask:\n        \"\"\"Create an ExplanationTask from a list of functions that evaluate configurations.\n\n        Args:\n            config_space: The configuration space.\n            functions: A list of callables that take a configuration and returns its performance.\n            n_samples: The number of configurations to sample for training the surrogate model. Defaults to 1000.\n            base_model: The base model to be used for training the surrogate model. Defaults to RandomForestRegressor.\n\n        Returns:\n            An ExplanationTask instance.\n\n        \"\"\"\n        surrogate_model_list = [\n            ExplanationTask.from_function(config_space, fun, n_samples, base_model).get_single_surrogate_model()\n            for fun in functions\n        ]\n        return ExplanationTask(config_space=config_space, surrogate_model=surrogate_model_list)\n\n    @staticmethod\n    def from_data_multidata(\n        config_space: ConfigurationSpace,\n        data_multidata: list[list[tuple[Configuration, float]]],\n        base_model: BaseEstimator | None = None,\n    ) -&gt; ExplanationTask:\n        \"\"\"Create an ExplanationTask from a list of datasets of different HPO tasks.\n\n        Args:\n            config_space: The configuration space.\n            data_multidata: A list of tuples, where each tuple contains a configuration and its corresponding performance.\n            base_model: The base model to use for training the surrogate model. Defaults to RandomForestRegressor.\n\n        Returns:\n            An ExplanationTask instance.\n\n        \"\"\"\n        surrogate_model_list = [\n            ExplanationTask.from_data(config_space, data, base_model).get_single_surrogate_model()\n            for data in data_multidata\n        ]\n        return ExplanationTask(config_space=config_space, surrogate_model=surrogate_model_list)\n\n    @staticmethod\n    def from_basemodel_multidata(\n        config_space: ConfigurationSpace,\n        base_model: list[BaseEstimator],\n    ) -&gt; ExplanationTask:\n        \"\"\"Create an ExplanationTask from a list of datasets of different HPO tasks.\n\n        Args:\n            config_space: The configuration space.\n            base_model: The list of base models to be used as surrogate models.\n\n        Returns:\n            An ExplanationTask instance.\n\n        \"\"\"\n        surrogate_model_list: list[SurrogateModel] = [\n            ModelBasedSurrogateModel(config_space=config_space, base_model=m) for m in base_model\n        ]\n        return ExplanationTask(config_space=config_space, surrogate_model=surrogate_model_list)\n</code></pre>"},{"location":"api/task/#hypershap.task.ExplanationTask.__init__","title":"<code>__init__(config_space, surrogate_model)</code>","text":"<p>Initialize an ExplanationTask with a configuration space and surrogate model.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space for the explanation task.</p> required <code>surrogate_model</code> <code>SurrogateModel | list[SurrogateModel]</code> <p>The (list of) surrogate model(s) used for the explanation task.</p> required Source code in <code>src/hypershap/task.py</code> <pre><code>def __init__(\n    self,\n    config_space: ConfigurationSpace,\n    surrogate_model: SurrogateModel | list[SurrogateModel],\n) -&gt; None:\n    \"\"\"Initialize an ExplanationTask with a configuration space and surrogate model.\n\n    Args:\n        config_space: The configuration space for the explanation task.\n        surrogate_model: The (list of) surrogate model(s) used for the explanation task.\n\n    \"\"\"\n    self.config_space = config_space\n    self.surrogate_model = surrogate_model\n</code></pre>"},{"location":"api/task/#hypershap.task.ExplanationTask.from_base_model","title":"<code>from_base_model(config_space, base_model)</code>  <code>staticmethod</code>","text":"<p>Create an ExplanationTask from a pre-trained base model.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>base_model</code> <code>BaseEstimator</code> <p>The pre-trained base model.</p> required <p>Returns:</p> Type Description <code>ExplanationTask</code> <p>An ExplanationTask instance.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>@staticmethod\ndef from_base_model(config_space: ConfigurationSpace, base_model: BaseEstimator) -&gt; ExplanationTask:\n    \"\"\"Create an ExplanationTask from a pre-trained base model.\n\n    Args:\n        config_space: The configuration space.\n        base_model: The pre-trained base model.\n\n    Returns:\n        An ExplanationTask instance.\n\n    \"\"\"\n    surrogate_model = ModelBasedSurrogateModel(config_space=config_space, base_model=base_model)\n    return ExplanationTask(config_space=config_space, surrogate_model=surrogate_model)\n</code></pre>"},{"location":"api/task/#hypershap.task.ExplanationTask.from_basemodel_multidata","title":"<code>from_basemodel_multidata(config_space, base_model)</code>  <code>staticmethod</code>","text":"<p>Create an ExplanationTask from a list of datasets of different HPO tasks.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>base_model</code> <code>list[BaseEstimator]</code> <p>The list of base models to be used as surrogate models.</p> required <p>Returns:</p> Type Description <code>ExplanationTask</code> <p>An ExplanationTask instance.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>@staticmethod\ndef from_basemodel_multidata(\n    config_space: ConfigurationSpace,\n    base_model: list[BaseEstimator],\n) -&gt; ExplanationTask:\n    \"\"\"Create an ExplanationTask from a list of datasets of different HPO tasks.\n\n    Args:\n        config_space: The configuration space.\n        base_model: The list of base models to be used as surrogate models.\n\n    Returns:\n        An ExplanationTask instance.\n\n    \"\"\"\n    surrogate_model_list: list[SurrogateModel] = [\n        ModelBasedSurrogateModel(config_space=config_space, base_model=m) for m in base_model\n    ]\n    return ExplanationTask(config_space=config_space, surrogate_model=surrogate_model_list)\n</code></pre>"},{"location":"api/task/#hypershap.task.ExplanationTask.from_data","title":"<code>from_data(config_space, data, base_model=None)</code>  <code>staticmethod</code>","text":"<p>Create an ExplanationTask from a dataset of configurations and their performance.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>data</code> <code>list[tuple[Configuration, float]]</code> <p>A list of tuples, where each tuple contains a configuration and its corresponding performance.</p> required <code>base_model</code> <code>BaseEstimator | None</code> <p>The base model to use for training the surrogate model. Defaults to RandomForestRegressor.</p> <code>None</code> <p>Returns:</p> Type Description <code>ExplanationTask</code> <p>An ExplanationTask instance.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>@staticmethod\ndef from_data(\n    config_space: ConfigurationSpace,\n    data: list[tuple[Configuration, float]],\n    base_model: BaseEstimator | None = None,\n) -&gt; ExplanationTask:\n    \"\"\"Create an ExplanationTask from a dataset of configurations and their performance.\n\n    Args:\n        config_space: The configuration space.\n        data: A list of tuples, where each tuple contains a configuration and its corresponding performance.\n        base_model: The base model to use for training the surrogate model. Defaults to RandomForestRegressor.\n\n    Returns:\n        An ExplanationTask instance.\n\n    \"\"\"\n    surrogate_model = DataBasedSurrogateModel(config_space=config_space, data=data, base_model=base_model)\n    return ExplanationTask(config_space=config_space, surrogate_model=surrogate_model)\n</code></pre>"},{"location":"api/task/#hypershap.task.ExplanationTask.from_data_multidata","title":"<code>from_data_multidata(config_space, data_multidata, base_model=None)</code>  <code>staticmethod</code>","text":"<p>Create an ExplanationTask from a list of datasets of different HPO tasks.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>data_multidata</code> <code>list[list[tuple[Configuration, float]]]</code> <p>A list of tuples, where each tuple contains a configuration and its corresponding performance.</p> required <code>base_model</code> <code>BaseEstimator | None</code> <p>The base model to use for training the surrogate model. Defaults to RandomForestRegressor.</p> <code>None</code> <p>Returns:</p> Type Description <code>ExplanationTask</code> <p>An ExplanationTask instance.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>@staticmethod\ndef from_data_multidata(\n    config_space: ConfigurationSpace,\n    data_multidata: list[list[tuple[Configuration, float]]],\n    base_model: BaseEstimator | None = None,\n) -&gt; ExplanationTask:\n    \"\"\"Create an ExplanationTask from a list of datasets of different HPO tasks.\n\n    Args:\n        config_space: The configuration space.\n        data_multidata: A list of tuples, where each tuple contains a configuration and its corresponding performance.\n        base_model: The base model to use for training the surrogate model. Defaults to RandomForestRegressor.\n\n    Returns:\n        An ExplanationTask instance.\n\n    \"\"\"\n    surrogate_model_list = [\n        ExplanationTask.from_data(config_space, data, base_model).get_single_surrogate_model()\n        for data in data_multidata\n    ]\n    return ExplanationTask(config_space=config_space, surrogate_model=surrogate_model_list)\n</code></pre>"},{"location":"api/task/#hypershap.task.ExplanationTask.from_function","title":"<code>from_function(config_space, function, n_samples=1000, base_model=None, seed=0)</code>  <code>staticmethod</code>","text":"<p>Create an ExplanationTask from a function that evaluates configurations.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>function</code> <code>Callable[[Configuration], float]</code> <p>A callable that takes a configuration and returns its performance.</p> required <code>n_samples</code> <code>int</code> <p>The number of configurations to sample for training the surrogate model. Defaults to 1000.</p> <code>1000</code> <code>base_model</code> <code>BaseEstimator | None</code> <p>The base model to use for training the surrogate model. Defaults to RandomForestRegressor.</p> <code>None</code> <code>seed</code> <code>int | None</code> <p>The seed for the random number generator, it is used to seed a deep copy of the config space.</p> <code>0</code> <p>Returns:</p> Type Description <code>ExplanationTask</code> <p>An ExplanationTask instance.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>@staticmethod\ndef from_function(\n    config_space: ConfigurationSpace,\n    function: Callable[[Configuration], float],\n    n_samples: int = 1_000,\n    base_model: BaseEstimator | None = None,\n    seed: int | None = 0,\n) -&gt; ExplanationTask:\n    \"\"\"Create an ExplanationTask from a function that evaluates configurations.\n\n    Args:\n        config_space: The configuration space.\n        function: A callable that takes a configuration and returns its performance.\n        n_samples: The number of configurations to sample for training the surrogate model. Defaults to 1000.\n        base_model: The base model to use for training the surrogate model. Defaults to RandomForestRegressor.\n        seed: The seed for the random number generator, it is used to seed a deep copy of the config space.\n\n    Returns:\n        An ExplanationTask instance.\n\n    \"\"\"\n    cs = deepcopy(config_space)\n    if seed is not None:\n        cs.seed(seed)\n    samples: list[Configuration] = cs.sample_configuration(n_samples)\n    values: list[float] = [function(config) for config in samples]\n    data: list[tuple[Configuration, float]] = list(zip(samples, values, strict=False))\n    base_model = base_model if base_model is not None else RandomForestRegressor(random_state=seed)\n\n    return ExplanationTask.from_data(config_space=cs, data=data, base_model=base_model)\n</code></pre>"},{"location":"api/task/#hypershap.task.ExplanationTask.from_function_multidata","title":"<code>from_function_multidata(config_space, functions, n_samples=1000, base_model=None)</code>  <code>staticmethod</code>","text":"<p>Create an ExplanationTask from a list of functions that evaluate configurations.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>functions</code> <code>list[Callable[[Configuration], float]]</code> <p>A list of callables that take a configuration and returns its performance.</p> required <code>n_samples</code> <code>int</code> <p>The number of configurations to sample for training the surrogate model. Defaults to 1000.</p> <code>1000</code> <code>base_model</code> <code>BaseEstimator | None</code> <p>The base model to be used for training the surrogate model. Defaults to RandomForestRegressor.</p> <code>None</code> <p>Returns:</p> Type Description <code>ExplanationTask</code> <p>An ExplanationTask instance.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>@staticmethod\ndef from_function_multidata(\n    config_space: ConfigurationSpace,\n    functions: list[Callable[[Configuration], float]],\n    n_samples: int = 1_000,\n    base_model: BaseEstimator | None = None,\n) -&gt; ExplanationTask:\n    \"\"\"Create an ExplanationTask from a list of functions that evaluate configurations.\n\n    Args:\n        config_space: The configuration space.\n        functions: A list of callables that take a configuration and returns its performance.\n        n_samples: The number of configurations to sample for training the surrogate model. Defaults to 1000.\n        base_model: The base model to be used for training the surrogate model. Defaults to RandomForestRegressor.\n\n    Returns:\n        An ExplanationTask instance.\n\n    \"\"\"\n    surrogate_model_list = [\n        ExplanationTask.from_function(config_space, fun, n_samples, base_model).get_single_surrogate_model()\n        for fun in functions\n    ]\n    return ExplanationTask(config_space=config_space, surrogate_model=surrogate_model_list)\n</code></pre>"},{"location":"api/task/#hypershap.task.ExplanationTask.get_hyperparameter_names","title":"<code>get_hyperparameter_names()</code>","text":"<p>Return the names of the hyperparameters in the configuration space.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of hyperparameter names.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>def get_hyperparameter_names(self) -&gt; list[str]:\n    \"\"\"Return the names of the hyperparameters in the configuration space.\n\n    Returns:\n        A list of hyperparameter names.\n\n    \"\"\"\n    return list(self.config_space.keys())\n</code></pre>"},{"location":"api/task/#hypershap.task.ExplanationTask.get_num_hyperparameters","title":"<code>get_num_hyperparameters()</code>","text":"<p>Return the number of hyperparameters in the configuration space.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of hyperparameters.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>def get_num_hyperparameters(self) -&gt; int:\n    \"\"\"Return the number of hyperparameters in the configuration space.\n\n    Returns:\n        The number of hyperparameters.\n\n    \"\"\"\n    return len(self.config_space)\n</code></pre>"},{"location":"api/task/#hypershap.task.ExplanationTask.get_single_surrogate_model","title":"<code>get_single_surrogate_model()</code>","text":"<p>Return the surrogate model for the explanation task.</p> <p>Returns:</p> Type Description <code>SurrogateModel</code> <p>The surrogate model for the explanation task.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>def get_single_surrogate_model(self) -&gt; SurrogateModel:\n    \"\"\"Return the surrogate model for the explanation task.\n\n    Returns:\n        The surrogate model for the explanation task.\n\n    \"\"\"\n    if isinstance(self.surrogate_model, list):\n        raise TypeError\n\n    return self.surrogate_model\n</code></pre>"},{"location":"api/task/#hypershap.task.ExplanationTask.get_surrogate_model_list","title":"<code>get_surrogate_model_list()</code>","text":"<p>Return the list of surrogate models for the explanation task.</p> <p>Returns:</p> Type Description <code>list[SurrogateModel]</code> <p>The list of surrogate models for the explanation task.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>def get_surrogate_model_list(self) -&gt; list[SurrogateModel]:\n    \"\"\"Return the list of surrogate models for the explanation task.\n\n    Returns:\n        The list of surrogate models for the explanation task.\n\n    \"\"\"\n    if not isinstance(self.surrogate_model, list):\n        raise TypeError\n\n    return self.surrogate_model\n</code></pre>"},{"location":"api/task/#hypershap.task.ExplanationTask.is_multi_data","title":"<code>is_multi_data()</code>","text":"<p>Return if the explanation task is a multi-data task.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the explanation task is a multi-data task.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>def is_multi_data(self) -&gt; bool:\n    \"\"\"Return if the explanation task is a multi-data task.\n\n    Returns:\n        True if the explanation task is a multi-data task.\n\n    \"\"\"\n    return isinstance(self.surrogate_model, list)\n</code></pre>"},{"location":"api/task/#hypershap.task.MistunabilityExplanationTask","title":"<code>MistunabilityExplanationTask</code>","text":"<p>               Bases: <code>BaselineExplanationTask</code></p> <p>Defines a mistunability explanation task.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>class MistunabilityExplanationTask(BaselineExplanationTask):\n    \"\"\"Defines a mistunability explanation task.\"\"\"\n\n    def __init__(\n        self,\n        config_space: ConfigurationSpace,\n        surrogate_model: SurrogateModel | list[SurrogateModel],\n        baseline_config: Configuration,\n    ) -&gt; None:\n        \"\"\"Initialize a MistunabilityExplanationTask.\n\n        Args:\n            config_space: The configuration space.\n            surrogate_model: The (list of) surrogate model(s) used for the explanation task.\n            baseline_config: The baseline configuration.\n\n        \"\"\"\n        super().__init__(config_space, surrogate_model, baseline_config)\n</code></pre>"},{"location":"api/task/#hypershap.task.MistunabilityExplanationTask.__init__","title":"<code>__init__(config_space, surrogate_model, baseline_config)</code>","text":"<p>Initialize a MistunabilityExplanationTask.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>surrogate_model</code> <code>SurrogateModel | list[SurrogateModel]</code> <p>The (list of) surrogate model(s) used for the explanation task.</p> required <code>baseline_config</code> <code>Configuration</code> <p>The baseline configuration.</p> required Source code in <code>src/hypershap/task.py</code> <pre><code>def __init__(\n    self,\n    config_space: ConfigurationSpace,\n    surrogate_model: SurrogateModel | list[SurrogateModel],\n    baseline_config: Configuration,\n) -&gt; None:\n    \"\"\"Initialize a MistunabilityExplanationTask.\n\n    Args:\n        config_space: The configuration space.\n        surrogate_model: The (list of) surrogate model(s) used for the explanation task.\n        baseline_config: The baseline configuration.\n\n    \"\"\"\n    super().__init__(config_space, surrogate_model, baseline_config)\n</code></pre>"},{"location":"api/task/#hypershap.task.MultiBaselineAblationExplanationTask","title":"<code>MultiBaselineAblationExplanationTask</code>","text":"<p>               Bases: <code>MultiBaselineExplanationTask</code></p> <p>Defines an ablation explanation task with multiple baseline configurations.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>class MultiBaselineAblationExplanationTask(MultiBaselineExplanationTask):\n    \"\"\"Defines an ablation explanation task with multiple baseline configurations.\"\"\"\n\n    def __init__(\n        self,\n        config_space: ConfigurationSpace,\n        surrogate_model: SurrogateModel | list[SurrogateModel],\n        baseline_configs: list[Configuration],\n        config_of_interest: Configuration,\n    ) -&gt; None:\n        \"\"\"Initialize an MultiBaselineAblationExplanationTask with a list of baseline configurations.\n\n        Args:\n            config_space: The configuration space.\n            surrogate_model: The (list of) surrogate model(s) used for the explanation task.\n            baseline_configs: The baseline configurations.\n            config_of_interest: The configuration of interest.\n\n        \"\"\"\n        super().__init__(\n            config_space,\n            surrogate_model,\n            baseline_configs,\n        )\n        self.config_of_interest = config_of_interest\n</code></pre>"},{"location":"api/task/#hypershap.task.MultiBaselineAblationExplanationTask.__init__","title":"<code>__init__(config_space, surrogate_model, baseline_configs, config_of_interest)</code>","text":"<p>Initialize an MultiBaselineAblationExplanationTask with a list of baseline configurations.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>surrogate_model</code> <code>SurrogateModel | list[SurrogateModel]</code> <p>The (list of) surrogate model(s) used for the explanation task.</p> required <code>baseline_configs</code> <code>list[Configuration]</code> <p>The baseline configurations.</p> required <code>config_of_interest</code> <code>Configuration</code> <p>The configuration of interest.</p> required Source code in <code>src/hypershap/task.py</code> <pre><code>def __init__(\n    self,\n    config_space: ConfigurationSpace,\n    surrogate_model: SurrogateModel | list[SurrogateModel],\n    baseline_configs: list[Configuration],\n    config_of_interest: Configuration,\n) -&gt; None:\n    \"\"\"Initialize an MultiBaselineAblationExplanationTask with a list of baseline configurations.\n\n    Args:\n        config_space: The configuration space.\n        surrogate_model: The (list of) surrogate model(s) used for the explanation task.\n        baseline_configs: The baseline configurations.\n        config_of_interest: The configuration of interest.\n\n    \"\"\"\n    super().__init__(\n        config_space,\n        surrogate_model,\n        baseline_configs,\n    )\n    self.config_of_interest = config_of_interest\n</code></pre>"},{"location":"api/task/#hypershap.task.MultiBaselineExplanationTask","title":"<code>MultiBaselineExplanationTask</code>","text":"<p>               Bases: <code>ExplanationTask</code></p> <p>Defines an explanation task with multiple baseline configurations.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>class MultiBaselineExplanationTask(ExplanationTask):\n    \"\"\"Defines an explanation task with multiple baseline configurations.\"\"\"\n\n    def __init__(\n        self,\n        config_space: ConfigurationSpace,\n        surrogate_model: SurrogateModel | list[SurrogateModel],\n        baseline_configs: list[Configuration],\n    ) -&gt; None:\n        \"\"\"Initialize a MultiBaselineExplanationTask with a list of baseline configurations.\n\n        Args:\n            config_space: The configuration space.\n            surrogate_model: The (list of) surrogate model(s) used for the explanation task.\n            baseline_configs: A list of baseline configurations.\n\n        \"\"\"\n        super().__init__(config_space, surrogate_model)\n        self.baseline_configs = baseline_configs\n</code></pre>"},{"location":"api/task/#hypershap.task.MultiBaselineExplanationTask.__init__","title":"<code>__init__(config_space, surrogate_model, baseline_configs)</code>","text":"<p>Initialize a MultiBaselineExplanationTask with a list of baseline configurations.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>surrogate_model</code> <code>SurrogateModel | list[SurrogateModel]</code> <p>The (list of) surrogate model(s) used for the explanation task.</p> required <code>baseline_configs</code> <code>list[Configuration]</code> <p>A list of baseline configurations.</p> required Source code in <code>src/hypershap/task.py</code> <pre><code>def __init__(\n    self,\n    config_space: ConfigurationSpace,\n    surrogate_model: SurrogateModel | list[SurrogateModel],\n    baseline_configs: list[Configuration],\n) -&gt; None:\n    \"\"\"Initialize a MultiBaselineExplanationTask with a list of baseline configurations.\n\n    Args:\n        config_space: The configuration space.\n        surrogate_model: The (list of) surrogate model(s) used for the explanation task.\n        baseline_configs: A list of baseline configurations.\n\n    \"\"\"\n    super().__init__(config_space, surrogate_model)\n    self.baseline_configs = baseline_configs\n</code></pre>"},{"location":"api/task/#hypershap.task.OptimizerBiasExplanationTask","title":"<code>OptimizerBiasExplanationTask</code>","text":"<p>               Bases: <code>ExplanationTask</code></p> <p>Defines an optimizer bias explanation task.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>class OptimizerBiasExplanationTask(ExplanationTask):\n    \"\"\"Defines an optimizer bias explanation task.\"\"\"\n\n    def __init__(\n        self,\n        config_space: ConfigurationSpace,\n        surrogate_model: SurrogateModel | list[SurrogateModel],\n        optimizer_of_interest: ConfigSpaceSearcher,\n        optimizer_ensemble: list[ConfigSpaceSearcher],\n    ) -&gt; None:\n        \"\"\"Initialize an OptimizerBiasExplanationTask.\n\n        Args:\n            config_space: The configuration space.\n            surrogate_model: The (list of) surrogate model(s) used for the explanation task.\n            optimizer_of_interest: The optimizer of interest.\n            optimizer_ensemble: The ensemble of optimizers.\n\n        \"\"\"\n        super().__init__(config_space, surrogate_model)\n        self.optimizer_of_interest = optimizer_of_interest\n        self.optimizer_ensemble = optimizer_ensemble\n</code></pre>"},{"location":"api/task/#hypershap.task.OptimizerBiasExplanationTask.__init__","title":"<code>__init__(config_space, surrogate_model, optimizer_of_interest, optimizer_ensemble)</code>","text":"<p>Initialize an OptimizerBiasExplanationTask.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>surrogate_model</code> <code>SurrogateModel | list[SurrogateModel]</code> <p>The (list of) surrogate model(s) used for the explanation task.</p> required <code>optimizer_of_interest</code> <code>ConfigSpaceSearcher</code> <p>The optimizer of interest.</p> required <code>optimizer_ensemble</code> <code>list[ConfigSpaceSearcher]</code> <p>The ensemble of optimizers.</p> required Source code in <code>src/hypershap/task.py</code> <pre><code>def __init__(\n    self,\n    config_space: ConfigurationSpace,\n    surrogate_model: SurrogateModel | list[SurrogateModel],\n    optimizer_of_interest: ConfigSpaceSearcher,\n    optimizer_ensemble: list[ConfigSpaceSearcher],\n) -&gt; None:\n    \"\"\"Initialize an OptimizerBiasExplanationTask.\n\n    Args:\n        config_space: The configuration space.\n        surrogate_model: The (list of) surrogate model(s) used for the explanation task.\n        optimizer_of_interest: The optimizer of interest.\n        optimizer_ensemble: The ensemble of optimizers.\n\n    \"\"\"\n    super().__init__(config_space, surrogate_model)\n    self.optimizer_of_interest = optimizer_of_interest\n    self.optimizer_ensemble = optimizer_ensemble\n</code></pre>"},{"location":"api/task/#hypershap.task.SensitivityExplanationTask","title":"<code>SensitivityExplanationTask</code>","text":"<p>               Bases: <code>BaselineExplanationTask</code></p> <p>Defines a sensitivity explanation task.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>class SensitivityExplanationTask(BaselineExplanationTask):\n    \"\"\"Defines a sensitivity explanation task.\"\"\"\n\n    def __init__(\n        self,\n        config_space: ConfigurationSpace,\n        surrogate_model: SurrogateModel | list[SurrogateModel],\n        baseline_config: Configuration,\n    ) -&gt; None:\n        \"\"\"Initialize a SensitivityExplanationTask.\n\n        Args:\n            config_space: The configuration space.\n            surrogate_model: The (list of) surrogate model(s) used for the explanation task.\n            baseline_config: The baseline configuration.\n\n        \"\"\"\n        super().__init__(config_space, surrogate_model, baseline_config)\n</code></pre>"},{"location":"api/task/#hypershap.task.SensitivityExplanationTask.__init__","title":"<code>__init__(config_space, surrogate_model, baseline_config)</code>","text":"<p>Initialize a SensitivityExplanationTask.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>surrogate_model</code> <code>SurrogateModel | list[SurrogateModel]</code> <p>The (list of) surrogate model(s) used for the explanation task.</p> required <code>baseline_config</code> <code>Configuration</code> <p>The baseline configuration.</p> required Source code in <code>src/hypershap/task.py</code> <pre><code>def __init__(\n    self,\n    config_space: ConfigurationSpace,\n    surrogate_model: SurrogateModel | list[SurrogateModel],\n    baseline_config: Configuration,\n) -&gt; None:\n    \"\"\"Initialize a SensitivityExplanationTask.\n\n    Args:\n        config_space: The configuration space.\n        surrogate_model: The (list of) surrogate model(s) used for the explanation task.\n        baseline_config: The baseline configuration.\n\n    \"\"\"\n    super().__init__(config_space, surrogate_model, baseline_config)\n</code></pre>"},{"location":"api/task/#hypershap.task.TunabilityExplanationTask","title":"<code>TunabilityExplanationTask</code>","text":"<p>               Bases: <code>BaselineExplanationTask</code></p> <p>Defines a tunability explanation task.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>class TunabilityExplanationTask(BaselineExplanationTask):\n    \"\"\"Defines a tunability explanation task.\"\"\"\n\n    def __init__(\n        self,\n        config_space: ConfigurationSpace,\n        surrogate_model: SurrogateModel | list[SurrogateModel],\n        baseline_config: Configuration,\n    ) -&gt; None:\n        \"\"\"Initialize a TunabilityExplanationTask.\n\n        Args:\n            config_space: The configuration space.\n            surrogate_model: The (list of) surrogate model(s) used for the explanation task.\n            baseline_config: The baseline configuration.\n\n        \"\"\"\n        super().__init__(config_space, surrogate_model, baseline_config)\n</code></pre>"},{"location":"api/task/#hypershap.task.TunabilityExplanationTask.__init__","title":"<code>__init__(config_space, surrogate_model, baseline_config)</code>","text":"<p>Initialize a TunabilityExplanationTask.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>surrogate_model</code> <code>SurrogateModel | list[SurrogateModel]</code> <p>The (list of) surrogate model(s) used for the explanation task.</p> required <code>baseline_config</code> <code>Configuration</code> <p>The baseline configuration.</p> required Source code in <code>src/hypershap/task.py</code> <pre><code>def __init__(\n    self,\n    config_space: ConfigurationSpace,\n    surrogate_model: SurrogateModel | list[SurrogateModel],\n    baseline_config: Configuration,\n) -&gt; None:\n    \"\"\"Initialize a TunabilityExplanationTask.\n\n    Args:\n        config_space: The configuration space.\n        surrogate_model: The (list of) surrogate model(s) used for the explanation task.\n        baseline_config: The baseline configuration.\n\n    \"\"\"\n    super().__init__(config_space, surrogate_model, baseline_config)\n</code></pre>"},{"location":"api/utils/","title":"Utils","text":"<p>Utils module for specifying custom error classes and config space search interfaces.</p> <p>This module defines specific error classes for simpler debugging and interfaces for searching config spaces.</p>"},{"location":"api/utils/#hypershap.utils.Aggregation","title":"<code>Aggregation</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Enum of aggregation functions for summarizing numpy arrays.</p> Source code in <code>src/hypershap/utils.py</code> <pre><code>class Aggregation(Enum):\n    \"\"\"Enum of aggregation functions for summarizing numpy arrays.\"\"\"\n\n    AVG = \"avg\"\n    MAX = \"max\"\n    MIN = \"min\"\n    VAR = \"var\"\n</code></pre>"},{"location":"api/utils/#hypershap.utils.ConfigSpaceSearcher","title":"<code>ConfigSpaceSearcher</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for searching the configuration space.</p> <p>Provides an interface for retrieving performance values based on a coalition of hyperparameters.</p> Source code in <code>src/hypershap/utils.py</code> <pre><code>class ConfigSpaceSearcher(ABC):\n    \"\"\"Abstract base class for searching the configuration space.\n\n    Provides an interface for retrieving performance values based on a coalition\n    of hyperparameters.\n    \"\"\"\n\n    def __init__(\n        self,\n        explanation_task: BaselineExplanationTask,\n        mode: Aggregation,\n    ) -&gt; None:\n        \"\"\"Initialize the searcher with the explanation task.\n\n        Args:\n            explanation_task: The explanation task containing the configuration\n                space and surrogate model.\n            mode: The aggregation mode for performance values.\n\n        \"\"\"\n        self.explanation_task = explanation_task\n        self.mode = mode\n\n    @abstractmethod\n    def search(self, coalition: np.ndarray) -&gt; float:\n        \"\"\"Search the configuration space based on the coalition.\n\n        Args:\n            coalition: A boolean array indicating which hyperparameters are\n                constrained by the coalition.\n\n        Returns:\n            The aggregated performance value based on the search results.\n\n        \"\"\"\n</code></pre>"},{"location":"api/utils/#hypershap.utils.ConfigSpaceSearcher.__init__","title":"<code>__init__(explanation_task, mode)</code>","text":"<p>Initialize the searcher with the explanation task.</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>BaselineExplanationTask</code> <p>The explanation task containing the configuration space and surrogate model.</p> required <code>mode</code> <code>Aggregation</code> <p>The aggregation mode for performance values.</p> required Source code in <code>src/hypershap/utils.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: BaselineExplanationTask,\n    mode: Aggregation,\n) -&gt; None:\n    \"\"\"Initialize the searcher with the explanation task.\n\n    Args:\n        explanation_task: The explanation task containing the configuration\n            space and surrogate model.\n        mode: The aggregation mode for performance values.\n\n    \"\"\"\n    self.explanation_task = explanation_task\n    self.mode = mode\n</code></pre>"},{"location":"api/utils/#hypershap.utils.ConfigSpaceSearcher.search","title":"<code>search(coalition)</code>  <code>abstractmethod</code>","text":"<p>Search the configuration space based on the coalition.</p> <p>Parameters:</p> Name Type Description Default <code>coalition</code> <code>ndarray</code> <p>A boolean array indicating which hyperparameters are constrained by the coalition.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The aggregated performance value based on the search results.</p> Source code in <code>src/hypershap/utils.py</code> <pre><code>@abstractmethod\ndef search(self, coalition: np.ndarray) -&gt; float:\n    \"\"\"Search the configuration space based on the coalition.\n\n    Args:\n        coalition: A boolean array indicating which hyperparameters are\n            constrained by the coalition.\n\n    Returns:\n        The aggregated performance value based on the search results.\n\n    \"\"\"\n</code></pre>"},{"location":"api/utils/#hypershap.utils.RandomConfigSpaceSearcher","title":"<code>RandomConfigSpaceSearcher</code>","text":"<p>               Bases: <code>ConfigSpaceSearcher</code></p> <p>A searcher that randomly samples the configuration space and evaluates them using the surrogate model.</p> <p>Useful for establishing baseline performance or approximating game values.</p> Source code in <code>src/hypershap/utils.py</code> <pre><code>class RandomConfigSpaceSearcher(ConfigSpaceSearcher):\n    \"\"\"A searcher that randomly samples the configuration space and evaluates them using the surrogate model.\n\n    Useful for establishing baseline performance or approximating game values.\n    \"\"\"\n\n    def __init__(\n        self,\n        explanation_task: BaselineExplanationTask,\n        mode: Aggregation = Aggregation.MAX,\n        n_samples: int = 10_000,\n        seed: int | None = 0,\n    ) -&gt; None:\n        \"\"\"Initialize the random configuration space searcher.\n\n        Args:\n            explanation_task: The explanation task containing the configuration\n                space and surrogate model.\n            mode: The aggregation mode for performance values.\n            n_samples: The number of configurations to sample.\n            seed: The random seed for sampling configurations from the config space.\n\n        \"\"\"\n        super().__init__(explanation_task, mode=mode)\n        cs = deepcopy(explanation_task.config_space)\n        if seed is not None:\n            cs.seed(seed)\n        sampled_configurations = cs.sample_configuration(size=n_samples)\n        self.random_sample = np.array([config.get_array() for config in sampled_configurations])\n\n        # cache coalition values to ensure monotonicity for min/max\n        self.coalition_cache = {}\n\n    def _is_valid(self, config: np.ndarray) -&gt; bool:\n        \"\"\"Check whether a configuration is valid with respect to conditions of the configuration space.\"\"\"\n        try:\n            self.explanation_task.config_space.check_configuration_vector_representation(config)\n        except (\n            ActiveHyperparameterNotSetError,\n            IllegalVectorizedValueError,\n            InactiveHyperparameterSetError,\n            ForbiddenValueError,\n        ):\n            return False\n        else:\n            return True\n\n    def search(self, coalition: np.ndarray) -&gt; float:\n        \"\"\"Search the configuration space based on the coalition.\n\n        Args:\n            coalition: A boolean array indicating which hyperparameters are\n                constrained by the coalition.\n\n        Returns:\n            The aggregated performance value based on the search results.\n\n        \"\"\"\n        # copy the sampled configurations\n        temp_random_sample = self.random_sample.copy()\n\n        # blind configurations according to coalition\n        blind_coalition = ~coalition\n        column_index = np.where(blind_coalition)\n        temp_random_sample[:, column_index] = self.explanation_task.baseline_config.get_array()[column_index]\n\n        # in case of conditions in the config space, it might happen that through blinding hyperparameter values\n        # configurations might become invalid and those should not be considered for calculating vals\n        if len(self.explanation_task.config_space.conditions) &gt; 0:\n            # filter invalid configurations\n            validity = np.apply_along_axis(self._is_valid, axis=1, arr=temp_random_sample)\n            filtered_samples = temp_random_sample[validity]\n\n            if len(filtered_samples) &lt; 0.05 * len(temp_random_sample):  # pragma: no cover\n                logger.warning(\n                    \"WARNING: Due to blinding less than 5% of the samples in the random search remain valid. \"\n                    \"Consider increasing the sampling budget of the random search.\",\n                )\n\n            # predict performance values with the help of the surrogate model for the filtered configurations\n            vals: np.ndarray = np.array(self.explanation_task.get_single_surrogate_model().evaluate(filtered_samples))\n        else:\n            vals: np.ndarray = np.array(self.explanation_task.get_single_surrogate_model().evaluate(temp_random_sample))\n\n        return evaluate_aggregation(self.mode, vals)\n</code></pre>"},{"location":"api/utils/#hypershap.utils.RandomConfigSpaceSearcher.__init__","title":"<code>__init__(explanation_task, mode=Aggregation.MAX, n_samples=10000, seed=0)</code>","text":"<p>Initialize the random configuration space searcher.</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>BaselineExplanationTask</code> <p>The explanation task containing the configuration space and surrogate model.</p> required <code>mode</code> <code>Aggregation</code> <p>The aggregation mode for performance values.</p> <code>MAX</code> <code>n_samples</code> <code>int</code> <p>The number of configurations to sample.</p> <code>10000</code> <code>seed</code> <code>int | None</code> <p>The random seed for sampling configurations from the config space.</p> <code>0</code> Source code in <code>src/hypershap/utils.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: BaselineExplanationTask,\n    mode: Aggregation = Aggregation.MAX,\n    n_samples: int = 10_000,\n    seed: int | None = 0,\n) -&gt; None:\n    \"\"\"Initialize the random configuration space searcher.\n\n    Args:\n        explanation_task: The explanation task containing the configuration\n            space and surrogate model.\n        mode: The aggregation mode for performance values.\n        n_samples: The number of configurations to sample.\n        seed: The random seed for sampling configurations from the config space.\n\n    \"\"\"\n    super().__init__(explanation_task, mode=mode)\n    cs = deepcopy(explanation_task.config_space)\n    if seed is not None:\n        cs.seed(seed)\n    sampled_configurations = cs.sample_configuration(size=n_samples)\n    self.random_sample = np.array([config.get_array() for config in sampled_configurations])\n\n    # cache coalition values to ensure monotonicity for min/max\n    self.coalition_cache = {}\n</code></pre>"},{"location":"api/utils/#hypershap.utils.RandomConfigSpaceSearcher.search","title":"<code>search(coalition)</code>","text":"<p>Search the configuration space based on the coalition.</p> <p>Parameters:</p> Name Type Description Default <code>coalition</code> <code>ndarray</code> <p>A boolean array indicating which hyperparameters are constrained by the coalition.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The aggregated performance value based on the search results.</p> Source code in <code>src/hypershap/utils.py</code> <pre><code>def search(self, coalition: np.ndarray) -&gt; float:\n    \"\"\"Search the configuration space based on the coalition.\n\n    Args:\n        coalition: A boolean array indicating which hyperparameters are\n            constrained by the coalition.\n\n    Returns:\n        The aggregated performance value based on the search results.\n\n    \"\"\"\n    # copy the sampled configurations\n    temp_random_sample = self.random_sample.copy()\n\n    # blind configurations according to coalition\n    blind_coalition = ~coalition\n    column_index = np.where(blind_coalition)\n    temp_random_sample[:, column_index] = self.explanation_task.baseline_config.get_array()[column_index]\n\n    # in case of conditions in the config space, it might happen that through blinding hyperparameter values\n    # configurations might become invalid and those should not be considered for calculating vals\n    if len(self.explanation_task.config_space.conditions) &gt; 0:\n        # filter invalid configurations\n        validity = np.apply_along_axis(self._is_valid, axis=1, arr=temp_random_sample)\n        filtered_samples = temp_random_sample[validity]\n\n        if len(filtered_samples) &lt; 0.05 * len(temp_random_sample):  # pragma: no cover\n            logger.warning(\n                \"WARNING: Due to blinding less than 5% of the samples in the random search remain valid. \"\n                \"Consider increasing the sampling budget of the random search.\",\n            )\n\n        # predict performance values with the help of the surrogate model for the filtered configurations\n        vals: np.ndarray = np.array(self.explanation_task.get_single_surrogate_model().evaluate(filtered_samples))\n    else:\n        vals: np.ndarray = np.array(self.explanation_task.get_single_surrogate_model().evaluate(temp_random_sample))\n\n    return evaluate_aggregation(self.mode, vals)\n</code></pre>"},{"location":"api/utils/#hypershap.utils.evaluate_aggregation","title":"<code>evaluate_aggregation(aggregation, values)</code>","text":"<p>Evaluate an aggregation function for a numpy array summarizing it to a single float.</p> Source code in <code>src/hypershap/utils.py</code> <pre><code>def evaluate_aggregation(aggregation: Aggregation, values: np.ndarray) -&gt; float:\n    \"\"\"Evaluate an aggregation function for a numpy array summarizing it to a single float.\"\"\"\n    if aggregation == Aggregation.AVG:\n        return values.mean()\n    if aggregation == Aggregation.MAX:\n        return values.max()\n    if aggregation == Aggregation.MIN:\n        return values.min()\n    return values.var()\n</code></pre>"}]}