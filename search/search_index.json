{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"hypershap","text":"<p>HyperSHAP is a post-hoc explanation method for hyperparameter optimization.</p>"},{"location":"modules/","title":"API Reference","text":""},{"location":"modules/#hypershap","title":"HyperSHAP","text":"<p>HyperSHAP main interface to work on explanation for a given task.</p> <p>This module provides the main interface for working with HyperSHAP to access explanations regarding ablation, tunability, sensitivity, and optimizer bias.</p>"},{"location":"modules/#hypershap.hypershap.HyperSHAP","title":"<code>HyperSHAP</code>","text":"<p>A class for computing and visualizing HyperSHAP Shapley values and interactions.</p> <p>Attributes:</p> Name Type Description <code>explanation_task</code> <code>ExplanationTask</code> <p>The task responsible for generating explanations.</p> <code>last_interaction_values</code> <code>InteractionValues | None</code> <p>The cached interaction values for plotting shortcuts.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>ExplanationTask): Initializes the HyperSHAP instance with an explanation task.</p> <code>ablation</code> <p>Configuration, baseline_config: Configuration, index: str = \"FSII\", order: int = 2) -&gt; InteractionValues: Computes and returns the interaction values for ablation analysis.</p> <code>tunability</code> <p>Configuration | None, index: str = \"FSII\", order: int = 2) -&gt; InteractionValues: Computes and returns the interaction values for tunability analysis.</p> <code>optimizer_bias</code> <p>ConfigSpaceSearcher, optimizer_ensemble: list[ConfigSpaceSearcher], index: str = \"FSII\", order: int = 2) -&gt; InteractionValues: Computes and returns the interaction values for optimizer bias analysis.</p> <code>plot_si_graph</code> <p>InteractionValues | None = None, save_path: str | None = None): Plots the SHAP interaction values as a graph.</p> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>class HyperSHAP:\n    \"\"\"A class for computing and visualizing HyperSHAP Shapley values and interactions.\n\n    Attributes:\n        explanation_task (ExplanationTask): The task responsible for generating explanations.\n        last_interaction_values (InteractionValues | None): The cached interaction values for plotting shortcuts.\n\n    Methods:\n        __init__(explanation_task: ExplanationTask):\n            Initializes the HyperSHAP instance with an explanation task.\n\n        ablation(config_of_interest: Configuration, baseline_config: Configuration, index: str = \"FSII\", order: int = 2) -&gt; InteractionValues:\n            Computes and returns the interaction values for ablation analysis.\n\n        tunability(baseline_config: Configuration | None, index: str = \"FSII\", order: int = 2) -&gt; InteractionValues:\n            Computes and returns the interaction values for tunability analysis.\n\n        optimizer_bias(optimizer_of_interest: ConfigSpaceSearcher, optimizer_ensemble: list[ConfigSpaceSearcher], index: str = \"FSII\", order: int = 2) -&gt; InteractionValues:\n            Computes and returns the interaction values for optimizer bias analysis.\n\n        plot_si_graph(interaction_values: InteractionValues | None = None, save_path: str | None = None):\n            Plots the SHAP interaction values as a graph.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        explanation_task: ExplanationTask,\n        n_workers: int | None = None,\n        verbose: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize the HyperSHAP instance with an explanation task.\n\n        Args:\n            explanation_task (ExplanationTask): The task responsible for generating explanations.\n            n_workers: The number of worker threads to use for parallel evaluation\n                of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n                speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n            verbose:  A boolean indicating whether to print verbose messages during\n                computation. Defaults to None.  When set to True, the method prints\n                debugging information and progress updates.\n\n        \"\"\"\n        self.explanation_task = explanation_task\n        self.last_interaction_values = None\n        self.n_workers = n_workers\n        self.verbose = verbose\n\n    def __get_interaction_values(self, game: AbstractHPIGame, index: str = \"FSII\", order: int = 2) -&gt; InteractionValues:\n        # instantiate exact computer if number of hyperparameters is small enough\n        ec = ExactComputer(n_players=game.get_num_hyperparameters(), game=game)  # pyright: ignore\n\n        # compute interaction values with the given index and order\n        interaction_values = ec(index=index, order=order)\n\n        # cache current interaction values for plotting shortcuts\n        self.last_interaction_values = interaction_values\n\n        return interaction_values\n\n    def ablation(\n        self,\n        config_of_interest: Configuration,\n        baseline_config: Configuration,\n        index: str = \"FSII\",\n        order: int = 2,\n    ) -&gt; InteractionValues:\n        \"\"\"Compute and return the interaction values for ablation analysis.\n\n        Args:\n            config_of_interest (Configuration): The configuration of interest.\n            baseline_config (Configuration): The baseline configuration.\n            index (str, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n            order (int, optional): The order of the interaction values. Defaults to 2.\n\n        Returns:\n            InteractionValues: The computed interaction values.\n\n        \"\"\"\n        # setup explanation task\n        ablation_task: AblationExplanationTask = AblationExplanationTask(\n            config_space=self.explanation_task.config_space,\n            surrogate_model=self.explanation_task.surrogate_model,\n            baseline_config=baseline_config,\n            config_of_interest=config_of_interest,\n        )\n\n        # setup ablation game and get interaction values\n        ag = AblationGame(\n            explanation_task=ablation_task,\n            n_workers=self.n_workers,\n            verbose=self.verbose,\n        )\n        return self.__get_interaction_values(game=ag, index=index, order=order)\n\n    def tunability(\n        self,\n        baseline_config: Configuration | None = None,\n        index: str = \"FSII\",\n        order: int = 2,\n        n_samples: int = 10_000,\n    ) -&gt; InteractionValues:\n        \"\"\"Compute and return the interaction values for tunability analysis.\n\n        Args:\n            baseline_config (Configuration | None, optional): The baseline configuration. Defaults to None.\n            index (str, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n            order (int, optional): The order of the interaction values. Defaults to 2.\n            n_samples (int, optional): The number of samples to use for simulating HPO. Defaults to 10_000.\n\n        Returns:\n            InteractionValues: The computed interaction values.\n\n        \"\"\"\n        if baseline_config is None:\n            baseline_config = self.explanation_task.config_space.get_default_configuration()\n\n        # setup explanation task\n        tunability_task: TunabilityExplanationTask = TunabilityExplanationTask(\n            config_space=self.explanation_task.config_space,\n            surrogate_model=self.explanation_task.surrogate_model,\n            baseline_config=baseline_config,\n        )\n\n        # setup tunability game and get interaction values\n        tg = TunabilityGame(\n            explanation_task=tunability_task,\n            cs_searcher=RandomConfigSpaceSearcher(\n                explanation_task=tunability_task,\n                n_samples=n_samples,\n                mode=\"max\",\n            ),\n            n_workers=self.n_workers,\n            verbose=self.verbose,\n        )\n        return self.__get_interaction_values(game=tg, index=index, order=order)\n\n    def sensitivity(\n        self,\n        baseline_config: Configuration | None = None,\n        index: str = \"FSII\",\n        order: int = 2,\n        n_samples: int = 10_000,\n    ) -&gt; InteractionValues:\n        \"\"\"Compute and return the interaction values for sensitivity analysis.\n\n        Args:\n            baseline_config (Configuration | None, optional): The baseline configuration. Defaults to None.\n            index (str, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n            order (int, optional): The order of the interaction values. Defaults to 2.\n            n_samples (int, optional): The number of samples to use for simulating HPO. Defaults to 10_000.\n\n        Returns:\n            InteractionValues: The computed interaction values.\n\n        \"\"\"\n        if baseline_config is None:\n            baseline_config = self.explanation_task.config_space.get_default_configuration()\n\n        # setup explanation task\n        sensitivity_task: SensitivityExplanationTask = SensitivityExplanationTask(\n            config_space=self.explanation_task.config_space,\n            surrogate_model=self.explanation_task.surrogate_model,\n            baseline_config=baseline_config,\n        )\n\n        # setup tunability game and get interaction values\n        tg = SensitivityGame(\n            explanation_task=sensitivity_task,\n            cs_searcher=RandomConfigSpaceSearcher(\n                explanation_task=sensitivity_task,\n                n_samples=n_samples,\n                mode=\"var\",\n            ),\n            n_workers=self.n_workers,\n            verbose=self.verbose,\n        )\n        return self.__get_interaction_values(game=tg, index=index, order=order)\n\n    def mistunability(\n        self,\n        baseline_config: Configuration | None = None,\n        index: str = \"FSII\",\n        order: int = 2,\n        n_samples: int = 10_000,\n    ) -&gt; InteractionValues:\n        \"\"\"Compute and return the interaction values for mistunability analysis.\n\n        Args:\n            baseline_config (Configuration | None, optional): The baseline configuration. Defaults to None.\n            index (str, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n            order (int, optional): The order of the interaction values. Defaults to 2.\n            n_samples (int, optional): The number of samples to use for simulating HPO. Defaults to 10_000.\n\n        Returns:\n            InteractionValues: The computed interaction values.\n\n        \"\"\"\n        if baseline_config is None:\n            baseline_config = self.explanation_task.config_space.get_default_configuration()\n\n        # setup explanation task\n        mistunability_task: MistunabilityExplanationTask = MistunabilityExplanationTask(\n            config_space=self.explanation_task.config_space,\n            surrogate_model=self.explanation_task.surrogate_model,\n            baseline_config=baseline_config,\n        )\n\n        # setup tunability game and get interaction values\n        tg = MistunabilityGame(\n            explanation_task=mistunability_task,\n            cs_searcher=RandomConfigSpaceSearcher(\n                explanation_task=mistunability_task,\n                n_samples=n_samples,\n                mode=\"min\",\n            ),\n            n_workers=self.n_workers,\n            verbose=self.verbose,\n        )\n        return self.__get_interaction_values(game=tg, index=index, order=order)\n\n    def optimizer_bias(\n        self,\n        optimizer_of_interest: ConfigSpaceSearcher,\n        optimizer_ensemble: list[ConfigSpaceSearcher],\n        index: str = \"FSII\",\n        order: int = 2,\n    ) -&gt; InteractionValues:\n        \"\"\"Compute and return the interaction values for optimizer bias analysis.\n\n        Args:\n            optimizer_of_interest (ConfigSpaceSearcher): The optimizer of interest.\n            optimizer_ensemble (list[ConfigSpaceSearcher]): The ensemble of optimizers.\n            index (str, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n            order (int, optional): The order of the interaction values. Defaults to 2.\n\n        Returns:\n            InteractionValues: The computed interaction values.\n\n        \"\"\"\n        # setup explanation task\n        optimizer_bias_task: OptimizerBiasExplanationTask = OptimizerBiasExplanationTask(\n            config_space=self.explanation_task.config_space,\n            surrogate_model=self.explanation_task.surrogate_model,\n            optimizer_of_interest=optimizer_of_interest,\n            optimizer_ensemble=optimizer_ensemble,\n        )\n\n        # setup optimizer bias game and get interaction values\n        og = OptimizerBiasGame(explanation_task=optimizer_bias_task, n_workers=self.n_workers, verbose=self.verbose)\n        return self.__get_interaction_values(game=og, index=index, order=order)\n\n    def plot_si_graph(self, interaction_values: InteractionValues | None = None, save_path: str | None = None) -&gt; None:\n        \"\"\"Plot the SHAP interaction values as a graph.\n\n        Args:\n            interaction_values (InteractionValues | None, optional): The interaction values to plot. Defaults to None.\n            save_path (str | None, optional): The path to save the plot. Defaults to None.\n\n        \"\"\"\n        if interaction_values is None and self.last_interaction_values is None:\n            raise NoInteractionValuesError\n\n        # if given interaction values use those, else use cached interaction values\n        iv = interaction_values if interaction_values is not None else self.last_interaction_values\n\n        if not isinstance(iv, InteractionValues):\n            raise TypeError\n\n        hyperparameter_names = self.explanation_task.get_hyperparameter_names()\n\n        def get_circular_layout(n_players: int) -&gt; dict:\n            original_graph, graph_nodes = nx.Graph(), []\n            for i in range(n_players):\n                original_graph.add_node(i, label=i)\n                graph_nodes.append(i)\n            return nx.circular_layout(original_graph)\n\n        pos = get_circular_layout(n_players=self.explanation_task.get_num_hyperparameters())\n        iv.plot_si_graph(\n            show=False,\n            size_factor=3.0,\n            feature_names=hyperparameter_names,\n            pos=pos,\n            n_interactions=1_000,\n            compactness=1e50,\n        )\n        plt.tight_layout()\n\n        if save_path is not None:\n            plt.savefig(save_path)\n            logger.info(\"Saved SI graph to %s\", save_path)\n\n        plt.show()\n\n    def plot_upset(self, interaction_values: InteractionValues | None = None, save_path: str | None = None) -&gt; None:\n        \"\"\"Plot the SHAP interaction values as an upset plot graph.\n\n        Args:\n            interaction_values (InteractionValues | None, optional): The interaction values to plot. Defaults to None.\n            save_path (str | None, optional): The path to save the plot. Defaults to None.\n\n        \"\"\"\n        if interaction_values is None and self.last_interaction_values is None:\n            raise NoInteractionValuesError\n\n        # if given interaction values use those, else use cached interaction values\n        iv = interaction_values if interaction_values is not None else self.last_interaction_values\n\n        if not isinstance(iv, InteractionValues):\n            raise TypeError\n\n        hyperparameter_names = self.explanation_task.get_hyperparameter_names()\n\n        fig = iv.plot_upset(feature_names=hyperparameter_names, show=False)\n\n        if fig is None:\n            raise TypeError\n\n        ax = fig.get_axes()[0]\n        ax.set_ylabel(\"Performance Gain\")\n        # also add \"parameter\" to the y-axis label\n        ax = fig.get_axes()[1]\n        ax.set_ylabel(\"Hyperparameter\")\n\n        plt.tight_layout()\n\n        if save_path is not None:\n            plt.savefig(save_path)\n\n        plt.show()\n\n    def plot_force(self, interaction_values: InteractionValues | None = None, save_path: str | None = None) -&gt; None:\n        \"\"\"Plot the SHAP interaction values as a forceplot graph.\n\n        Args:\n            interaction_values: Interaction values to plot. Defaults to None.\n            save_path: The path to save the plot. Defaults to None.\n\n        \"\"\"\n        if interaction_values is None and self.last_interaction_values is None:\n            raise NoInteractionValuesError\n\n        # if given interaction values use those, else use cached interaction values\n        iv = interaction_values if interaction_values is not None else self.last_interaction_values\n\n        if not isinstance(iv, InteractionValues):\n            raise TypeError\n\n        hyperparameter_names = self.explanation_task.get_hyperparameter_names()\n\n        iv.plot_force(feature_names=np.array(hyperparameter_names), show=False)\n        plt.tight_layout()\n\n        if save_path is not None:\n            plt.savefig(save_path)\n\n        plt.show()\n</code></pre>"},{"location":"modules/#hypershap.hypershap.HyperSHAP.__init__","title":"<code>__init__(explanation_task, n_workers=None, verbose=None)</code>","text":"<p>Initialize the HyperSHAP instance with an explanation task.</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>ExplanationTask</code> <p>The task responsible for generating explanations.</p> required <code>n_workers</code> <code>int | None</code> <p>The number of worker threads to use for parallel evaluation of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.</p> <code>None</code> <code>verbose</code> <code>bool | None</code> <p>A boolean indicating whether to print verbose messages during computation. Defaults to None.  When set to True, the method prints debugging information and progress updates.</p> <code>None</code> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: ExplanationTask,\n    n_workers: int | None = None,\n    verbose: bool | None = None,\n) -&gt; None:\n    \"\"\"Initialize the HyperSHAP instance with an explanation task.\n\n    Args:\n        explanation_task (ExplanationTask): The task responsible for generating explanations.\n        n_workers: The number of worker threads to use for parallel evaluation\n            of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n            speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n        verbose:  A boolean indicating whether to print verbose messages during\n            computation. Defaults to None.  When set to True, the method prints\n            debugging information and progress updates.\n\n    \"\"\"\n    self.explanation_task = explanation_task\n    self.last_interaction_values = None\n    self.n_workers = n_workers\n    self.verbose = verbose\n</code></pre>"},{"location":"modules/#hypershap.hypershap.HyperSHAP.ablation","title":"<code>ablation(config_of_interest, baseline_config, index='FSII', order=2)</code>","text":"<p>Compute and return the interaction values for ablation analysis.</p> <p>Parameters:</p> Name Type Description Default <code>config_of_interest</code> <code>Configuration</code> <p>The configuration of interest.</p> required <code>baseline_config</code> <code>Configuration</code> <p>The baseline configuration.</p> required <code>index</code> <code>str</code> <p>The index to use for computing interaction values. Defaults to \"FSII\".</p> <code>'FSII'</code> <code>order</code> <code>int</code> <p>The order of the interaction values. Defaults to 2.</p> <code>2</code> <p>Returns:</p> Name Type Description <code>InteractionValues</code> <code>InteractionValues</code> <p>The computed interaction values.</p> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def ablation(\n    self,\n    config_of_interest: Configuration,\n    baseline_config: Configuration,\n    index: str = \"FSII\",\n    order: int = 2,\n) -&gt; InteractionValues:\n    \"\"\"Compute and return the interaction values for ablation analysis.\n\n    Args:\n        config_of_interest (Configuration): The configuration of interest.\n        baseline_config (Configuration): The baseline configuration.\n        index (str, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n        order (int, optional): The order of the interaction values. Defaults to 2.\n\n    Returns:\n        InteractionValues: The computed interaction values.\n\n    \"\"\"\n    # setup explanation task\n    ablation_task: AblationExplanationTask = AblationExplanationTask(\n        config_space=self.explanation_task.config_space,\n        surrogate_model=self.explanation_task.surrogate_model,\n        baseline_config=baseline_config,\n        config_of_interest=config_of_interest,\n    )\n\n    # setup ablation game and get interaction values\n    ag = AblationGame(\n        explanation_task=ablation_task,\n        n_workers=self.n_workers,\n        verbose=self.verbose,\n    )\n    return self.__get_interaction_values(game=ag, index=index, order=order)\n</code></pre>"},{"location":"modules/#hypershap.hypershap.HyperSHAP.mistunability","title":"<code>mistunability(baseline_config=None, index='FSII', order=2, n_samples=10000)</code>","text":"<p>Compute and return the interaction values for mistunability analysis.</p> <p>Parameters:</p> Name Type Description Default <code>baseline_config</code> <code>Configuration | None</code> <p>The baseline configuration. Defaults to None.</p> <code>None</code> <code>index</code> <code>str</code> <p>The index to use for computing interaction values. Defaults to \"FSII\".</p> <code>'FSII'</code> <code>order</code> <code>int</code> <p>The order of the interaction values. Defaults to 2.</p> <code>2</code> <code>n_samples</code> <code>int</code> <p>The number of samples to use for simulating HPO. Defaults to 10_000.</p> <code>10000</code> <p>Returns:</p> Name Type Description <code>InteractionValues</code> <code>InteractionValues</code> <p>The computed interaction values.</p> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def mistunability(\n    self,\n    baseline_config: Configuration | None = None,\n    index: str = \"FSII\",\n    order: int = 2,\n    n_samples: int = 10_000,\n) -&gt; InteractionValues:\n    \"\"\"Compute and return the interaction values for mistunability analysis.\n\n    Args:\n        baseline_config (Configuration | None, optional): The baseline configuration. Defaults to None.\n        index (str, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n        order (int, optional): The order of the interaction values. Defaults to 2.\n        n_samples (int, optional): The number of samples to use for simulating HPO. Defaults to 10_000.\n\n    Returns:\n        InteractionValues: The computed interaction values.\n\n    \"\"\"\n    if baseline_config is None:\n        baseline_config = self.explanation_task.config_space.get_default_configuration()\n\n    # setup explanation task\n    mistunability_task: MistunabilityExplanationTask = MistunabilityExplanationTask(\n        config_space=self.explanation_task.config_space,\n        surrogate_model=self.explanation_task.surrogate_model,\n        baseline_config=baseline_config,\n    )\n\n    # setup tunability game and get interaction values\n    tg = MistunabilityGame(\n        explanation_task=mistunability_task,\n        cs_searcher=RandomConfigSpaceSearcher(\n            explanation_task=mistunability_task,\n            n_samples=n_samples,\n            mode=\"min\",\n        ),\n        n_workers=self.n_workers,\n        verbose=self.verbose,\n    )\n    return self.__get_interaction_values(game=tg, index=index, order=order)\n</code></pre>"},{"location":"modules/#hypershap.hypershap.HyperSHAP.optimizer_bias","title":"<code>optimizer_bias(optimizer_of_interest, optimizer_ensemble, index='FSII', order=2)</code>","text":"<p>Compute and return the interaction values for optimizer bias analysis.</p> <p>Parameters:</p> Name Type Description Default <code>optimizer_of_interest</code> <code>ConfigSpaceSearcher</code> <p>The optimizer of interest.</p> required <code>optimizer_ensemble</code> <code>list[ConfigSpaceSearcher]</code> <p>The ensemble of optimizers.</p> required <code>index</code> <code>str</code> <p>The index to use for computing interaction values. Defaults to \"FSII\".</p> <code>'FSII'</code> <code>order</code> <code>int</code> <p>The order of the interaction values. Defaults to 2.</p> <code>2</code> <p>Returns:</p> Name Type Description <code>InteractionValues</code> <code>InteractionValues</code> <p>The computed interaction values.</p> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def optimizer_bias(\n    self,\n    optimizer_of_interest: ConfigSpaceSearcher,\n    optimizer_ensemble: list[ConfigSpaceSearcher],\n    index: str = \"FSII\",\n    order: int = 2,\n) -&gt; InteractionValues:\n    \"\"\"Compute and return the interaction values for optimizer bias analysis.\n\n    Args:\n        optimizer_of_interest (ConfigSpaceSearcher): The optimizer of interest.\n        optimizer_ensemble (list[ConfigSpaceSearcher]): The ensemble of optimizers.\n        index (str, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n        order (int, optional): The order of the interaction values. Defaults to 2.\n\n    Returns:\n        InteractionValues: The computed interaction values.\n\n    \"\"\"\n    # setup explanation task\n    optimizer_bias_task: OptimizerBiasExplanationTask = OptimizerBiasExplanationTask(\n        config_space=self.explanation_task.config_space,\n        surrogate_model=self.explanation_task.surrogate_model,\n        optimizer_of_interest=optimizer_of_interest,\n        optimizer_ensemble=optimizer_ensemble,\n    )\n\n    # setup optimizer bias game and get interaction values\n    og = OptimizerBiasGame(explanation_task=optimizer_bias_task, n_workers=self.n_workers, verbose=self.verbose)\n    return self.__get_interaction_values(game=og, index=index, order=order)\n</code></pre>"},{"location":"modules/#hypershap.hypershap.HyperSHAP.plot_force","title":"<code>plot_force(interaction_values=None, save_path=None)</code>","text":"<p>Plot the SHAP interaction values as a forceplot graph.</p> <p>Parameters:</p> Name Type Description Default <code>interaction_values</code> <code>InteractionValues | None</code> <p>Interaction values to plot. Defaults to None.</p> <code>None</code> <code>save_path</code> <code>str | None</code> <p>The path to save the plot. Defaults to None.</p> <code>None</code> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def plot_force(self, interaction_values: InteractionValues | None = None, save_path: str | None = None) -&gt; None:\n    \"\"\"Plot the SHAP interaction values as a forceplot graph.\n\n    Args:\n        interaction_values: Interaction values to plot. Defaults to None.\n        save_path: The path to save the plot. Defaults to None.\n\n    \"\"\"\n    if interaction_values is None and self.last_interaction_values is None:\n        raise NoInteractionValuesError\n\n    # if given interaction values use those, else use cached interaction values\n    iv = interaction_values if interaction_values is not None else self.last_interaction_values\n\n    if not isinstance(iv, InteractionValues):\n        raise TypeError\n\n    hyperparameter_names = self.explanation_task.get_hyperparameter_names()\n\n    iv.plot_force(feature_names=np.array(hyperparameter_names), show=False)\n    plt.tight_layout()\n\n    if save_path is not None:\n        plt.savefig(save_path)\n\n    plt.show()\n</code></pre>"},{"location":"modules/#hypershap.hypershap.HyperSHAP.plot_si_graph","title":"<code>plot_si_graph(interaction_values=None, save_path=None)</code>","text":"<p>Plot the SHAP interaction values as a graph.</p> <p>Parameters:</p> Name Type Description Default <code>interaction_values</code> <code>InteractionValues | None</code> <p>The interaction values to plot. Defaults to None.</p> <code>None</code> <code>save_path</code> <code>str | None</code> <p>The path to save the plot. Defaults to None.</p> <code>None</code> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def plot_si_graph(self, interaction_values: InteractionValues | None = None, save_path: str | None = None) -&gt; None:\n    \"\"\"Plot the SHAP interaction values as a graph.\n\n    Args:\n        interaction_values (InteractionValues | None, optional): The interaction values to plot. Defaults to None.\n        save_path (str | None, optional): The path to save the plot. Defaults to None.\n\n    \"\"\"\n    if interaction_values is None and self.last_interaction_values is None:\n        raise NoInteractionValuesError\n\n    # if given interaction values use those, else use cached interaction values\n    iv = interaction_values if interaction_values is not None else self.last_interaction_values\n\n    if not isinstance(iv, InteractionValues):\n        raise TypeError\n\n    hyperparameter_names = self.explanation_task.get_hyperparameter_names()\n\n    def get_circular_layout(n_players: int) -&gt; dict:\n        original_graph, graph_nodes = nx.Graph(), []\n        for i in range(n_players):\n            original_graph.add_node(i, label=i)\n            graph_nodes.append(i)\n        return nx.circular_layout(original_graph)\n\n    pos = get_circular_layout(n_players=self.explanation_task.get_num_hyperparameters())\n    iv.plot_si_graph(\n        show=False,\n        size_factor=3.0,\n        feature_names=hyperparameter_names,\n        pos=pos,\n        n_interactions=1_000,\n        compactness=1e50,\n    )\n    plt.tight_layout()\n\n    if save_path is not None:\n        plt.savefig(save_path)\n        logger.info(\"Saved SI graph to %s\", save_path)\n\n    plt.show()\n</code></pre>"},{"location":"modules/#hypershap.hypershap.HyperSHAP.plot_upset","title":"<code>plot_upset(interaction_values=None, save_path=None)</code>","text":"<p>Plot the SHAP interaction values as an upset plot graph.</p> <p>Parameters:</p> Name Type Description Default <code>interaction_values</code> <code>InteractionValues | None</code> <p>The interaction values to plot. Defaults to None.</p> <code>None</code> <code>save_path</code> <code>str | None</code> <p>The path to save the plot. Defaults to None.</p> <code>None</code> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def plot_upset(self, interaction_values: InteractionValues | None = None, save_path: str | None = None) -&gt; None:\n    \"\"\"Plot the SHAP interaction values as an upset plot graph.\n\n    Args:\n        interaction_values (InteractionValues | None, optional): The interaction values to plot. Defaults to None.\n        save_path (str | None, optional): The path to save the plot. Defaults to None.\n\n    \"\"\"\n    if interaction_values is None and self.last_interaction_values is None:\n        raise NoInteractionValuesError\n\n    # if given interaction values use those, else use cached interaction values\n    iv = interaction_values if interaction_values is not None else self.last_interaction_values\n\n    if not isinstance(iv, InteractionValues):\n        raise TypeError\n\n    hyperparameter_names = self.explanation_task.get_hyperparameter_names()\n\n    fig = iv.plot_upset(feature_names=hyperparameter_names, show=False)\n\n    if fig is None:\n        raise TypeError\n\n    ax = fig.get_axes()[0]\n    ax.set_ylabel(\"Performance Gain\")\n    # also add \"parameter\" to the y-axis label\n    ax = fig.get_axes()[1]\n    ax.set_ylabel(\"Hyperparameter\")\n\n    plt.tight_layout()\n\n    if save_path is not None:\n        plt.savefig(save_path)\n\n    plt.show()\n</code></pre>"},{"location":"modules/#hypershap.hypershap.HyperSHAP.sensitivity","title":"<code>sensitivity(baseline_config=None, index='FSII', order=2, n_samples=10000)</code>","text":"<p>Compute and return the interaction values for sensitivity analysis.</p> <p>Parameters:</p> Name Type Description Default <code>baseline_config</code> <code>Configuration | None</code> <p>The baseline configuration. Defaults to None.</p> <code>None</code> <code>index</code> <code>str</code> <p>The index to use for computing interaction values. Defaults to \"FSII\".</p> <code>'FSII'</code> <code>order</code> <code>int</code> <p>The order of the interaction values. Defaults to 2.</p> <code>2</code> <code>n_samples</code> <code>int</code> <p>The number of samples to use for simulating HPO. Defaults to 10_000.</p> <code>10000</code> <p>Returns:</p> Name Type Description <code>InteractionValues</code> <code>InteractionValues</code> <p>The computed interaction values.</p> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def sensitivity(\n    self,\n    baseline_config: Configuration | None = None,\n    index: str = \"FSII\",\n    order: int = 2,\n    n_samples: int = 10_000,\n) -&gt; InteractionValues:\n    \"\"\"Compute and return the interaction values for sensitivity analysis.\n\n    Args:\n        baseline_config (Configuration | None, optional): The baseline configuration. Defaults to None.\n        index (str, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n        order (int, optional): The order of the interaction values. Defaults to 2.\n        n_samples (int, optional): The number of samples to use for simulating HPO. Defaults to 10_000.\n\n    Returns:\n        InteractionValues: The computed interaction values.\n\n    \"\"\"\n    if baseline_config is None:\n        baseline_config = self.explanation_task.config_space.get_default_configuration()\n\n    # setup explanation task\n    sensitivity_task: SensitivityExplanationTask = SensitivityExplanationTask(\n        config_space=self.explanation_task.config_space,\n        surrogate_model=self.explanation_task.surrogate_model,\n        baseline_config=baseline_config,\n    )\n\n    # setup tunability game and get interaction values\n    tg = SensitivityGame(\n        explanation_task=sensitivity_task,\n        cs_searcher=RandomConfigSpaceSearcher(\n            explanation_task=sensitivity_task,\n            n_samples=n_samples,\n            mode=\"var\",\n        ),\n        n_workers=self.n_workers,\n        verbose=self.verbose,\n    )\n    return self.__get_interaction_values(game=tg, index=index, order=order)\n</code></pre>"},{"location":"modules/#hypershap.hypershap.HyperSHAP.tunability","title":"<code>tunability(baseline_config=None, index='FSII', order=2, n_samples=10000)</code>","text":"<p>Compute and return the interaction values for tunability analysis.</p> <p>Parameters:</p> Name Type Description Default <code>baseline_config</code> <code>Configuration | None</code> <p>The baseline configuration. Defaults to None.</p> <code>None</code> <code>index</code> <code>str</code> <p>The index to use for computing interaction values. Defaults to \"FSII\".</p> <code>'FSII'</code> <code>order</code> <code>int</code> <p>The order of the interaction values. Defaults to 2.</p> <code>2</code> <code>n_samples</code> <code>int</code> <p>The number of samples to use for simulating HPO. Defaults to 10_000.</p> <code>10000</code> <p>Returns:</p> Name Type Description <code>InteractionValues</code> <code>InteractionValues</code> <p>The computed interaction values.</p> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def tunability(\n    self,\n    baseline_config: Configuration | None = None,\n    index: str = \"FSII\",\n    order: int = 2,\n    n_samples: int = 10_000,\n) -&gt; InteractionValues:\n    \"\"\"Compute and return the interaction values for tunability analysis.\n\n    Args:\n        baseline_config (Configuration | None, optional): The baseline configuration. Defaults to None.\n        index (str, optional): The index to use for computing interaction values. Defaults to \"FSII\".\n        order (int, optional): The order of the interaction values. Defaults to 2.\n        n_samples (int, optional): The number of samples to use for simulating HPO. Defaults to 10_000.\n\n    Returns:\n        InteractionValues: The computed interaction values.\n\n    \"\"\"\n    if baseline_config is None:\n        baseline_config = self.explanation_task.config_space.get_default_configuration()\n\n    # setup explanation task\n    tunability_task: TunabilityExplanationTask = TunabilityExplanationTask(\n        config_space=self.explanation_task.config_space,\n        surrogate_model=self.explanation_task.surrogate_model,\n        baseline_config=baseline_config,\n    )\n\n    # setup tunability game and get interaction values\n    tg = TunabilityGame(\n        explanation_task=tunability_task,\n        cs_searcher=RandomConfigSpaceSearcher(\n            explanation_task=tunability_task,\n            n_samples=n_samples,\n            mode=\"max\",\n        ),\n        n_workers=self.n_workers,\n        verbose=self.verbose,\n    )\n    return self.__get_interaction_values(game=tg, index=index, order=order)\n</code></pre>"},{"location":"modules/#hypershap.hypershap.NoInteractionValuesError","title":"<code>NoInteractionValuesError</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>Exception raised when no interaction values are present for plotting.</p> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>class NoInteractionValuesError(ValueError):\n    \"\"\"Exception raised when no interaction values are present for plotting.\"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize the no interaction values error.\"\"\"\n        super().__init__(\"No interaction values present for plotting.\")\n</code></pre>"},{"location":"modules/#hypershap.hypershap.NoInteractionValuesError.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the no interaction values error.</p> Source code in <code>src/hypershap/hypershap.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize the no interaction values error.\"\"\"\n    super().__init__(\"No interaction values present for plotting.\")\n</code></pre>"},{"location":"modules/#explanation-task","title":"Explanation Task","text":"<p>The task module implements a hierarchy of explanation tasks that can be used to explain HPO.</p> <p>The tasks provide a convenient API to construct surrogate models from different data sources (pretrained estimators, empirical data, or a black box function) and to add domain specific information such as a baseline configuration or an optimizer of interest.</p>"},{"location":"modules/#hypershap.task.AblationExplanationTask","title":"<code>AblationExplanationTask</code>","text":"<p>               Bases: <code>BaselineExplanationTask</code></p> <p>Defines an ablation explanation task, comparing a configuration of interest to a baseline.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>class AblationExplanationTask(BaselineExplanationTask):\n    \"\"\"Defines an ablation explanation task, comparing a configuration of interest to a baseline.\"\"\"\n\n    def __init__(\n        self,\n        config_space: ConfigurationSpace,\n        surrogate_model: SurrogateModel,\n        baseline_config: Configuration,\n        config_of_interest: Configuration,\n    ) -&gt; None:\n        \"\"\"Initialize an AblationExplanationTask with a baseline and a configuration of interest.\n\n        Args:\n            config_space: The configuration space.\n            surrogate_model: The surrogate model.\n            baseline_config: The baseline configuration.\n            config_of_interest: The configuration of interest.\n\n        \"\"\"\n        super().__init__(config_space, surrogate_model, baseline_config)\n        self.config_of_interest = config_of_interest\n</code></pre>"},{"location":"modules/#hypershap.task.AblationExplanationTask.__init__","title":"<code>__init__(config_space, surrogate_model, baseline_config, config_of_interest)</code>","text":"<p>Initialize an AblationExplanationTask with a baseline and a configuration of interest.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>surrogate_model</code> <code>SurrogateModel</code> <p>The surrogate model.</p> required <code>baseline_config</code> <code>Configuration</code> <p>The baseline configuration.</p> required <code>config_of_interest</code> <code>Configuration</code> <p>The configuration of interest.</p> required Source code in <code>src/hypershap/task.py</code> <pre><code>def __init__(\n    self,\n    config_space: ConfigurationSpace,\n    surrogate_model: SurrogateModel,\n    baseline_config: Configuration,\n    config_of_interest: Configuration,\n) -&gt; None:\n    \"\"\"Initialize an AblationExplanationTask with a baseline and a configuration of interest.\n\n    Args:\n        config_space: The configuration space.\n        surrogate_model: The surrogate model.\n        baseline_config: The baseline configuration.\n        config_of_interest: The configuration of interest.\n\n    \"\"\"\n    super().__init__(config_space, surrogate_model, baseline_config)\n    self.config_of_interest = config_of_interest\n</code></pre>"},{"location":"modules/#hypershap.task.BaselineExplanationTask","title":"<code>BaselineExplanationTask</code>","text":"<p>               Bases: <code>ExplanationTask</code></p> <p>Defines an explanation task with a baseline configuration.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>class BaselineExplanationTask(ExplanationTask):\n    \"\"\"Defines an explanation task with a baseline configuration.\"\"\"\n\n    def __init__(\n        self,\n        config_space: ConfigurationSpace,\n        surrogate_model: SurrogateModel,\n        baseline_config: Configuration,\n    ) -&gt; None:\n        \"\"\"Initialize a BaselineExplanationTask with a baseline configuration.\n\n        Args:\n            config_space: The configuration space.\n            surrogate_model: The surrogate model.\n            baseline_config: The baseline configuration.\n\n        \"\"\"\n        super().__init__(config_space, surrogate_model)\n        self.baseline_config = baseline_config\n</code></pre>"},{"location":"modules/#hypershap.task.BaselineExplanationTask.__init__","title":"<code>__init__(config_space, surrogate_model, baseline_config)</code>","text":"<p>Initialize a BaselineExplanationTask with a baseline configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>surrogate_model</code> <code>SurrogateModel</code> <p>The surrogate model.</p> required <code>baseline_config</code> <code>Configuration</code> <p>The baseline configuration.</p> required Source code in <code>src/hypershap/task.py</code> <pre><code>def __init__(\n    self,\n    config_space: ConfigurationSpace,\n    surrogate_model: SurrogateModel,\n    baseline_config: Configuration,\n) -&gt; None:\n    \"\"\"Initialize a BaselineExplanationTask with a baseline configuration.\n\n    Args:\n        config_space: The configuration space.\n        surrogate_model: The surrogate model.\n        baseline_config: The baseline configuration.\n\n    \"\"\"\n    super().__init__(config_space, surrogate_model)\n    self.baseline_config = baseline_config\n</code></pre>"},{"location":"modules/#hypershap.task.ExplanationTask","title":"<code>ExplanationTask</code>","text":"<p>Defines the base class for explanation tasks, providing access to the configuration space and surrogate model.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>class ExplanationTask:\n    \"\"\"Defines the base class for explanation tasks, providing access to the configuration space and surrogate model.\"\"\"\n\n    def __init__(self, config_space: ConfigurationSpace, surrogate_model: SurrogateModel) -&gt; None:\n        \"\"\"Initialize an ExplanationTask with a configuration space and surrogate model.\n\n        Args:\n            config_space: The configuration space for the explanation task.\n            surrogate_model: The surrogate model used for the explanation task.\n\n        \"\"\"\n        self.config_space: ConfigurationSpace = config_space\n        self.surrogate_model: SurrogateModel = surrogate_model\n\n    def get_num_hyperparameters(self) -&gt; int:\n        \"\"\"Return the number of hyperparameters in the configuration space.\n\n        Returns:\n            The number of hyperparameters.\n\n        \"\"\"\n        return len(self.config_space)\n\n    def get_hyperparameter_names(self) -&gt; list[str]:\n        \"\"\"Return the names of the hyperparameters in the configuration space.\n\n        Returns:\n            A list of hyperparameter names.\n\n        \"\"\"\n        return list(self.config_space.keys())\n\n    @staticmethod\n    def from_base_model(config_space: ConfigurationSpace, base_model: BaseEstimator) -&gt; ExplanationTask:\n        \"\"\"Create an ExplanationTask from a pre-trained base model.\n\n        Args:\n            config_space: The configuration space.\n            base_model: The pre-trained base model.\n\n        Returns:\n            An ExplanationTask instance.\n\n        \"\"\"\n        surrogate_model = ModelBasedSurrogateModel(config_space=config_space, base_model=base_model)\n        return ExplanationTask(config_space=config_space, surrogate_model=surrogate_model)\n\n    @staticmethod\n    def from_data(\n        config_space: ConfigurationSpace,\n        data: list[tuple[Configuration, float]],\n        base_model: BaseEstimator | None = None,\n    ) -&gt; ExplanationTask:\n        \"\"\"Create an ExplanationTask from a dataset of configurations and their performance.\n\n        Args:\n            config_space: The configuration space.\n            data: A list of tuples, where each tuple contains a configuration and its corresponding performance.\n            base_model: The base model to use for training the surrogate model. Defaults to RandomForestRegressor.\n\n        Returns:\n            An ExplanationTask instance.\n\n        \"\"\"\n        surrogate_model = DataBasedSurrogateModel(config_space=config_space, data=data, base_model=base_model)\n        return ExplanationTask(config_space=config_space, surrogate_model=surrogate_model)\n\n    @staticmethod\n    def from_function(\n        config_space: ConfigurationSpace,\n        function: Callable[[Configuration], float],\n        n_samples: int = 1_000,\n        base_model: BaseEstimator | None = None,\n    ) -&gt; ExplanationTask:\n        \"\"\"Create an ExplanationTask from a function that evaluates configurations.\n\n        Args:\n            config_space: The configuration space.\n            function: A callable that takes a configuration and returns its performance.\n            n_samples: The number of configurations to sample for training the surrogate model. Defaults to 1000.\n            base_model: The base model to use for training the surrogate model. Defaults to RandomForestRegressor.\n\n        Returns:\n            An ExplanationTask instance.\n\n        \"\"\"\n        samples: list[Configuration] = config_space.sample_configuration(n_samples)\n        values: list[float] = [function(config) for config in samples]\n        data: list[tuple[Configuration, float]] = list(zip(samples, values, strict=False))\n        base_model = base_model if base_model is not None else RandomForestRegressor()\n\n        return ExplanationTask.from_data(config_space=config_space, data=data, base_model=base_model)\n</code></pre>"},{"location":"modules/#hypershap.task.ExplanationTask.__init__","title":"<code>__init__(config_space, surrogate_model)</code>","text":"<p>Initialize an ExplanationTask with a configuration space and surrogate model.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space for the explanation task.</p> required <code>surrogate_model</code> <code>SurrogateModel</code> <p>The surrogate model used for the explanation task.</p> required Source code in <code>src/hypershap/task.py</code> <pre><code>def __init__(self, config_space: ConfigurationSpace, surrogate_model: SurrogateModel) -&gt; None:\n    \"\"\"Initialize an ExplanationTask with a configuration space and surrogate model.\n\n    Args:\n        config_space: The configuration space for the explanation task.\n        surrogate_model: The surrogate model used for the explanation task.\n\n    \"\"\"\n    self.config_space: ConfigurationSpace = config_space\n    self.surrogate_model: SurrogateModel = surrogate_model\n</code></pre>"},{"location":"modules/#hypershap.task.ExplanationTask.from_base_model","title":"<code>from_base_model(config_space, base_model)</code>  <code>staticmethod</code>","text":"<p>Create an ExplanationTask from a pre-trained base model.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>base_model</code> <code>BaseEstimator</code> <p>The pre-trained base model.</p> required <p>Returns:</p> Type Description <code>ExplanationTask</code> <p>An ExplanationTask instance.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>@staticmethod\ndef from_base_model(config_space: ConfigurationSpace, base_model: BaseEstimator) -&gt; ExplanationTask:\n    \"\"\"Create an ExplanationTask from a pre-trained base model.\n\n    Args:\n        config_space: The configuration space.\n        base_model: The pre-trained base model.\n\n    Returns:\n        An ExplanationTask instance.\n\n    \"\"\"\n    surrogate_model = ModelBasedSurrogateModel(config_space=config_space, base_model=base_model)\n    return ExplanationTask(config_space=config_space, surrogate_model=surrogate_model)\n</code></pre>"},{"location":"modules/#hypershap.task.ExplanationTask.from_data","title":"<code>from_data(config_space, data, base_model=None)</code>  <code>staticmethod</code>","text":"<p>Create an ExplanationTask from a dataset of configurations and their performance.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>data</code> <code>list[tuple[Configuration, float]]</code> <p>A list of tuples, where each tuple contains a configuration and its corresponding performance.</p> required <code>base_model</code> <code>BaseEstimator | None</code> <p>The base model to use for training the surrogate model. Defaults to RandomForestRegressor.</p> <code>None</code> <p>Returns:</p> Type Description <code>ExplanationTask</code> <p>An ExplanationTask instance.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>@staticmethod\ndef from_data(\n    config_space: ConfigurationSpace,\n    data: list[tuple[Configuration, float]],\n    base_model: BaseEstimator | None = None,\n) -&gt; ExplanationTask:\n    \"\"\"Create an ExplanationTask from a dataset of configurations and their performance.\n\n    Args:\n        config_space: The configuration space.\n        data: A list of tuples, where each tuple contains a configuration and its corresponding performance.\n        base_model: The base model to use for training the surrogate model. Defaults to RandomForestRegressor.\n\n    Returns:\n        An ExplanationTask instance.\n\n    \"\"\"\n    surrogate_model = DataBasedSurrogateModel(config_space=config_space, data=data, base_model=base_model)\n    return ExplanationTask(config_space=config_space, surrogate_model=surrogate_model)\n</code></pre>"},{"location":"modules/#hypershap.task.ExplanationTask.from_function","title":"<code>from_function(config_space, function, n_samples=1000, base_model=None)</code>  <code>staticmethod</code>","text":"<p>Create an ExplanationTask from a function that evaluates configurations.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>function</code> <code>Callable[[Configuration], float]</code> <p>A callable that takes a configuration and returns its performance.</p> required <code>n_samples</code> <code>int</code> <p>The number of configurations to sample for training the surrogate model. Defaults to 1000.</p> <code>1000</code> <code>base_model</code> <code>BaseEstimator | None</code> <p>The base model to use for training the surrogate model. Defaults to RandomForestRegressor.</p> <code>None</code> <p>Returns:</p> Type Description <code>ExplanationTask</code> <p>An ExplanationTask instance.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>@staticmethod\ndef from_function(\n    config_space: ConfigurationSpace,\n    function: Callable[[Configuration], float],\n    n_samples: int = 1_000,\n    base_model: BaseEstimator | None = None,\n) -&gt; ExplanationTask:\n    \"\"\"Create an ExplanationTask from a function that evaluates configurations.\n\n    Args:\n        config_space: The configuration space.\n        function: A callable that takes a configuration and returns its performance.\n        n_samples: The number of configurations to sample for training the surrogate model. Defaults to 1000.\n        base_model: The base model to use for training the surrogate model. Defaults to RandomForestRegressor.\n\n    Returns:\n        An ExplanationTask instance.\n\n    \"\"\"\n    samples: list[Configuration] = config_space.sample_configuration(n_samples)\n    values: list[float] = [function(config) for config in samples]\n    data: list[tuple[Configuration, float]] = list(zip(samples, values, strict=False))\n    base_model = base_model if base_model is not None else RandomForestRegressor()\n\n    return ExplanationTask.from_data(config_space=config_space, data=data, base_model=base_model)\n</code></pre>"},{"location":"modules/#hypershap.task.ExplanationTask.get_hyperparameter_names","title":"<code>get_hyperparameter_names()</code>","text":"<p>Return the names of the hyperparameters in the configuration space.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of hyperparameter names.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>def get_hyperparameter_names(self) -&gt; list[str]:\n    \"\"\"Return the names of the hyperparameters in the configuration space.\n\n    Returns:\n        A list of hyperparameter names.\n\n    \"\"\"\n    return list(self.config_space.keys())\n</code></pre>"},{"location":"modules/#hypershap.task.ExplanationTask.get_num_hyperparameters","title":"<code>get_num_hyperparameters()</code>","text":"<p>Return the number of hyperparameters in the configuration space.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of hyperparameters.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>def get_num_hyperparameters(self) -&gt; int:\n    \"\"\"Return the number of hyperparameters in the configuration space.\n\n    Returns:\n        The number of hyperparameters.\n\n    \"\"\"\n    return len(self.config_space)\n</code></pre>"},{"location":"modules/#hypershap.task.MistunabilityExplanationTask","title":"<code>MistunabilityExplanationTask</code>","text":"<p>               Bases: <code>BaselineExplanationTask</code></p> <p>Defines a mistunability explanation task.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>class MistunabilityExplanationTask(BaselineExplanationTask):\n    \"\"\"Defines a mistunability explanation task.\"\"\"\n\n    def __init__(\n        self,\n        config_space: ConfigurationSpace,\n        surrogate_model: SurrogateModel,\n        baseline_config: Configuration,\n    ) -&gt; None:\n        \"\"\"Initialize a MistunabilityExplanationTask.\n\n        Args:\n            config_space: The configuration space.\n            surrogate_model: The surrogate model.\n            baseline_config: The baseline configuration.\n\n        \"\"\"\n        super().__init__(config_space, surrogate_model, baseline_config)\n</code></pre>"},{"location":"modules/#hypershap.task.MistunabilityExplanationTask.__init__","title":"<code>__init__(config_space, surrogate_model, baseline_config)</code>","text":"<p>Initialize a MistunabilityExplanationTask.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>surrogate_model</code> <code>SurrogateModel</code> <p>The surrogate model.</p> required <code>baseline_config</code> <code>Configuration</code> <p>The baseline configuration.</p> required Source code in <code>src/hypershap/task.py</code> <pre><code>def __init__(\n    self,\n    config_space: ConfigurationSpace,\n    surrogate_model: SurrogateModel,\n    baseline_config: Configuration,\n) -&gt; None:\n    \"\"\"Initialize a MistunabilityExplanationTask.\n\n    Args:\n        config_space: The configuration space.\n        surrogate_model: The surrogate model.\n        baseline_config: The baseline configuration.\n\n    \"\"\"\n    super().__init__(config_space, surrogate_model, baseline_config)\n</code></pre>"},{"location":"modules/#hypershap.task.MultiBaselineExplanationTask","title":"<code>MultiBaselineExplanationTask</code>","text":"<p>               Bases: <code>ExplanationTask</code></p> <p>Defines an explanation task with multiple baseline configurations.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>class MultiBaselineExplanationTask(ExplanationTask):\n    \"\"\"Defines an explanation task with multiple baseline configurations.\"\"\"\n\n    def __init__(\n        self,\n        config_space: ConfigurationSpace,\n        surrogate_model: SurrogateModel,\n        baseline_configs: list[Configuration],\n    ) -&gt; None:\n        \"\"\"Initialize a MultiBaselineExplanationTask with a list of baseline configurations.\n\n        Args:\n            config_space: The configuration space.\n            surrogate_model: The surrogate model.\n            baseline_configs: A list of baseline configurations.\n\n        \"\"\"\n        super().__init__(config_space, surrogate_model)\n        self.baseline_configs = baseline_configs\n</code></pre>"},{"location":"modules/#hypershap.task.MultiBaselineExplanationTask.__init__","title":"<code>__init__(config_space, surrogate_model, baseline_configs)</code>","text":"<p>Initialize a MultiBaselineExplanationTask with a list of baseline configurations.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>surrogate_model</code> <code>SurrogateModel</code> <p>The surrogate model.</p> required <code>baseline_configs</code> <code>list[Configuration]</code> <p>A list of baseline configurations.</p> required Source code in <code>src/hypershap/task.py</code> <pre><code>def __init__(\n    self,\n    config_space: ConfigurationSpace,\n    surrogate_model: SurrogateModel,\n    baseline_configs: list[Configuration],\n) -&gt; None:\n    \"\"\"Initialize a MultiBaselineExplanationTask with a list of baseline configurations.\n\n    Args:\n        config_space: The configuration space.\n        surrogate_model: The surrogate model.\n        baseline_configs: A list of baseline configurations.\n\n    \"\"\"\n    super().__init__(config_space, surrogate_model)\n    self.baseline_configs = baseline_configs\n</code></pre>"},{"location":"modules/#hypershap.task.OptimizerBiasExplanationTask","title":"<code>OptimizerBiasExplanationTask</code>","text":"<p>               Bases: <code>ExplanationTask</code></p> <p>Defines an optimizer bias explanation task.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>class OptimizerBiasExplanationTask(ExplanationTask):\n    \"\"\"Defines an optimizer bias explanation task.\"\"\"\n\n    def __init__(\n        self,\n        config_space: ConfigurationSpace,\n        surrogate_model: SurrogateModel,\n        optimizer_of_interest: ConfigSpaceSearcher,\n        optimizer_ensemble: list[ConfigSpaceSearcher],\n    ) -&gt; None:\n        \"\"\"Initialize an OptimizerBiasExplanationTask.\n\n        Args:\n            config_space: The configuration space.\n            surrogate_model: The surrogate model.\n            optimizer_of_interest: The optimizer of interest.\n            optimizer_ensemble: The ensemble of optimizers.\n\n        \"\"\"\n        super().__init__(config_space, surrogate_model)\n        self.optimizer_of_interest = optimizer_of_interest\n        self.optimizer_ensemble = optimizer_ensemble\n</code></pre>"},{"location":"modules/#hypershap.task.OptimizerBiasExplanationTask.__init__","title":"<code>__init__(config_space, surrogate_model, optimizer_of_interest, optimizer_ensemble)</code>","text":"<p>Initialize an OptimizerBiasExplanationTask.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>surrogate_model</code> <code>SurrogateModel</code> <p>The surrogate model.</p> required <code>optimizer_of_interest</code> <code>ConfigSpaceSearcher</code> <p>The optimizer of interest.</p> required <code>optimizer_ensemble</code> <code>list[ConfigSpaceSearcher]</code> <p>The ensemble of optimizers.</p> required Source code in <code>src/hypershap/task.py</code> <pre><code>def __init__(\n    self,\n    config_space: ConfigurationSpace,\n    surrogate_model: SurrogateModel,\n    optimizer_of_interest: ConfigSpaceSearcher,\n    optimizer_ensemble: list[ConfigSpaceSearcher],\n) -&gt; None:\n    \"\"\"Initialize an OptimizerBiasExplanationTask.\n\n    Args:\n        config_space: The configuration space.\n        surrogate_model: The surrogate model.\n        optimizer_of_interest: The optimizer of interest.\n        optimizer_ensemble: The ensemble of optimizers.\n\n    \"\"\"\n    super().__init__(config_space, surrogate_model)\n    self.optimizer_of_interest = optimizer_of_interest\n    self.optimizer_ensemble = optimizer_ensemble\n</code></pre>"},{"location":"modules/#hypershap.task.SensitivityExplanationTask","title":"<code>SensitivityExplanationTask</code>","text":"<p>               Bases: <code>BaselineExplanationTask</code></p> <p>Defines a sensitivity explanation task.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>class SensitivityExplanationTask(BaselineExplanationTask):\n    \"\"\"Defines a sensitivity explanation task.\"\"\"\n\n    def __init__(\n        self,\n        config_space: ConfigurationSpace,\n        surrogate_model: SurrogateModel,\n        baseline_config: Configuration,\n    ) -&gt; None:\n        \"\"\"Initialize a SensitivityExplanationTask.\n\n        Args:\n            config_space: The configuration space.\n            surrogate_model: The surrogate model.\n            baseline_config: The baseline configuration.\n\n        \"\"\"\n        super().__init__(config_space, surrogate_model, baseline_config)\n</code></pre>"},{"location":"modules/#hypershap.task.SensitivityExplanationTask.__init__","title":"<code>__init__(config_space, surrogate_model, baseline_config)</code>","text":"<p>Initialize a SensitivityExplanationTask.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>surrogate_model</code> <code>SurrogateModel</code> <p>The surrogate model.</p> required <code>baseline_config</code> <code>Configuration</code> <p>The baseline configuration.</p> required Source code in <code>src/hypershap/task.py</code> <pre><code>def __init__(\n    self,\n    config_space: ConfigurationSpace,\n    surrogate_model: SurrogateModel,\n    baseline_config: Configuration,\n) -&gt; None:\n    \"\"\"Initialize a SensitivityExplanationTask.\n\n    Args:\n        config_space: The configuration space.\n        surrogate_model: The surrogate model.\n        baseline_config: The baseline configuration.\n\n    \"\"\"\n    super().__init__(config_space, surrogate_model, baseline_config)\n</code></pre>"},{"location":"modules/#hypershap.task.TunabilityExplanationTask","title":"<code>TunabilityExplanationTask</code>","text":"<p>               Bases: <code>BaselineExplanationTask</code></p> <p>Defines a tunability explanation task.</p> Source code in <code>src/hypershap/task.py</code> <pre><code>class TunabilityExplanationTask(BaselineExplanationTask):\n    \"\"\"Defines a tunability explanation task.\"\"\"\n\n    def __init__(\n        self,\n        config_space: ConfigurationSpace,\n        surrogate_model: SurrogateModel,\n        baseline_config: Configuration,\n    ) -&gt; None:\n        \"\"\"Initialize a TunabilityExplanationTask.\n\n        Args:\n            config_space: The configuration space.\n            surrogate_model: The surrogate model.\n            baseline_config: The baseline configuration.\n\n        \"\"\"\n        super().__init__(config_space, surrogate_model, baseline_config)\n</code></pre>"},{"location":"modules/#hypershap.task.TunabilityExplanationTask.__init__","title":"<code>__init__(config_space, surrogate_model, baseline_config)</code>","text":"<p>Initialize a TunabilityExplanationTask.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>surrogate_model</code> <code>SurrogateModel</code> <p>The surrogate model.</p> required <code>baseline_config</code> <code>Configuration</code> <p>The baseline configuration.</p> required Source code in <code>src/hypershap/task.py</code> <pre><code>def __init__(\n    self,\n    config_space: ConfigurationSpace,\n    surrogate_model: SurrogateModel,\n    baseline_config: Configuration,\n) -&gt; None:\n    \"\"\"Initialize a TunabilityExplanationTask.\n\n    Args:\n        config_space: The configuration space.\n        surrogate_model: The surrogate model.\n        baseline_config: The baseline configuration.\n\n    \"\"\"\n    super().__init__(config_space, surrogate_model, baseline_config)\n</code></pre>"},{"location":"modules/#surrogate-model","title":"Surrogate Model","text":"<p>The surrogate module defines the basic classes for surrogate models.</p> <p>It provides methods for training and evaluating a model that approximates the relationship between input hyperparameters and performance.</p>"},{"location":"modules/#hypershap.surrogate_model.DataBasedSurrogateModel","title":"<code>DataBasedSurrogateModel</code>","text":"<p>               Bases: <code>ModelBasedSurrogateModel</code></p> <p>A surrogate model trained on a dataset of configurations and their performance.</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>class DataBasedSurrogateModel(ModelBasedSurrogateModel):\n    \"\"\"A surrogate model trained on a dataset of configurations and their performance.\"\"\"\n\n    def __init__(\n        self,\n        config_space: ConfigurationSpace,\n        data: list[tuple[Configuration, float]],\n        base_model: BaseEstimator | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize the DataBasedSurrogateModel with data and an optional base model.\n\n        Args:\n            config_space: The configuration space.\n            data: The data to be used for fitting the surrogate model.  Each element\n                  is a tuple of (Configuration, float).\n            base_model: The base model to be used for fitting the surrogate model.\n                        If None, a RandomForestRegressor is used.\n\n        \"\"\"\n        train_x = np.array([obs[0].get_array() for obs in data])\n        train_y = np.array([obs[1] for obs in data])\n\n        if base_model is None:\n            base_model = RandomForestRegressor()\n\n        pipeline = cast(\"SklearnRegressorProtocol\", base_model)\n        pipeline.fit(train_x, train_y)\n\n        super().__init__(config_space, base_model)\n</code></pre>"},{"location":"modules/#hypershap.surrogate_model.DataBasedSurrogateModel.__init__","title":"<code>__init__(config_space, data, base_model=None)</code>","text":"<p>Initialize the DataBasedSurrogateModel with data and an optional base model.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>data</code> <code>list[tuple[Configuration, float]]</code> <p>The data to be used for fitting the surrogate model.  Each element   is a tuple of (Configuration, float).</p> required <code>base_model</code> <code>BaseEstimator | None</code> <p>The base model to be used for fitting the surrogate model.         If None, a RandomForestRegressor is used.</p> <code>None</code> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>def __init__(\n    self,\n    config_space: ConfigurationSpace,\n    data: list[tuple[Configuration, float]],\n    base_model: BaseEstimator | None = None,\n) -&gt; None:\n    \"\"\"Initialize the DataBasedSurrogateModel with data and an optional base model.\n\n    Args:\n        config_space: The configuration space.\n        data: The data to be used for fitting the surrogate model.  Each element\n              is a tuple of (Configuration, float).\n        base_model: The base model to be used for fitting the surrogate model.\n                    If None, a RandomForestRegressor is used.\n\n    \"\"\"\n    train_x = np.array([obs[0].get_array() for obs in data])\n    train_y = np.array([obs[1] for obs in data])\n\n    if base_model is None:\n        base_model = RandomForestRegressor()\n\n    pipeline = cast(\"SklearnRegressorProtocol\", base_model)\n    pipeline.fit(train_x, train_y)\n\n    super().__init__(config_space, base_model)\n</code></pre>"},{"location":"modules/#hypershap.surrogate_model.ModelBasedSurrogateModel","title":"<code>ModelBasedSurrogateModel</code>","text":"<p>               Bases: <code>SurrogateModel</code></p> <p>A surrogate model based on a pre-trained machine learning model.</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>class ModelBasedSurrogateModel(SurrogateModel):\n    \"\"\"A surrogate model based on a pre-trained machine learning model.\"\"\"\n\n    def __init__(self, config_space: ConfigurationSpace, base_model: BaseEstimator) -&gt; None:\n        \"\"\"Initialize the ModelBasedSurrogateModel with a configuration space and a base model.\n\n        Args:\n            config_space: The configuration space.\n            base_model: The base machine learning model.\n\n        \"\"\"\n        super().__init__(config_space)\n        self.base_model = base_model\n\n    def evaluate_config(self, config: Configuration) -&gt; float:\n        \"\"\"Evaluate a single configuration.\n\n        Args:\n            config: The configuration to evaluate.\n\n        Returns:\n            The predicted performance for the given configuration.\n\n        \"\"\"\n        res = self.evaluate(config.get_array())\n        if not isinstance(res, float):\n            raise TypeError\n        return res\n\n    def evaluate_config_batch(self, config_batch: list[Configuration]) -&gt; list[float]:\n        \"\"\"Evaluate a batch of configurations.\n\n        Args:\n            config_batch: A list of configurations to evaluate.\n\n        Returns:\n            A list of predicted performances for the given configurations.\n\n        \"\"\"\n        res = self.evaluate(np.array([config.get_array() for config in config_batch]))\n        if not isinstance(res, list):\n            raise TypeError\n        return res\n\n    def evaluate(self, config_array: np.ndarray) -&gt; float | list[float]:\n        \"\"\"Evaluate a configuration (or batch of configurations).\n\n        Args:\n            config_array: A numpy array representing the configuration(s).\n\n        Returns:\n            The predicted performance(s).\n\n        \"\"\"\n        if config_array.ndim == 1:\n            config_array = config_array.reshape(1, -1)\n\n        base_model = cast(\"SklearnRegressorProtocol\", self.base_model)\n        predictions = base_model.predict(config_array)\n\n        if predictions.shape == (1,):  # Check for a 1-element array (scalar)\n            return float(predictions[0])  # Convert to a Python float\n\n        return predictions.tolist()  # Convert to a Python list\n</code></pre>"},{"location":"modules/#hypershap.surrogate_model.ModelBasedSurrogateModel.__init__","title":"<code>__init__(config_space, base_model)</code>","text":"<p>Initialize the ModelBasedSurrogateModel with a configuration space and a base model.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space.</p> required <code>base_model</code> <code>BaseEstimator</code> <p>The base machine learning model.</p> required Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>def __init__(self, config_space: ConfigurationSpace, base_model: BaseEstimator) -&gt; None:\n    \"\"\"Initialize the ModelBasedSurrogateModel with a configuration space and a base model.\n\n    Args:\n        config_space: The configuration space.\n        base_model: The base machine learning model.\n\n    \"\"\"\n    super().__init__(config_space)\n    self.base_model = base_model\n</code></pre>"},{"location":"modules/#hypershap.surrogate_model.ModelBasedSurrogateModel.evaluate","title":"<code>evaluate(config_array)</code>","text":"<p>Evaluate a configuration (or batch of configurations).</p> <p>Parameters:</p> Name Type Description Default <code>config_array</code> <code>ndarray</code> <p>A numpy array representing the configuration(s).</p> required <p>Returns:</p> Type Description <code>float | list[float]</code> <p>The predicted performance(s).</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>def evaluate(self, config_array: np.ndarray) -&gt; float | list[float]:\n    \"\"\"Evaluate a configuration (or batch of configurations).\n\n    Args:\n        config_array: A numpy array representing the configuration(s).\n\n    Returns:\n        The predicted performance(s).\n\n    \"\"\"\n    if config_array.ndim == 1:\n        config_array = config_array.reshape(1, -1)\n\n    base_model = cast(\"SklearnRegressorProtocol\", self.base_model)\n    predictions = base_model.predict(config_array)\n\n    if predictions.shape == (1,):  # Check for a 1-element array (scalar)\n        return float(predictions[0])  # Convert to a Python float\n\n    return predictions.tolist()  # Convert to a Python list\n</code></pre>"},{"location":"modules/#hypershap.surrogate_model.ModelBasedSurrogateModel.evaluate_config","title":"<code>evaluate_config(config)</code>","text":"<p>Evaluate a single configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Configuration</code> <p>The configuration to evaluate.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The predicted performance for the given configuration.</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>def evaluate_config(self, config: Configuration) -&gt; float:\n    \"\"\"Evaluate a single configuration.\n\n    Args:\n        config: The configuration to evaluate.\n\n    Returns:\n        The predicted performance for the given configuration.\n\n    \"\"\"\n    res = self.evaluate(config.get_array())\n    if not isinstance(res, float):\n        raise TypeError\n    return res\n</code></pre>"},{"location":"modules/#hypershap.surrogate_model.ModelBasedSurrogateModel.evaluate_config_batch","title":"<code>evaluate_config_batch(config_batch)</code>","text":"<p>Evaluate a batch of configurations.</p> <p>Parameters:</p> Name Type Description Default <code>config_batch</code> <code>list[Configuration]</code> <p>A list of configurations to evaluate.</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>A list of predicted performances for the given configurations.</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>def evaluate_config_batch(self, config_batch: list[Configuration]) -&gt; list[float]:\n    \"\"\"Evaluate a batch of configurations.\n\n    Args:\n        config_batch: A list of configurations to evaluate.\n\n    Returns:\n        A list of predicted performances for the given configurations.\n\n    \"\"\"\n    res = self.evaluate(np.array([config.get_array() for config in config_batch]))\n    if not isinstance(res, list):\n        raise TypeError\n    return res\n</code></pre>"},{"location":"modules/#hypershap.surrogate_model.SklearnRegressorProtocol","title":"<code>SklearnRegressorProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Defines the interface for scikit-learn-like regression models.</p> <p>This protocol specifies the required methods for a class to be considered a compatible scikit-learn regression model.  It mandates the presence of <code>fit</code>, <code>predict</code>, and <code>score</code> methods, mirroring the structure of many scikit-learn estimators.</p> <p>Attributes:</p> Name Type Description <code>fit</code> <code>callable</code> <p>A method that fits the model to the provided data.              It should accept training data (X) and target variables (y)              as arguments, and any optional fit parameters. It should return              the fitted model instance itself (allowing for chaining).</p> <code>predict</code> <code>callable</code> <p>A method that generates predictions for a given input dataset.                It accepts input data (X) and returns predictions as a NumPy array.</p> <code>score</code> <code>callable</code> <p>A method that evaluates the model's performance on a given dataset.               It accepts input data (X) and corresponding target variables (y)               and returns a scalar performance score (e.g., R-squared, MSE).</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>class SklearnRegressorProtocol(Protocol):\n    \"\"\"Defines the interface for scikit-learn-like regression models.\n\n    This protocol specifies the required methods for a class to be considered\n    a compatible scikit-learn regression model.  It mandates the presence of `fit`,\n    `predict`, and `score` methods, mirroring the structure of many\n    scikit-learn estimators.\n\n    Attributes:\n        fit (callable): A method that fits the model to the provided data.\n                         It should accept training data (X) and target variables (y)\n                         as arguments, and any optional fit parameters. It should return\n                         the fitted model instance itself (allowing for chaining).\n        predict (callable): A method that generates predictions for a given input dataset.\n                           It accepts input data (X) and returns predictions as a NumPy array.\n        score (callable): A method that evaluates the model's performance on a given dataset.\n                          It accepts input data (X) and corresponding target variables (y)\n                          and returns a scalar performance score (e.g., R-squared, MSE).\n\n    \"\"\"\n\n    def fit(self, X: Any, y: Any, **fit_params: Any) -&gt; None:\n        \"\"\"Fit the regression model to the provided training data.\n\n        Args:\n            X (np.ndarray): The training data features.\n            y (np.ndarray): The training data target variables.\n            **fit_params (Any): Optional keyword arguments passed to the fit method.\n\n        Returns:\n            'SklearnRegressorProtocol': The fitted regression model instance itself, allowing for method chaining.\n\n        \"\"\"\n        ...\n\n    def predict(self, X: Any) -&gt; np.ndarray:\n        \"\"\"Generate predictions for a given input dataset.\n\n        Args:\n            X (np.ndarray): The input data features for prediction.\n\n        Returns:\n            np.ndarray: The predicted target values as a NumPy array.\n\n        \"\"\"\n        ...\n\n    def score(self, X: Any, y: Any) -&gt; float:\n        \"\"\"Evaluate the model's performance on a given dataset.\n\n        Args:\n            X (np.ndarray): The input data features.\n            y (np.ndarray): The corresponding target variables.\n\n        Returns:\n            float: A scalar performance score, representing the model's accuracy on the dataset.\n\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/#hypershap.surrogate_model.SklearnRegressorProtocol.fit","title":"<code>fit(X, y, **fit_params)</code>","text":"<p>Fit the regression model to the provided training data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The training data features.</p> required <code>y</code> <code>ndarray</code> <p>The training data target variables.</p> required <code>**fit_params</code> <code>Any</code> <p>Optional keyword arguments passed to the fit method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>None</code> <p>'SklearnRegressorProtocol': The fitted regression model instance itself, allowing for method chaining.</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>def fit(self, X: Any, y: Any, **fit_params: Any) -&gt; None:\n    \"\"\"Fit the regression model to the provided training data.\n\n    Args:\n        X (np.ndarray): The training data features.\n        y (np.ndarray): The training data target variables.\n        **fit_params (Any): Optional keyword arguments passed to the fit method.\n\n    Returns:\n        'SklearnRegressorProtocol': The fitted regression model instance itself, allowing for method chaining.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/#hypershap.surrogate_model.SklearnRegressorProtocol.predict","title":"<code>predict(X)</code>","text":"<p>Generate predictions for a given input dataset.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The input data features for prediction.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The predicted target values as a NumPy array.</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>def predict(self, X: Any) -&gt; np.ndarray:\n    \"\"\"Generate predictions for a given input dataset.\n\n    Args:\n        X (np.ndarray): The input data features for prediction.\n\n    Returns:\n        np.ndarray: The predicted target values as a NumPy array.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/#hypershap.surrogate_model.SklearnRegressorProtocol.score","title":"<code>score(X, y)</code>","text":"<p>Evaluate the model's performance on a given dataset.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The input data features.</p> required <code>y</code> <code>ndarray</code> <p>The corresponding target variables.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>A scalar performance score, representing the model's accuracy on the dataset.</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>def score(self, X: Any, y: Any) -&gt; float:\n    \"\"\"Evaluate the model's performance on a given dataset.\n\n    Args:\n        X (np.ndarray): The input data features.\n        y (np.ndarray): The corresponding target variables.\n\n    Returns:\n        float: A scalar performance score, representing the model's accuracy on the dataset.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/#hypershap.surrogate_model.SurrogateModel","title":"<code>SurrogateModel</code>","text":"<p>               Bases: <code>ABC</code></p> <p>An abstract class for defining the interface of surrogate models.</p> <p>This class defines the basic methods that all surrogate models should implement, allowing for a consistent interface for evaluating different models.</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>class SurrogateModel(ABC):\n    \"\"\"An abstract class for defining the interface of surrogate models.\n\n    This class defines the basic methods that all surrogate models should implement,\n    allowing for a consistent interface for evaluating different models.\n    \"\"\"\n\n    def __init__(self, config_space: ConfigurationSpace) -&gt; None:\n        \"\"\"Initialize the SurrogateModel with a configuration space.\n\n        Args:\n            config_space: The configuration space for the surrogate model.\n\n        \"\"\"\n        self.config_space = config_space\n\n    def evaluate_config(self, config: Configuration) -&gt; float:\n        \"\"\"Evaluate a single configuration using the surrogate model.\n\n        Args:\n            config: The configuration to evaluate.\n\n        Returns:\n            The predicted performance for the given configuration.\n\n        \"\"\"\n        res = self.evaluate(np.array(config.get_array()))\n        if not isinstance(res, float):\n            raise TypeError\n        return res\n\n    def evaluate_config_batch(self, config_batch: list[Configuration]) -&gt; list[float]:\n        \"\"\"Evaluate a batch of configurations using the surrogate model.\n\n        Args:\n            config_batch: A list of configurations to evaluate.\n\n        Returns:\n            A list of predicted performances for the given configurations.\n\n        \"\"\"\n        res = self.evaluate(np.array([config.get_array() for config in config_batch]))\n        if not isinstance(res, list):\n            raise TypeError\n        return res\n\n    @abstractmethod\n    def evaluate(self, config_array: np.ndarray) -&gt; float | list[float]:\n        \"\"\"Evaluate a configuration (or batch of configurations) represented as a numpy array.\n\n        Args:\n            config_array: A numpy array representing the configuration(s).\n\n        Returns:\n            The predicted performance(s).\n\n        \"\"\"\n</code></pre>"},{"location":"modules/#hypershap.surrogate_model.SurrogateModel.__init__","title":"<code>__init__(config_space)</code>","text":"<p>Initialize the SurrogateModel with a configuration space.</p> <p>Parameters:</p> Name Type Description Default <code>config_space</code> <code>ConfigurationSpace</code> <p>The configuration space for the surrogate model.</p> required Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>def __init__(self, config_space: ConfigurationSpace) -&gt; None:\n    \"\"\"Initialize the SurrogateModel with a configuration space.\n\n    Args:\n        config_space: The configuration space for the surrogate model.\n\n    \"\"\"\n    self.config_space = config_space\n</code></pre>"},{"location":"modules/#hypershap.surrogate_model.SurrogateModel.evaluate","title":"<code>evaluate(config_array)</code>  <code>abstractmethod</code>","text":"<p>Evaluate a configuration (or batch of configurations) represented as a numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>config_array</code> <code>ndarray</code> <p>A numpy array representing the configuration(s).</p> required <p>Returns:</p> Type Description <code>float | list[float]</code> <p>The predicted performance(s).</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>@abstractmethod\ndef evaluate(self, config_array: np.ndarray) -&gt; float | list[float]:\n    \"\"\"Evaluate a configuration (or batch of configurations) represented as a numpy array.\n\n    Args:\n        config_array: A numpy array representing the configuration(s).\n\n    Returns:\n        The predicted performance(s).\n\n    \"\"\"\n</code></pre>"},{"location":"modules/#hypershap.surrogate_model.SurrogateModel.evaluate_config","title":"<code>evaluate_config(config)</code>","text":"<p>Evaluate a single configuration using the surrogate model.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Configuration</code> <p>The configuration to evaluate.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The predicted performance for the given configuration.</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>def evaluate_config(self, config: Configuration) -&gt; float:\n    \"\"\"Evaluate a single configuration using the surrogate model.\n\n    Args:\n        config: The configuration to evaluate.\n\n    Returns:\n        The predicted performance for the given configuration.\n\n    \"\"\"\n    res = self.evaluate(np.array(config.get_array()))\n    if not isinstance(res, float):\n        raise TypeError\n    return res\n</code></pre>"},{"location":"modules/#hypershap.surrogate_model.SurrogateModel.evaluate_config_batch","title":"<code>evaluate_config_batch(config_batch)</code>","text":"<p>Evaluate a batch of configurations using the surrogate model.</p> <p>Parameters:</p> Name Type Description Default <code>config_batch</code> <code>list[Configuration]</code> <p>A list of configurations to evaluate.</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>A list of predicted performances for the given configurations.</p> Source code in <code>src/hypershap/surrogate_model.py</code> <pre><code>def evaluate_config_batch(self, config_batch: list[Configuration]) -&gt; list[float]:\n    \"\"\"Evaluate a batch of configurations using the surrogate model.\n\n    Args:\n        config_batch: A list of configurations to evaluate.\n\n    Returns:\n        A list of predicted performances for the given configurations.\n\n    \"\"\"\n    res = self.evaluate(np.array([config.get_array() for config in config_batch]))\n    if not isinstance(res, list):\n        raise TypeError\n    return res\n</code></pre>"},{"location":"modules/#games","title":"Games","text":"<p>The games module contains all the game-theoretic explanation games of HyperSHAP.</p>"},{"location":"modules/#hypershap.games.AblationGame","title":"<code>AblationGame</code>","text":"<p>               Bases: <code>AbstractHPIGame</code></p> <p>The ablation game generates local explanations for hyperparameter configurations.</p> <p>It does so by evaluating all potential ablation paths, switching from a baseline configuration to an optimized configuration value by value. It leverages a surrogate model to estimate performance based on blended configurations.</p> Source code in <code>src/hypershap/games/ablation.py</code> <pre><code>class AblationGame(AbstractHPIGame):\n    \"\"\"The ablation game generates local explanations for hyperparameter configurations.\n\n    It does so by evaluating all potential ablation paths, switching from a baseline configuration\n    to an optimized configuration value by value. It leverages a surrogate model to estimate\n    performance based on blended configurations.\n    \"\"\"\n\n    def __init__(\n        self,\n        explanation_task: AblationExplanationTask,\n        n_workers: int | None = None,\n        verbose: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize an AblationGame.\n\n        Args:\n        explanation_task (AblationExplanationTask): An instance of `AblationExplanationTask`\n            providing access to the baseline configuration, configuration of interest,\n            and the surrogate model for evaluation.\n        n_workers (int | None): The number of worker threads to use for parallel\n            evaluation of coalitions. Defaults to None, which disables parallelization.\n            Using more workers can significantly speed up the computation of Shapley values.\n            The maximum number of workers is capped by the number of coalitions.\n        verbose (bool | None): A boolean indicating whether to print verbose messages\n            during computation. Defaults to None. When set to True, the method prints\n            debugging information and progress updates.\n\n        \"\"\"\n        super().__init__(explanation_task, n_workers=n_workers, verbose=verbose)\n\n    def evaluate_single_coalition(self, coalition: np.ndarray) -&gt; float:\n        \"\"\"Evaluate a single coalition (combination of baseline and optimized hyperparameters).\n\n        This method blends the baseline and optimized configurations based on the provided coalition,\n        then uses the surrogate model to estimate the performance of the blended configuration.\n\n        Args:\n            coalition (np.ndarray): A Boolean array indicating which hyperparameters should be taken from the\n                baseline configuration (False) and which from the configuration of interest (True).\n\n        Returns:\n            float: The performance score of the blended configuration as estimated by the surrogate model.\n\n        \"\"\"\n        baseline_cfg = self._get_explanation_task().baseline_config.get_array()\n        cfg_of_interest = self._get_explanation_task().config_of_interest.get_array()\n        blend = np.where(coalition == 0, baseline_cfg, cfg_of_interest)\n        res = self._get_explanation_task().surrogate_model.evaluate(blend)\n\n        # validate that we do not get a list of floats by accident\n        if isinstance(res, list):\n            raise TypeError\n\n        return res\n\n    def _get_explanation_task(self) -&gt; AblationExplanationTask:\n        \"\"\"Retrieve the explanation task associated with this ablation game.\n\n        This method simply returns the `explanation_task` attribute, which provides\n        access to the baseline configuration, configuration of interest, and surrogate model.\n\n        Returns:\n            AblationExplanationTask: The explanation task associated with this ablation game.\n\n        \"\"\"\n        if isinstance(self.explanation_task, AblationExplanationTask):\n            return self.explanation_task\n        raise ValueError\n</code></pre>"},{"location":"modules/#hypershap.games.AblationGame.__init__","title":"<code>__init__(explanation_task, n_workers=None, verbose=None)</code>","text":"<p>Initialize an AblationGame.</p> <p>explanation_task (AblationExplanationTask): An instance of <code>AblationExplanationTask</code>     providing access to the baseline configuration, configuration of interest,     and the surrogate model for evaluation. n_workers (int | None): The number of worker threads to use for parallel     evaluation of coalitions. Defaults to None, which disables parallelization.     Using more workers can significantly speed up the computation of Shapley values.     The maximum number of workers is capped by the number of coalitions. verbose (bool | None): A boolean indicating whether to print verbose messages     during computation. Defaults to None. When set to True, the method prints     debugging information and progress updates.</p> Source code in <code>src/hypershap/games/ablation.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: AblationExplanationTask,\n    n_workers: int | None = None,\n    verbose: bool | None = None,\n) -&gt; None:\n    \"\"\"Initialize an AblationGame.\n\n    Args:\n    explanation_task (AblationExplanationTask): An instance of `AblationExplanationTask`\n        providing access to the baseline configuration, configuration of interest,\n        and the surrogate model for evaluation.\n    n_workers (int | None): The number of worker threads to use for parallel\n        evaluation of coalitions. Defaults to None, which disables parallelization.\n        Using more workers can significantly speed up the computation of Shapley values.\n        The maximum number of workers is capped by the number of coalitions.\n    verbose (bool | None): A boolean indicating whether to print verbose messages\n        during computation. Defaults to None. When set to True, the method prints\n        debugging information and progress updates.\n\n    \"\"\"\n    super().__init__(explanation_task, n_workers=n_workers, verbose=verbose)\n</code></pre>"},{"location":"modules/#hypershap.games.AblationGame.evaluate_single_coalition","title":"<code>evaluate_single_coalition(coalition)</code>","text":"<p>Evaluate a single coalition (combination of baseline and optimized hyperparameters).</p> <p>This method blends the baseline and optimized configurations based on the provided coalition, then uses the surrogate model to estimate the performance of the blended configuration.</p> <p>Parameters:</p> Name Type Description Default <code>coalition</code> <code>ndarray</code> <p>A Boolean array indicating which hyperparameters should be taken from the baseline configuration (False) and which from the configuration of interest (True).</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The performance score of the blended configuration as estimated by the surrogate model.</p> Source code in <code>src/hypershap/games/ablation.py</code> <pre><code>def evaluate_single_coalition(self, coalition: np.ndarray) -&gt; float:\n    \"\"\"Evaluate a single coalition (combination of baseline and optimized hyperparameters).\n\n    This method blends the baseline and optimized configurations based on the provided coalition,\n    then uses the surrogate model to estimate the performance of the blended configuration.\n\n    Args:\n        coalition (np.ndarray): A Boolean array indicating which hyperparameters should be taken from the\n            baseline configuration (False) and which from the configuration of interest (True).\n\n    Returns:\n        float: The performance score of the blended configuration as estimated by the surrogate model.\n\n    \"\"\"\n    baseline_cfg = self._get_explanation_task().baseline_config.get_array()\n    cfg_of_interest = self._get_explanation_task().config_of_interest.get_array()\n    blend = np.where(coalition == 0, baseline_cfg, cfg_of_interest)\n    res = self._get_explanation_task().surrogate_model.evaluate(blend)\n\n    # validate that we do not get a list of floats by accident\n    if isinstance(res, list):\n        raise TypeError\n\n    return res\n</code></pre>"},{"location":"modules/#hypershap.games.AbstractHPIGame","title":"<code>AbstractHPIGame</code>","text":"<p>               Bases: <code>Game</code></p> <p>Abstract base class for Hyperparameter Importance Games (HPIGames).</p> <p>Represents a game-theoretic framework for analyzing the importance of hyperparameters for HPO. It leverages the <code>shapiq</code> library to compute Shapley values and analyze coalition behavior.</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>ExplanationTask</code> <p>The <code>ExplanationTask</code> containing information about the configuration space and surrogate model.</p> required <code>n_workers</code> <code>int | None</code> <p>The number of worker threads to use for parallel evaluation of coalitions. Defaults to 1.  Using more workers can significantly speed up the computation of Shapley values.</p> <code>None</code> <code>verbose</code> <code>bool | None</code> <p>A boolean indicating whether to print verbose messages during computation. Defaults to False.</p> <code>None</code> Source code in <code>src/hypershap/games/abstract.py</code> <pre><code>class AbstractHPIGame(Game):\n    \"\"\"Abstract base class for Hyperparameter Importance Games (HPIGames).\n\n    Represents a game-theoretic framework for analyzing the importance of\n    hyperparameters for HPO. It leverages the `shapiq` library to compute\n    Shapley values and analyze coalition behavior.\n\n    Args:\n        explanation_task: The `ExplanationTask` containing information about\n            the configuration space and surrogate model.\n        n_workers: The number of worker threads to use for parallel evaluation\n            of coalitions. Defaults to 1.  Using more workers can significantly\n            speed up the computation of Shapley values.\n        verbose:  A boolean indicating whether to print verbose messages during\n            computation. Defaults to False.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        explanation_task: ExplanationTask,\n        n_workers: int | None = None,\n        verbose: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize the Hyperparameter Interaction Game (HPIGame).\n\n        Args:\n            explanation_task: The `ExplanationTask` containing information about\n                the configuration space and surrogate model. This task defines the\n                hyperparameter search space and the model used to estimate performance.\n            n_workers: The number of worker threads to use for parallel evaluation\n                of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n                speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n            verbose:  A boolean indicating whether to print verbose messages during\n                computation. Defaults to None.  When set to True, the method prints\n                debugging information and progress updates.\n\n        \"\"\"\n        self.explanation_task = explanation_task\n        self.n_workers = n_workers if n_workers is not None else 1\n        self.verbose = verbose if verbose is not None else False\n\n        # determine the value of the empty coalition so that we can normalize wrt to that performance\n        normalization_value = self.evaluate_single_coalition(\n            np.array([False] * explanation_task.get_num_hyperparameters()),\n        )\n\n        super().__init__(\n            n_players=explanation_task.get_num_hyperparameters(),\n            normalize=True,\n            normalization_value=normalization_value,\n        )\n\n    def _process_chunk(self, chunk: np.ndarray) -&gt; list:\n        \"\"\"Process a chunk of coalitions, evaluating each coalition using the `evaluate_single_coalition` method.\n\n        Args:\n            chunk: A NumPy array representing a subset of coalitions.\n\n        Returns:\n            A list of floats, where each float is the value of a coalition\n            in the input chunk.\n\n        \"\"\"\n        return [self.evaluate_single_coalition(c) for c in chunk]\n\n    def value_function(self, coalitions: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Calculate the value of a list of coalitions.\n\n        This method handles both single-worker and multi-worker scenarios for efficient computation.\n\n        Args:\n            coalitions: A NumPy array representing a list of coalitions.  Each\n                coalition is a Boolean array indicating which hyperparameters\n                are included in that coalition.\n\n        Returns:\n            A NumPy array containing the values of the input coalitions.\n\n        \"\"\"\n        if self.n_workers == 1:\n            value_list = []\n            for coalition in coalitions:\n                value_list += [self.evaluate_single_coalition(coalition)]\n        else:\n            m = len(coalitions)\n            num_workers = min(self.n_workers, m)\n            base_size = m // num_workers\n            remainder = m % num_workers\n\n            chunk_indices: Iterable[tuple[int, int]] = []\n            start = 0\n            for i in range(num_workers):\n                size = base_size + (1 if i &lt; remainder else 0)\n                chunk_indices.append((start, start + size))\n                start += size\n\n            chunks = [coalitions[start:end] for start, end in chunk_indices]\n\n            with ThreadPoolExecutor(max_workers=self.n_workers) as executor:\n                partial_results = list(executor.map(self._process_chunk, chunks))\n\n            value_list = [val for sublist in partial_results for val in sublist]\n        return np.array(value_list)\n\n    @abstractmethod\n    def evaluate_single_coalition(self, coalition: np.ndarray) -&gt; float:\n        \"\"\"Evaluate the value of a single coalition.\n\n        This method *must* be implemented by subclasses.\n\n        Args:\n            coalition: A boolean array representing a coalition of hyperparameters.\n\n        Returns:\n            The value of the coalition (a float).\n\n        \"\"\"\n\n    def get_num_hyperparameters(self) -&gt; int:\n        \"\"\"Return the number of hyperparameters being considered.\n\n        Returns:\n            The number of hyperparameters (an integer).\n\n        \"\"\"\n        return self.explanation_task.get_num_hyperparameters()\n\n    def get_hyperparameter_names(self) -&gt; list[str]:\n        \"\"\"Return a list of the names of the hyperparameters.\n\n        Returns:\n            A list of strings, where each string is the name of a hyperparameter.\n\n        \"\"\"\n        return self.explanation_task.get_hyperparameter_names()\n</code></pre>"},{"location":"modules/#hypershap.games.AbstractHPIGame.__init__","title":"<code>__init__(explanation_task, n_workers=None, verbose=None)</code>","text":"<p>Initialize the Hyperparameter Interaction Game (HPIGame).</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>ExplanationTask</code> <p>The <code>ExplanationTask</code> containing information about the configuration space and surrogate model. This task defines the hyperparameter search space and the model used to estimate performance.</p> required <code>n_workers</code> <code>int | None</code> <p>The number of worker threads to use for parallel evaluation of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.</p> <code>None</code> <code>verbose</code> <code>bool | None</code> <p>A boolean indicating whether to print verbose messages during computation. Defaults to None.  When set to True, the method prints debugging information and progress updates.</p> <code>None</code> Source code in <code>src/hypershap/games/abstract.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: ExplanationTask,\n    n_workers: int | None = None,\n    verbose: bool | None = None,\n) -&gt; None:\n    \"\"\"Initialize the Hyperparameter Interaction Game (HPIGame).\n\n    Args:\n        explanation_task: The `ExplanationTask` containing information about\n            the configuration space and surrogate model. This task defines the\n            hyperparameter search space and the model used to estimate performance.\n        n_workers: The number of worker threads to use for parallel evaluation\n            of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n            speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n        verbose:  A boolean indicating whether to print verbose messages during\n            computation. Defaults to None.  When set to True, the method prints\n            debugging information and progress updates.\n\n    \"\"\"\n    self.explanation_task = explanation_task\n    self.n_workers = n_workers if n_workers is not None else 1\n    self.verbose = verbose if verbose is not None else False\n\n    # determine the value of the empty coalition so that we can normalize wrt to that performance\n    normalization_value = self.evaluate_single_coalition(\n        np.array([False] * explanation_task.get_num_hyperparameters()),\n    )\n\n    super().__init__(\n        n_players=explanation_task.get_num_hyperparameters(),\n        normalize=True,\n        normalization_value=normalization_value,\n    )\n</code></pre>"},{"location":"modules/#hypershap.games.AbstractHPIGame.evaluate_single_coalition","title":"<code>evaluate_single_coalition(coalition)</code>  <code>abstractmethod</code>","text":"<p>Evaluate the value of a single coalition.</p> <p>This method must be implemented by subclasses.</p> <p>Parameters:</p> Name Type Description Default <code>coalition</code> <code>ndarray</code> <p>A boolean array representing a coalition of hyperparameters.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The value of the coalition (a float).</p> Source code in <code>src/hypershap/games/abstract.py</code> <pre><code>@abstractmethod\ndef evaluate_single_coalition(self, coalition: np.ndarray) -&gt; float:\n    \"\"\"Evaluate the value of a single coalition.\n\n    This method *must* be implemented by subclasses.\n\n    Args:\n        coalition: A boolean array representing a coalition of hyperparameters.\n\n    Returns:\n        The value of the coalition (a float).\n\n    \"\"\"\n</code></pre>"},{"location":"modules/#hypershap.games.AbstractHPIGame.get_hyperparameter_names","title":"<code>get_hyperparameter_names()</code>","text":"<p>Return a list of the names of the hyperparameters.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of strings, where each string is the name of a hyperparameter.</p> Source code in <code>src/hypershap/games/abstract.py</code> <pre><code>def get_hyperparameter_names(self) -&gt; list[str]:\n    \"\"\"Return a list of the names of the hyperparameters.\n\n    Returns:\n        A list of strings, where each string is the name of a hyperparameter.\n\n    \"\"\"\n    return self.explanation_task.get_hyperparameter_names()\n</code></pre>"},{"location":"modules/#hypershap.games.AbstractHPIGame.get_num_hyperparameters","title":"<code>get_num_hyperparameters()</code>","text":"<p>Return the number of hyperparameters being considered.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of hyperparameters (an integer).</p> Source code in <code>src/hypershap/games/abstract.py</code> <pre><code>def get_num_hyperparameters(self) -&gt; int:\n    \"\"\"Return the number of hyperparameters being considered.\n\n    Returns:\n        The number of hyperparameters (an integer).\n\n    \"\"\"\n    return self.explanation_task.get_num_hyperparameters()\n</code></pre>"},{"location":"modules/#hypershap.games.AbstractHPIGame.value_function","title":"<code>value_function(coalitions)</code>","text":"<p>Calculate the value of a list of coalitions.</p> <p>This method handles both single-worker and multi-worker scenarios for efficient computation.</p> <p>Parameters:</p> Name Type Description Default <code>coalitions</code> <code>ndarray</code> <p>A NumPy array representing a list of coalitions.  Each coalition is a Boolean array indicating which hyperparameters are included in that coalition.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A NumPy array containing the values of the input coalitions.</p> Source code in <code>src/hypershap/games/abstract.py</code> <pre><code>def value_function(self, coalitions: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Calculate the value of a list of coalitions.\n\n    This method handles both single-worker and multi-worker scenarios for efficient computation.\n\n    Args:\n        coalitions: A NumPy array representing a list of coalitions.  Each\n            coalition is a Boolean array indicating which hyperparameters\n            are included in that coalition.\n\n    Returns:\n        A NumPy array containing the values of the input coalitions.\n\n    \"\"\"\n    if self.n_workers == 1:\n        value_list = []\n        for coalition in coalitions:\n            value_list += [self.evaluate_single_coalition(coalition)]\n    else:\n        m = len(coalitions)\n        num_workers = min(self.n_workers, m)\n        base_size = m // num_workers\n        remainder = m % num_workers\n\n        chunk_indices: Iterable[tuple[int, int]] = []\n        start = 0\n        for i in range(num_workers):\n            size = base_size + (1 if i &lt; remainder else 0)\n            chunk_indices.append((start, start + size))\n            start += size\n\n        chunks = [coalitions[start:end] for start, end in chunk_indices]\n\n        with ThreadPoolExecutor(max_workers=self.n_workers) as executor:\n            partial_results = list(executor.map(self._process_chunk, chunks))\n\n        value_list = [val for sublist in partial_results for val in sublist]\n    return np.array(value_list)\n</code></pre>"},{"location":"modules/#hypershap.games.MistunabilityGame","title":"<code>MistunabilityGame</code>","text":"<p>               Bases: <code>SearchBasedGame</code></p> <p>Game representing the mistunability of hyperparameters.</p> Source code in <code>src/hypershap/games/tunability.py</code> <pre><code>class MistunabilityGame(SearchBasedGame):\n    \"\"\"Game representing the mistunability of hyperparameters.\"\"\"\n\n    def __init__(\n        self,\n        explanation_task: MistunabilityExplanationTask,\n        cs_searcher: ConfigSpaceSearcher | None = None,\n        n_workers: int | None = None,\n        verbose: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize the mistunability game.\n\n        Args:\n            explanation_task: The explanation task containing the configuration\n                space and surrogate model.\n            cs_searcher: The configuration space searcher. If None, a\n                RandomConfigSpaceSearcher is used by default.\n            n_workers: The number of worker threads to use for parallel evaluation\n                of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n                speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n            verbose:  A boolean indicating whether to print verbose messages during\n                computation. Defaults to None.  When set to True, the method prints\n                debugging information and progress updates.\n\n        \"\"\"\n        # set cs searcher if not given by default to a random config space searcher.\n        if cs_searcher is None:\n            cs_searcher = RandomConfigSpaceSearcher(explanation_task, mode=\"min\")\n        elif cs_searcher.mode != \"min\":  # ensure that cs_searcher is maximizing\n            logger.warning(\"WARN: Mistunability game set mode of given ConfigSpaceSearcher to minimize.\")\n            cs_searcher.mode = \"min\"\n\n        super().__init__(explanation_task, cs_searcher, n_workers=n_workers, verbose=verbose)\n</code></pre>"},{"location":"modules/#hypershap.games.MistunabilityGame.__init__","title":"<code>__init__(explanation_task, cs_searcher=None, n_workers=None, verbose=None)</code>","text":"<p>Initialize the mistunability game.</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>MistunabilityExplanationTask</code> <p>The explanation task containing the configuration space and surrogate model.</p> required <code>cs_searcher</code> <code>ConfigSpaceSearcher | None</code> <p>The configuration space searcher. If None, a RandomConfigSpaceSearcher is used by default.</p> <code>None</code> <code>n_workers</code> <code>int | None</code> <p>The number of worker threads to use for parallel evaluation of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.</p> <code>None</code> <code>verbose</code> <code>bool | None</code> <p>A boolean indicating whether to print verbose messages during computation. Defaults to None.  When set to True, the method prints debugging information and progress updates.</p> <code>None</code> Source code in <code>src/hypershap/games/tunability.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: MistunabilityExplanationTask,\n    cs_searcher: ConfigSpaceSearcher | None = None,\n    n_workers: int | None = None,\n    verbose: bool | None = None,\n) -&gt; None:\n    \"\"\"Initialize the mistunability game.\n\n    Args:\n        explanation_task: The explanation task containing the configuration\n            space and surrogate model.\n        cs_searcher: The configuration space searcher. If None, a\n            RandomConfigSpaceSearcher is used by default.\n        n_workers: The number of worker threads to use for parallel evaluation\n            of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n            speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n        verbose:  A boolean indicating whether to print verbose messages during\n            computation. Defaults to None.  When set to True, the method prints\n            debugging information and progress updates.\n\n    \"\"\"\n    # set cs searcher if not given by default to a random config space searcher.\n    if cs_searcher is None:\n        cs_searcher = RandomConfigSpaceSearcher(explanation_task, mode=\"min\")\n    elif cs_searcher.mode != \"min\":  # ensure that cs_searcher is maximizing\n        logger.warning(\"WARN: Mistunability game set mode of given ConfigSpaceSearcher to minimize.\")\n        cs_searcher.mode = \"min\"\n\n    super().__init__(explanation_task, cs_searcher, n_workers=n_workers, verbose=verbose)\n</code></pre>"},{"location":"modules/#hypershap.games.OptimizerBiasGame","title":"<code>OptimizerBiasGame</code>","text":"<p>               Bases: <code>AbstractHPIGame</code></p> <p>An explanation game to measure bias in hyperparameter optimizers.</p> <p>This class extends the <code>AbstractHPIGame</code> base class and is specifically designed to quantify how much an optimizer is biased toward tuning certain hyperparameters. To this end a set of diverse optimizers is used as a reference.</p> <p>Attributes:</p> Name Type Description <code>explanation_task</code> <code>OptimizerBiasExplanationTask</code> <p>The task that defines the game. This includes the configuration sapce, the surrogate model and a baseline configuration, as well as the optimizer of interest and the ensemble of diverse optimizers.</p> <p>Methods:</p> Name Description <code>evaluate_single_coalition</code> <p>Computes the marginal contribution of a coalition (subset of features) by comparing the optimizer of interest against an optimizer ensemble. This method is called internally during the game's main evaluation process.</p> Note <p>The game evaluates coalitions based on the difference between the outcome using the primary optimizer and the maximum outcome achieved by any optimizer in the provided ensemble.</p> Source code in <code>src/hypershap/games/optimizerbias.py</code> <pre><code>class OptimizerBiasGame(AbstractHPIGame):\n    \"\"\"An explanation game to measure bias in hyperparameter optimizers.\n\n    This class extends the `AbstractHPIGame` base class and is specifically designed\n    to quantify how much an optimizer is biased toward tuning certain hyperparameters.\n    To this end a set of diverse optimizers is used as a reference.\n\n    Attributes:\n        explanation_task (OptimizerBiasExplanationTask): The task that defines the game.\n            This includes the configuration sapce, the surrogate model and a baseline configuration, as well as the\n            optimizer of interest and the ensemble of diverse optimizers.\n\n\n    Methods:\n        evaluate_single_coalition: Computes the marginal contribution of a coalition (subset of features)\n            by comparing the optimizer of interest against an optimizer ensemble. This method is called internally\n            during the game's main evaluation process.\n\n    Note:\n        The game evaluates coalitions based on the difference between the outcome using the primary optimizer\n        and the maximum outcome achieved by any optimizer in the provided ensemble.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        explanation_task: OptimizerBiasExplanationTask,\n        n_workers: int | None = None,\n        verbose: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize an instance of `OptimizerBiasGame`.\n\n        Args:\n            explanation_task (OptimizerBiasExplanationTask): The task that contains all necessary\n                information for defining the game. This includes the configuration space, the surrogate model, the\n                optimizer of interest, and the ensemble of diverse optimizers.\n            n_workers: The number of worker threads to use for parallel evaluation\n                of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n                speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n            verbose:  A boolean indicating whether to print verbose messages during\n                computation. Defaults to None.  When set to True, the method prints\n                debugging information and progress updates.\n\n        Example:\n            &gt;&gt;&gt; from hypershap.task import OptimizerBiasExplanationTask\n            &gt;&gt;&gt; # Create an explanation task instance with specific parameters\n            &gt;&gt;&gt; expl_task = OptimizerBiasExplanationTask(...)\n            &gt;&gt;&gt; game = OptimizerBiasGame(expl_task)\n\n        \"\"\"\n        super().__init__(explanation_task, n_workers=n_workers, verbose=verbose)\n\n    def _get_explanation_task(self) -&gt; OptimizerBiasExplanationTask:\n        if isinstance(self.explanation_task, OptimizerBiasExplanationTask):\n            return self.explanation_task\n        raise ValueError\n\n    def evaluate_single_coalition(self, coalition: np.ndarray) -&gt; float:\n        \"\"\"Evaluate a single coalition by comparing against an optimizer ensemble.\n\n        Args:\n            coalition (np.ndarray): A binary array indicating which hyperparameters are included in the coalition.\n                The array has shape (n_hyperparameters,) where True means hyperparameters is included and False\n                 otherwise.\n\n        Returns:\n            float: The marginal contribution of the coalition. It is computed as the difference between\n                the outcome when using the optimizer of interest with the given coalition, versus the best outcome\n                achievable by any optimizer in the ensemble (including the one of interest).\n\n        Note:\n            This method overrides a base class abstract method and must be implemented to provide specific game logic.\n            The value returned here is used for computing Shapley values or other cooperative game theory measures.\n\n        Example:\n            &gt;&gt;&gt; coalition = np.array([1, 0, 1])  # Hyperparameters 0 and 2 are included\n            &gt;&gt;&gt; marginal_contribution = game.evaluate_single_coalition(coalition)\n            &gt;&gt;&gt; print(marginal_contribution)  # Outputs the difference in outcomes for this coalition.\n\n        \"\"\"\n        optimizer_res = self._get_explanation_task().optimizer_of_interest.search(coalition)\n        optimizer_ensemble_res = [\n            optimizer.search(coalition) for optimizer in self._get_explanation_task().optimizer_ensemble\n        ]\n        return optimizer_res - max([*optimizer_ensemble_res, optimizer_res])\n</code></pre>"},{"location":"modules/#hypershap.games.OptimizerBiasGame.__init__","title":"<code>__init__(explanation_task, n_workers=None, verbose=None)</code>","text":"<p>Initialize an instance of <code>OptimizerBiasGame</code>.</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>OptimizerBiasExplanationTask</code> <p>The task that contains all necessary information for defining the game. This includes the configuration space, the surrogate model, the optimizer of interest, and the ensemble of diverse optimizers.</p> required <code>n_workers</code> <code>int | None</code> <p>The number of worker threads to use for parallel evaluation of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.</p> <code>None</code> <code>verbose</code> <code>bool | None</code> <p>A boolean indicating whether to print verbose messages during computation. Defaults to None.  When set to True, the method prints debugging information and progress updates.</p> <code>None</code> Example <p>from hypershap.task import OptimizerBiasExplanationTask</p> Source code in <code>src/hypershap/games/optimizerbias.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: OptimizerBiasExplanationTask,\n    n_workers: int | None = None,\n    verbose: bool | None = None,\n) -&gt; None:\n    \"\"\"Initialize an instance of `OptimizerBiasGame`.\n\n    Args:\n        explanation_task (OptimizerBiasExplanationTask): The task that contains all necessary\n            information for defining the game. This includes the configuration space, the surrogate model, the\n            optimizer of interest, and the ensemble of diverse optimizers.\n        n_workers: The number of worker threads to use for parallel evaluation\n            of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n            speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n        verbose:  A boolean indicating whether to print verbose messages during\n            computation. Defaults to None.  When set to True, the method prints\n            debugging information and progress updates.\n\n    Example:\n        &gt;&gt;&gt; from hypershap.task import OptimizerBiasExplanationTask\n        &gt;&gt;&gt; # Create an explanation task instance with specific parameters\n        &gt;&gt;&gt; expl_task = OptimizerBiasExplanationTask(...)\n        &gt;&gt;&gt; game = OptimizerBiasGame(expl_task)\n\n    \"\"\"\n    super().__init__(explanation_task, n_workers=n_workers, verbose=verbose)\n</code></pre>"},{"location":"modules/#hypershap.games.OptimizerBiasGame.__init__--create-an-explanation-task-instance-with-specific-parameters","title":"Create an explanation task instance with specific parameters","text":"<p>expl_task = OptimizerBiasExplanationTask(...) game = OptimizerBiasGame(expl_task)</p>"},{"location":"modules/#hypershap.games.OptimizerBiasGame.evaluate_single_coalition","title":"<code>evaluate_single_coalition(coalition)</code>","text":"<p>Evaluate a single coalition by comparing against an optimizer ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>coalition</code> <code>ndarray</code> <p>A binary array indicating which hyperparameters are included in the coalition. The array has shape (n_hyperparameters,) where True means hyperparameters is included and False  otherwise.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The marginal contribution of the coalition. It is computed as the difference between the outcome when using the optimizer of interest with the given coalition, versus the best outcome achievable by any optimizer in the ensemble (including the one of interest).</p> Note <p>This method overrides a base class abstract method and must be implemented to provide specific game logic. The value returned here is used for computing Shapley values or other cooperative game theory measures.</p> Example <p>coalition = np.array([1, 0, 1])  # Hyperparameters 0 and 2 are included marginal_contribution = game.evaluate_single_coalition(coalition) print(marginal_contribution)  # Outputs the difference in outcomes for this coalition.</p> Source code in <code>src/hypershap/games/optimizerbias.py</code> <pre><code>def evaluate_single_coalition(self, coalition: np.ndarray) -&gt; float:\n    \"\"\"Evaluate a single coalition by comparing against an optimizer ensemble.\n\n    Args:\n        coalition (np.ndarray): A binary array indicating which hyperparameters are included in the coalition.\n            The array has shape (n_hyperparameters,) where True means hyperparameters is included and False\n             otherwise.\n\n    Returns:\n        float: The marginal contribution of the coalition. It is computed as the difference between\n            the outcome when using the optimizer of interest with the given coalition, versus the best outcome\n            achievable by any optimizer in the ensemble (including the one of interest).\n\n    Note:\n        This method overrides a base class abstract method and must be implemented to provide specific game logic.\n        The value returned here is used for computing Shapley values or other cooperative game theory measures.\n\n    Example:\n        &gt;&gt;&gt; coalition = np.array([1, 0, 1])  # Hyperparameters 0 and 2 are included\n        &gt;&gt;&gt; marginal_contribution = game.evaluate_single_coalition(coalition)\n        &gt;&gt;&gt; print(marginal_contribution)  # Outputs the difference in outcomes for this coalition.\n\n    \"\"\"\n    optimizer_res = self._get_explanation_task().optimizer_of_interest.search(coalition)\n    optimizer_ensemble_res = [\n        optimizer.search(coalition) for optimizer in self._get_explanation_task().optimizer_ensemble\n    ]\n    return optimizer_res - max([*optimizer_ensemble_res, optimizer_res])\n</code></pre>"},{"location":"modules/#hypershap.games.SearchBasedGame","title":"<code>SearchBasedGame</code>","text":"<p>               Bases: <code>AbstractHPIGame</code></p> <p>Base class for games that rely on searching the configuration space.</p> Source code in <code>src/hypershap/games/tunability.py</code> <pre><code>class SearchBasedGame(AbstractHPIGame):\n    \"\"\"Base class for games that rely on searching the configuration space.\"\"\"\n\n    def __init__(\n        self,\n        explanation_task: BaselineExplanationTask,\n        cs_searcher: ConfigSpaceSearcher,\n        n_workers: int | None = None,\n        verbose: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize the search-based game.\n\n        Args:\n            explanation_task: The explanation task containing the configuration\n                space and surrogate model.\n            cs_searcher: The configuration space searcher. If None, a\n                RandomConfigSpaceSearcher is used by default.\n            n_workers: The number of worker threads to use for parallel evaluation\n                of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n                speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n            verbose:  A boolean indicating whether to print verbose messages during\n                computation. Defaults to None.  When set to True, the method prints\n                debugging information and progress updates.\n\n        \"\"\"\n        self.cs_searcher = cs_searcher\n        super().__init__(explanation_task, n_workers=n_workers, verbose=verbose)\n\n    def evaluate_single_coalition(self, coalition: np.ndarray) -&gt; float:\n        \"\"\"Evaluate the value of a single coalition using the configuration space searcher.\n\n        Args:\n            coalition: A boolean array indicating which hyperparameters are\n                constrained by the coalition.\n\n        Returns:\n            The value of the coalition based on the search results.\n\n        \"\"\"\n        return self.cs_searcher.search(coalition)\n</code></pre>"},{"location":"modules/#hypershap.games.SearchBasedGame.__init__","title":"<code>__init__(explanation_task, cs_searcher, n_workers=None, verbose=None)</code>","text":"<p>Initialize the search-based game.</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>BaselineExplanationTask</code> <p>The explanation task containing the configuration space and surrogate model.</p> required <code>cs_searcher</code> <code>ConfigSpaceSearcher</code> <p>The configuration space searcher. If None, a RandomConfigSpaceSearcher is used by default.</p> required <code>n_workers</code> <code>int | None</code> <p>The number of worker threads to use for parallel evaluation of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.</p> <code>None</code> <code>verbose</code> <code>bool | None</code> <p>A boolean indicating whether to print verbose messages during computation. Defaults to None.  When set to True, the method prints debugging information and progress updates.</p> <code>None</code> Source code in <code>src/hypershap/games/tunability.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: BaselineExplanationTask,\n    cs_searcher: ConfigSpaceSearcher,\n    n_workers: int | None = None,\n    verbose: bool | None = None,\n) -&gt; None:\n    \"\"\"Initialize the search-based game.\n\n    Args:\n        explanation_task: The explanation task containing the configuration\n            space and surrogate model.\n        cs_searcher: The configuration space searcher. If None, a\n            RandomConfigSpaceSearcher is used by default.\n        n_workers: The number of worker threads to use for parallel evaluation\n            of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n            speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n        verbose:  A boolean indicating whether to print verbose messages during\n            computation. Defaults to None.  When set to True, the method prints\n            debugging information and progress updates.\n\n    \"\"\"\n    self.cs_searcher = cs_searcher\n    super().__init__(explanation_task, n_workers=n_workers, verbose=verbose)\n</code></pre>"},{"location":"modules/#hypershap.games.SearchBasedGame.evaluate_single_coalition","title":"<code>evaluate_single_coalition(coalition)</code>","text":"<p>Evaluate the value of a single coalition using the configuration space searcher.</p> <p>Parameters:</p> Name Type Description Default <code>coalition</code> <code>ndarray</code> <p>A boolean array indicating which hyperparameters are constrained by the coalition.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The value of the coalition based on the search results.</p> Source code in <code>src/hypershap/games/tunability.py</code> <pre><code>def evaluate_single_coalition(self, coalition: np.ndarray) -&gt; float:\n    \"\"\"Evaluate the value of a single coalition using the configuration space searcher.\n\n    Args:\n        coalition: A boolean array indicating which hyperparameters are\n            constrained by the coalition.\n\n    Returns:\n        The value of the coalition based on the search results.\n\n    \"\"\"\n    return self.cs_searcher.search(coalition)\n</code></pre>"},{"location":"modules/#hypershap.games.SensitivityGame","title":"<code>SensitivityGame</code>","text":"<p>               Bases: <code>SearchBasedGame</code></p> <p>Game representing the sensitivity of hyperparameters.</p> Source code in <code>src/hypershap/games/tunability.py</code> <pre><code>class SensitivityGame(SearchBasedGame):\n    \"\"\"Game representing the sensitivity of hyperparameters.\"\"\"\n\n    def __init__(\n        self,\n        explanation_task: SensitivityExplanationTask,\n        cs_searcher: ConfigSpaceSearcher | None = None,\n        n_workers: int | None = None,\n        verbose: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize the sensitivity game.\n\n        Args:\n            explanation_task: The explanation task containing the configuration\n                space and surrogate model.\n            cs_searcher: The configuration space searcher. If None, a\n                RandomConfigSpaceSearcher is used by default.\n            n_workers: The number of worker threads to use for parallel evaluation\n                of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n                speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n            verbose:  A boolean indicating whether to print verbose messages during\n                computation. Defaults to None.  When set to True, the method prints\n                debugging information and progress updates.\n\n        \"\"\"\n        # set cs searcher if not given by default to a random config space searcher.\n        if cs_searcher is None:\n            cs_searcher = RandomConfigSpaceSearcher(explanation_task, mode=\"var\")\n        elif cs_searcher.mode != \"var\":  # ensure that cs_searcher is maximizing\n            logger.warning(\"WARN: Sensitivity game set mode of given ConfigSpaceSearcher to variance.\")\n            cs_searcher.mode = \"var\"\n\n        super().__init__(explanation_task, cs_searcher, n_workers=n_workers, verbose=verbose)\n</code></pre>"},{"location":"modules/#hypershap.games.SensitivityGame.__init__","title":"<code>__init__(explanation_task, cs_searcher=None, n_workers=None, verbose=None)</code>","text":"<p>Initialize the sensitivity game.</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>SensitivityExplanationTask</code> <p>The explanation task containing the configuration space and surrogate model.</p> required <code>cs_searcher</code> <code>ConfigSpaceSearcher | None</code> <p>The configuration space searcher. If None, a RandomConfigSpaceSearcher is used by default.</p> <code>None</code> <code>n_workers</code> <code>int | None</code> <p>The number of worker threads to use for parallel evaluation of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.</p> <code>None</code> <code>verbose</code> <code>bool | None</code> <p>A boolean indicating whether to print verbose messages during computation. Defaults to None.  When set to True, the method prints debugging information and progress updates.</p> <code>None</code> Source code in <code>src/hypershap/games/tunability.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: SensitivityExplanationTask,\n    cs_searcher: ConfigSpaceSearcher | None = None,\n    n_workers: int | None = None,\n    verbose: bool | None = None,\n) -&gt; None:\n    \"\"\"Initialize the sensitivity game.\n\n    Args:\n        explanation_task: The explanation task containing the configuration\n            space and surrogate model.\n        cs_searcher: The configuration space searcher. If None, a\n            RandomConfigSpaceSearcher is used by default.\n        n_workers: The number of worker threads to use for parallel evaluation\n            of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n            speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n        verbose:  A boolean indicating whether to print verbose messages during\n            computation. Defaults to None.  When set to True, the method prints\n            debugging information and progress updates.\n\n    \"\"\"\n    # set cs searcher if not given by default to a random config space searcher.\n    if cs_searcher is None:\n        cs_searcher = RandomConfigSpaceSearcher(explanation_task, mode=\"var\")\n    elif cs_searcher.mode != \"var\":  # ensure that cs_searcher is maximizing\n        logger.warning(\"WARN: Sensitivity game set mode of given ConfigSpaceSearcher to variance.\")\n        cs_searcher.mode = \"var\"\n\n    super().__init__(explanation_task, cs_searcher, n_workers=n_workers, verbose=verbose)\n</code></pre>"},{"location":"modules/#hypershap.games.TunabilityGame","title":"<code>TunabilityGame</code>","text":"<p>               Bases: <code>SearchBasedGame</code></p> <p>Game representing the tunability of hyperparameters.</p> Source code in <code>src/hypershap/games/tunability.py</code> <pre><code>class TunabilityGame(SearchBasedGame):\n    \"\"\"Game representing the tunability of hyperparameters.\"\"\"\n\n    def __init__(\n        self,\n        explanation_task: TunabilityExplanationTask,\n        cs_searcher: ConfigSpaceSearcher | None = None,\n        n_workers: int | None = None,\n        verbose: bool | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize the tunability game.\n\n        Args:\n            explanation_task: The explanation task containing the configuration\n                space and surrogate model.\n            cs_searcher: The configuration space searcher. If None, a\n                RandomConfigSpaceSearcher is used by default.\n            n_workers: The number of worker threads to use for parallel evaluation\n                of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n                speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n            verbose:  A boolean indicating whether to print verbose messages during\n                computation. Defaults to None.  When set to True, the method prints\n                debugging information and progress updates.\n\n        \"\"\"\n        # set cs searcher if not given by default to a random config space searcher.\n        if cs_searcher is None:\n            cs_searcher = RandomConfigSpaceSearcher(explanation_task, mode=\"max\")\n        elif cs_searcher.mode != \"max\":  # ensure that cs_searcher is maximizing\n            logger.warning(\"WARN: Tunability game set mode of given ConfigSpaceSearcher to maximize.\")\n            cs_searcher.mode = \"max\"\n        super().__init__(explanation_task, cs_searcher, n_workers=n_workers, verbose=verbose)\n</code></pre>"},{"location":"modules/#hypershap.games.TunabilityGame.__init__","title":"<code>__init__(explanation_task, cs_searcher=None, n_workers=None, verbose=None)</code>","text":"<p>Initialize the tunability game.</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>TunabilityExplanationTask</code> <p>The explanation task containing the configuration space and surrogate model.</p> required <code>cs_searcher</code> <code>ConfigSpaceSearcher | None</code> <p>The configuration space searcher. If None, a RandomConfigSpaceSearcher is used by default.</p> <code>None</code> <code>n_workers</code> <code>int | None</code> <p>The number of worker threads to use for parallel evaluation of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.</p> <code>None</code> <code>verbose</code> <code>bool | None</code> <p>A boolean indicating whether to print verbose messages during computation. Defaults to None.  When set to True, the method prints debugging information and progress updates.</p> <code>None</code> Source code in <code>src/hypershap/games/tunability.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: TunabilityExplanationTask,\n    cs_searcher: ConfigSpaceSearcher | None = None,\n    n_workers: int | None = None,\n    verbose: bool | None = None,\n) -&gt; None:\n    \"\"\"Initialize the tunability game.\n\n    Args:\n        explanation_task: The explanation task containing the configuration\n            space and surrogate model.\n        cs_searcher: The configuration space searcher. If None, a\n            RandomConfigSpaceSearcher is used by default.\n        n_workers: The number of worker threads to use for parallel evaluation\n            of coalitions. Defaults to None meaning no parallelization.  Using more workers can significantly\n            speed up the computation of Shapley values.  The maximum number of workers is capped by the number of coalitions.\n        verbose:  A boolean indicating whether to print verbose messages during\n            computation. Defaults to None.  When set to True, the method prints\n            debugging information and progress updates.\n\n    \"\"\"\n    # set cs searcher if not given by default to a random config space searcher.\n    if cs_searcher is None:\n        cs_searcher = RandomConfigSpaceSearcher(explanation_task, mode=\"max\")\n    elif cs_searcher.mode != \"max\":  # ensure that cs_searcher is maximizing\n        logger.warning(\"WARN: Tunability game set mode of given ConfigSpaceSearcher to maximize.\")\n        cs_searcher.mode = \"max\"\n    super().__init__(explanation_task, cs_searcher, n_workers=n_workers, verbose=verbose)\n</code></pre>"},{"location":"modules/#utils","title":"Utils","text":"<p>Utils module for specifying custom error classes and config space search interfaces.</p> <p>This module defines specific error classes for simpler debugging and interfaces for searching config spaces.</p>"},{"location":"modules/#hypershap.utils.ConfigSpaceSearcher","title":"<code>ConfigSpaceSearcher</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for searching the configuration space.</p> <p>Provides an interface for retrieving performance values based on a coalition of hyperparameters.</p> Source code in <code>src/hypershap/utils.py</code> <pre><code>class ConfigSpaceSearcher(ABC):\n    \"\"\"Abstract base class for searching the configuration space.\n\n    Provides an interface for retrieving performance values based on a coalition\n    of hyperparameters.\n    \"\"\"\n\n    def __init__(\n        self,\n        explanation_task: BaselineExplanationTask,\n        mode: str = \"max\",\n        allowed_modes: list[str] | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize the searcher with the explanation task.\n\n        Args:\n            explanation_task: The explanation task containing the configuration\n                space and surrogate model.\n            mode: The aggregation mode for performance values.\n            allowed_modes: The list of allowed aggregation mode for performance values.\n\n        \"\"\"\n        self.explanation_task = explanation_task\n        self.mode = mode\n        self.allowed_modes = allowed_modes\n\n        if self.allowed_modes is None or mode in self.allowed_modes:\n            self.mode = mode\n        else:\n            raise UnknownModeError\n\n    @abstractmethod\n    def search(self, coalition: np.ndarray) -&gt; float:\n        \"\"\"Search the configuration space based on the coalition.\n\n        Args:\n            coalition: A boolean array indicating which hyperparameters are\n                constrained by the coalition.\n\n        Returns:\n            The aggregated performance value based on the search results.\n\n        \"\"\"\n</code></pre>"},{"location":"modules/#hypershap.utils.ConfigSpaceSearcher.__init__","title":"<code>__init__(explanation_task, mode='max', allowed_modes=None)</code>","text":"<p>Initialize the searcher with the explanation task.</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>BaselineExplanationTask</code> <p>The explanation task containing the configuration space and surrogate model.</p> required <code>mode</code> <code>str</code> <p>The aggregation mode for performance values.</p> <code>'max'</code> <code>allowed_modes</code> <code>list[str] | None</code> <p>The list of allowed aggregation mode for performance values.</p> <code>None</code> Source code in <code>src/hypershap/utils.py</code> <pre><code>def __init__(\n    self,\n    explanation_task: BaselineExplanationTask,\n    mode: str = \"max\",\n    allowed_modes: list[str] | None = None,\n) -&gt; None:\n    \"\"\"Initialize the searcher with the explanation task.\n\n    Args:\n        explanation_task: The explanation task containing the configuration\n            space and surrogate model.\n        mode: The aggregation mode for performance values.\n        allowed_modes: The list of allowed aggregation mode for performance values.\n\n    \"\"\"\n    self.explanation_task = explanation_task\n    self.mode = mode\n    self.allowed_modes = allowed_modes\n\n    if self.allowed_modes is None or mode in self.allowed_modes:\n        self.mode = mode\n    else:\n        raise UnknownModeError\n</code></pre>"},{"location":"modules/#hypershap.utils.ConfigSpaceSearcher.search","title":"<code>search(coalition)</code>  <code>abstractmethod</code>","text":"<p>Search the configuration space based on the coalition.</p> <p>Parameters:</p> Name Type Description Default <code>coalition</code> <code>ndarray</code> <p>A boolean array indicating which hyperparameters are constrained by the coalition.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The aggregated performance value based on the search results.</p> Source code in <code>src/hypershap/utils.py</code> <pre><code>@abstractmethod\ndef search(self, coalition: np.ndarray) -&gt; float:\n    \"\"\"Search the configuration space based on the coalition.\n\n    Args:\n        coalition: A boolean array indicating which hyperparameters are\n            constrained by the coalition.\n\n    Returns:\n        The aggregated performance value based on the search results.\n\n    \"\"\"\n</code></pre>"},{"location":"modules/#hypershap.utils.RandomConfigSpaceSearcher","title":"<code>RandomConfigSpaceSearcher</code>","text":"<p>               Bases: <code>ConfigSpaceSearcher</code></p> <p>A searcher that randomly samples the configuration space and evaluates them using the surrogate model.</p> <p>Useful for establishing baseline performance or approximating game values.</p> Source code in <code>src/hypershap/utils.py</code> <pre><code>class RandomConfigSpaceSearcher(ConfigSpaceSearcher):\n    \"\"\"A searcher that randomly samples the configuration space and evaluates them using the surrogate model.\n\n    Useful for establishing baseline performance or approximating game values.\n    \"\"\"\n\n    def __init__(self, explanation_task: BaselineExplanationTask, mode: str = \"max\", n_samples: int = 10_000) -&gt; None:\n        \"\"\"Initialize the random configuration space searcher.\n\n        Args:\n            explanation_task: The explanation task containing the configuration\n                space and surrogate model.\n            mode: The aggregation mode for performance values ('max', 'min', 'avg', 'var').\n            n_samples: The number of configurations to sample.\n\n        \"\"\"\n        allowed_modes = [\"max\", \"min\", \"avg\", \"var\"]\n        super().__init__(explanation_task, mode=mode, allowed_modes=allowed_modes)\n\n        sampled_configurations = self.explanation_task.config_space.sample_configuration(size=n_samples)\n        self.random_sample = np.array([config.get_array() for config in sampled_configurations])\n\n        # cache coalition values to ensure monotonicity for min/max\n        self.coalition_cache = {}\n\n    def search(self, coalition: np.ndarray) -&gt; float:\n        \"\"\"Search the configuration space based on the coalition.\n\n        Args:\n            coalition: A boolean array indicating which hyperparameters are\n                constrained by the coalition.\n\n        Returns:\n            The aggregated performance value based on the search results.\n\n        \"\"\"\n        # copy the sampled configurations\n        temp_random_sample = self.random_sample.copy()\n\n        # blind configurations according to coalition\n        blind_coalition = ~coalition\n        column_index = np.where(blind_coalition)\n        temp_random_sample[:, column_index] = self.explanation_task.baseline_config.get_array()[column_index]\n\n        # predict performance values with the help of the surrogate model\n        vals: np.ndarray = np.array(self.explanation_task.surrogate_model.evaluate(temp_random_sample))\n\n        if self.mode == \"max\":\n            return vals.max()\n        if self.mode == \"avg\":\n            return vals.mean()\n        if self.mode == \"min\":\n            return vals.min()\n        if self.mode == \"var\":\n            return vals.var()\n\n        raise UnknownModeError\n</code></pre>"},{"location":"modules/#hypershap.utils.RandomConfigSpaceSearcher.__init__","title":"<code>__init__(explanation_task, mode='max', n_samples=10000)</code>","text":"<p>Initialize the random configuration space searcher.</p> <p>Parameters:</p> Name Type Description Default <code>explanation_task</code> <code>BaselineExplanationTask</code> <p>The explanation task containing the configuration space and surrogate model.</p> required <code>mode</code> <code>str</code> <p>The aggregation mode for performance values ('max', 'min', 'avg', 'var').</p> <code>'max'</code> <code>n_samples</code> <code>int</code> <p>The number of configurations to sample.</p> <code>10000</code> Source code in <code>src/hypershap/utils.py</code> <pre><code>def __init__(self, explanation_task: BaselineExplanationTask, mode: str = \"max\", n_samples: int = 10_000) -&gt; None:\n    \"\"\"Initialize the random configuration space searcher.\n\n    Args:\n        explanation_task: The explanation task containing the configuration\n            space and surrogate model.\n        mode: The aggregation mode for performance values ('max', 'min', 'avg', 'var').\n        n_samples: The number of configurations to sample.\n\n    \"\"\"\n    allowed_modes = [\"max\", \"min\", \"avg\", \"var\"]\n    super().__init__(explanation_task, mode=mode, allowed_modes=allowed_modes)\n\n    sampled_configurations = self.explanation_task.config_space.sample_configuration(size=n_samples)\n    self.random_sample = np.array([config.get_array() for config in sampled_configurations])\n\n    # cache coalition values to ensure monotonicity for min/max\n    self.coalition_cache = {}\n</code></pre>"},{"location":"modules/#hypershap.utils.RandomConfigSpaceSearcher.search","title":"<code>search(coalition)</code>","text":"<p>Search the configuration space based on the coalition.</p> <p>Parameters:</p> Name Type Description Default <code>coalition</code> <code>ndarray</code> <p>A boolean array indicating which hyperparameters are constrained by the coalition.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The aggregated performance value based on the search results.</p> Source code in <code>src/hypershap/utils.py</code> <pre><code>def search(self, coalition: np.ndarray) -&gt; float:\n    \"\"\"Search the configuration space based on the coalition.\n\n    Args:\n        coalition: A boolean array indicating which hyperparameters are\n            constrained by the coalition.\n\n    Returns:\n        The aggregated performance value based on the search results.\n\n    \"\"\"\n    # copy the sampled configurations\n    temp_random_sample = self.random_sample.copy()\n\n    # blind configurations according to coalition\n    blind_coalition = ~coalition\n    column_index = np.where(blind_coalition)\n    temp_random_sample[:, column_index] = self.explanation_task.baseline_config.get_array()[column_index]\n\n    # predict performance values with the help of the surrogate model\n    vals: np.ndarray = np.array(self.explanation_task.surrogate_model.evaluate(temp_random_sample))\n\n    if self.mode == \"max\":\n        return vals.max()\n    if self.mode == \"avg\":\n        return vals.mean()\n    if self.mode == \"min\":\n        return vals.min()\n    if self.mode == \"var\":\n        return vals.var()\n\n    raise UnknownModeError\n</code></pre>"},{"location":"modules/#hypershap.utils.UnknownModeError","title":"<code>UnknownModeError</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>Raised when an unknown mode is encountered.</p> Source code in <code>src/hypershap/utils.py</code> <pre><code>class UnknownModeError(ValueError):\n    \"\"\"Raised when an unknown mode is encountered.\"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize the unknown mode error.\"\"\"\n        super().__init__(\"Unknown mode for the config space searcher.\")\n</code></pre>"},{"location":"modules/#hypershap.utils.UnknownModeError.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the unknown mode error.</p> Source code in <code>src/hypershap/utils.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize the unknown mode error.\"\"\"\n    super().__init__(\"Unknown mode for the config space searcher.\")\n</code></pre>"}]}